
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Week 47: Recurrent neural networks and Autoencoders &#8212; Applied Data Analysis and Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'week47';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Project 1 on Machine Learning, deadline October 6 (midnight), 2025" href="project1.html" />
    <link rel="prev" title="Week 46: Decision Trees, Ensemble methods and Random Forests" href="week46.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Applied Data Analysis and Machine Learning - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Applied Data Analysis and Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Applied Data Analysis and Machine Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">About the course</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="schedule.html">Course setting</a></li>
<li class="toctree-l1"><a class="reference internal" href="teachers.html">Teachers and Grading</a></li>
<li class="toctree-l1"><a class="reference internal" href="textbooks.html">Textbooks</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Review of Statistics with Resampling Techniques and Linear Algebra</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="statistics.html">1. Elements of Probability Theory and Statistical Data Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg.html">2. Linear Algebra, Handling of Arrays and more Python Features</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">From Regression to Support Vector Machines</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chapter1.html">3. Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter2.html">4. Ridge and Lasso Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter3.html">5. Resampling Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter4.html">6. Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapteroptimization.html">7. Optimization, the central part of any Machine Learning algortithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter5.html">8. Support Vector Machines, overarching aims</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Decision Trees, Ensemble Methods and Boosting</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chapter6.html">9. Decision trees, overarching aims</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter7.html">10. Ensemble Methods: From a Single Tree to Many Trees and Extreme Boosting, Meet the Jungle of Methods</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Dimensionality Reduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chapter8.html">11. Basic ideas of the Principal Component Analysis (PCA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="clustering.html">12. Clustering and Unsupervised Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning Methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chapter9.html">13. Neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter10.html">14. Building a Feed Forward Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter11.html">15. Solving Differential Equations  with Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter12.html">16. Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter13.html">17. Recurrent neural networks: Overarching view</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Weekly material, notes and exercises</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="exercisesweek34.html">Exercises week 34</a></li>
<li class="toctree-l1"><a class="reference internal" href="week34.html">Week 34: Introduction to the course, Logistics and Practicalities</a></li>
<li class="toctree-l1"><a class="reference internal" href="exercisesweek35.html">Exercises week 35</a></li>
<li class="toctree-l1"><a class="reference internal" href="week35.html">Week 35: From Ordinary Linear Regression to Ridge and Lasso Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="exercisesweek36.html">Exercises week 36</a></li>
<li class="toctree-l1"><a class="reference internal" href="week36.html">Week 36: Linear Regression and Gradient descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="exercisesweek37.html">Exercises week 37</a></li>
<li class="toctree-l1"><a class="reference internal" href="week37.html">Week 37: Gradient descent methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="exercisesweek38.html">Exercises week 38</a></li>
<li class="toctree-l1"><a class="reference internal" href="week38.html">Week 38: Statistical analysis, bias-variance tradeoff and resampling methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="exercisesweek39.html">Exercises week 39</a></li>
<li class="toctree-l1"><a class="reference internal" href="week39.html">Week 39: Resampling methods and logistic regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="week40.html">Week 40: Gradient descent methods (continued) and start Neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="week41.html">Week 41 Neural networks and constructing a neural network code</a></li>
<li class="toctree-l1"><a class="reference internal" href="exercisesweek41.html">Exercises week 41</a></li>








<li class="toctree-l1"><a class="reference internal" href="week42.html">Week 42 Constructing a Neural Network code with examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="exercisesweek42.html">Exercises week 42</a></li>









<li class="toctree-l1"><a class="reference internal" href="week43.html">Week 43: Deep Learning: Constructing a Neural Network code and solving differential equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="exercisesweek43.html">Exercises week 43</a></li>

<li class="toctree-l1"><a class="reference internal" href="week44.html">Week 44,  Solving differential equations with neural networks and start Convolutional Neural Networks (CNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="exercisesweek44.html">Exercises week 44</a></li>

<li class="toctree-l1"><a class="reference internal" href="week45.html">Week 45,  Convolutional Neural Networks (CCNs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="week46.html">Week 46: Decision Trees, Ensemble methods  and Random Forests</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Week 47: Recurrent neural networks and Autoencoders</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="project1.html">Project 1 on Machine Learning, deadline October 6 (midnight), 2025</a></li>
<li class="toctree-l1"><a class="reference internal" href="project2.html">Project 2 on Machine Learning, deadline November 10 (Midnight)</a></li>
<li class="toctree-l1"><a class="reference internal" href="project3.html">Project 3 on Machine Learning, deadline December 15 (midnight), 2025</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/week47.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Week 47: Recurrent neural networks and Autoencoders</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plan-for-week-47">Plan for week 47</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reading-recommendations-rnns">Reading recommendations RNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow-examples">TensorFlow examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reading-recommendations-autoencoders-ae">Reading recommendations: Autoencoders (AE)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-recurrent-nn">What is a recurrent NN?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-rnns">Why RNNs?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-whys">More whys</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail">RNNs in more detail</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-2">RNNs in more detail, part 2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-3">RNNs in more detail, part 3</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-4">RNNs in more detail, part 4</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-5">RNNs in more detail, part 5</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-6">RNNs in more detail, part 6</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-7">RNNs in more detail, part 7</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnn-forward-pass-equations">RNN Forward Pass Equations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unrolled-rnn-in-time">Unrolled RNN in Time</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-task-character-level-rnn-classification">Example Task: Character-level RNN Classification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-defining-a-simple-rnn-using-tensorflow">PyTorch: Defining a Simple RNN, using Tensorflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#similar-example-using-pytorch">Similar example using PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropagation-through-time-bptt-and-gradients">Backpropagation Through Time (BPTT) and Gradients</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#truncated-bptt-and-gradient-clipping">Truncated BPTT and Gradient Clipping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-and-considerations">Limitations and Considerations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-rnn-time-series-example">PyTorch RNN Time Series Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow-keras-rnn-time-series-example">Tensorflow (Keras) RNN Time Series Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mathematics-of-rnns-the-basic-architecture">The mathematics of RNNs, the basic architecture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gating-mechanism-long-short-term-memory-lstm">Gating mechanism: Long Short Term Memory (LSTM)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-a-memory-cell-in-a-neural-network">Implementing a memory cell in a neural network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-details">LSTM details</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-cell-and-gates">LSTM Cell and Gates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#core-lstm-equations">Core LSTM Equations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gate-intuition-and-dynamics">Gate Intuition and Dynamics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-layout-all-figures-from-raschka-et-al">Basic layout (All figures from Raschka <em>et al.,</em>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">LSTM details</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-with-a-standard-rnn">Comparing with a standard  RNN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-details-i">LSTM details I</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-details-ii">LSTM details II</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-details-iii">LSTM details III</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forget-gate">Forget gate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-forget-gate">The forget gate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-layout">Basic layout</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input-gate">Input gate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#short-summary">Short summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forget-and-input">Forget and input</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Basic layout</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#output-gate">Output gate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-implementation-code-example">LSTM Implementation (Code Example)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-modeling-dynamical-systems">Example: Modeling Dynamical Systems</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-biological-sequences">Example: Biological Sequences</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-tips-and-variants">Training Tips and Variants</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-summary">LSTM Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-lstm">Summary of LSTM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-implementation-using-tensorflow">LSTM implementation using TensorFlow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#and-the-corresponding-one-with-pytorch">And the corresponding one with PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamical-ordinary-differential-equation">Dynamical ordinary differential equation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-runge-kutta-4-code">The Runge-Kutta-4 code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-the-above-data-to-train-an-rnn">Using the above data to train an RNN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#similar-code-using-pytorch">Similar code using PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoders-overarching-view">Autoencoders: Overarching view</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#powerful-detectors">Powerful detectors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#first-introduction-of-aes">First introduction of AEs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoder-structure">Autoencoder structure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#schematic-image-of-an-autoencoder">Schematic image of an Autoencoder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-on-the-structure">More on the structure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decoder-part">Decoder part</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#typical-aes">Typical AEs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feed-forward-autoencoder">Feed Forward Autoencoder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mirroring">Mirroring</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#output-of-middle-layer">Output of middle layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-function-of-the-output-layer">Activation Function of the Output Layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#relu">ReLU</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sigmoid">Sigmoid</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-loss-function">Cost/Loss Function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#binary-cross-entropy">Binary Cross-Entropy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstruction-error">Reconstruction Error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-using-tensorflow">Implementation using TensorFlow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-using-pytorch">Implementation using PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensionality-reduction-and-links-with-principal-component-analysis">Dimensionality reduction and links with Principal component analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-functions">Linear functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ae-mean-squared-error">AE mean-squared error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensionality-reduction">Dimensionality reduction</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)
doconce format html week47.do.txt --no_mako -->
<!-- dom:TITLE: Week 47: Recurrent neural networks and Autoencoders --><section class="tex2jax_ignore mathjax_ignore" id="week-47-recurrent-neural-networks-and-autoencoders">
<h1>Week 47: Recurrent neural networks and Autoencoders<a class="headerlink" href="#week-47-recurrent-neural-networks-and-autoencoders" title="Link to this heading">#</a></h1>
<p><strong>Morten Hjorth-Jensen</strong>, Department of Physics, University of Oslo, Norway</p>
<p>Date: <strong>November 17-21, 2025</strong></p>
<section id="plan-for-week-47">
<h2>Plan for week 47<a class="headerlink" href="#plan-for-week-47" title="Link to this heading">#</a></h2>
<p><strong>Plans for the lecture Monday 17 November, with video suggestions etc.</strong></p>
<ol class="arabic simple">
<li><p>Recurrent neural networks, code examples and long-short-term memory</p></li>
<li><p>Autoencoders (last topic this semester)</p></li>
<li><p>Last lecture: November 24, note error in time planner.</p></li>
<li><p>Video of lecture at <a class="reference external" href="https://youtu.be/cuuU-FTFaKQ">https://youtu.be/cuuU-FTFaKQ</a></p></li>
<li><p>Whiteboard notes at <a class="github reference external" href="https://github.com/CompPhysics/MachineLearning/blob/master/doc/HandWrittenNotes/2025/FYSSTKweek47.pdf">CompPhysics/MachineLearning</a></p></li>
</ol>
<p><strong>Lab sessions on Tuesday and Wednesday.</strong></p>
<ol class="arabic simple">
<li><p>Work and Discussion of project 3</p></li>
<li><p>Last weekly exercise with deadline November 28, available from (early morning) Tuesday November 18.</p></li>
<li><p>Last lab sessions: November 25 and 26</p></li>
</ol>
</section>
<section id="reading-recommendations-rnns">
<h2>Reading recommendations RNNs<a class="headerlink" href="#reading-recommendations-rnns" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>These lecture notes at <a class="github reference external" href="https://github.com/CompPhysics/MachineLearning/blob/master/doc/pub/week47/ipynb/week47.ipynb">CompPhysics/MachineLearning</a></p></li>
<li><p>See also lecture notes from week 46 at <a class="github reference external" href="https://github.com/CompPhysics/MachineLearning/blob/master/doc/pub/week46/ipynb/week46.ipynb">CompPhysics/MachineLearning</a>. The lecture on Monday starts with a repetition on recurrent neural networks. The second lecture starts with basics of autoenconders.</p></li>
<li><p>For RNNs, see Goodfellow et al chapter 10, see <a class="reference external" href="https://www.deeplearningbook.org/contents/rnn.html">https://www.deeplearningbook.org/contents/rnn.html</a>.</p></li>
<li><p>Reading suggestions for implementation of RNNs in PyTorch: see Rashcka et al.’s chapter 15 and GitHub site at <a class="github reference external" href="https://github.com/rasbt/machine-learning-book/tree/main/ch15">rasbt/machine-learning-book</a>.</p></li>
<li><p>RNN video at <a class="reference external" href="https://youtu.be/PCgrgHgy26c?feature=shared">https://youtu.be/PCgrgHgy26c?feature=shared</a></p></li>
<li><p>New xLSTM, see Beck et al <a class="reference external" href="https://arxiv.org/abs/2405.04517">https://arxiv.org/abs/2405.04517</a>. Exponential gating and modified memory structures boost xLSTM capabilities to perform favorably when compared to state-of-the-art Transformers and State Space Models, both in performance and scaling.</p></li>
</ol>
</section>
<section id="tensorflow-examples">
<h2>TensorFlow examples<a class="headerlink" href="#tensorflow-examples" title="Link to this heading">#</a></h2>
<p>For TensorFlow (using Keras) implementations, we recommend</p>
<ol class="arabic simple">
<li><p>David Foster, Generative Deep Learning with TensorFlow, see chapter 5 at <a class="reference external" href="https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/ch05.html">https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/ch05.html</a></p></li>
<li><p>Joseph Babcock and Raghav Bali Generative AI with Python and their GitHub link, chapters 2 and  3 at <a class="github reference external" href="https://github.com/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2">PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2</a></p></li>
</ol>
</section>
<section id="reading-recommendations-autoencoders-ae">
<h2>Reading recommendations: Autoencoders (AE)<a class="headerlink" href="#reading-recommendations-autoencoders-ae" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Goodfellow et al chapter 14, see <a class="reference external" href="https://www.deeplearningbook.org/contents/autoencoders.html">https://www.deeplearningbook.org/contents/autoencoders.html</a></p></li>
<li><p>Rashcka et al. Their chapter 17 contains a brief introduction only.</p></li>
<li><p>Building AEs in Keras at <a class="reference external" href="https://blog.keras.io/building-autoencoders-in-keras.html">https://blog.keras.io/building-autoencoders-in-keras.html</a></p></li>
<li><p>Introduction to AEs in TensorFlow at <a class="reference external" href="https://www.tensorflow.org/tutorials/generative/autoencoder">https://www.tensorflow.org/tutorials/generative/autoencoder</a></p></li>
</ol>
</section>
<section id="what-is-a-recurrent-nn">
<h2>What is a recurrent NN?<a class="headerlink" href="#what-is-a-recurrent-nn" title="Link to this heading">#</a></h2>
<p>A recurrent neural network (RNN), as opposed to a regular fully
connected neural network (FCNN) or just neural network (NN), has
layers that are connected to themselves.</p>
<p>In an FCNN there are no connections between nodes in a single
layer. For instance, <span class="math notranslate nohighlight">\((h_1^1\)</span> is not connected to <span class="math notranslate nohighlight">\((h_2^1\)</span>. In
addition, the input and output are always of a fixed length.</p>
<p>In an RNN, however, this is no longer the case. Nodes in the hidden
layers are connected to themselves.</p>
</section>
<section id="why-rnns">
<h2>Why RNNs?<a class="headerlink" href="#why-rnns" title="Link to this heading">#</a></h2>
<p>Recurrent neural networks work very well when working with
sequential data, that is data where the order matters. In a regular
fully connected network, the order of input doesn’t really matter.</p>
<p>Another property of  RNNs is that they can handle variable input
and output. Consider again the simplified breast cancer dataset. If you
have trained a regular FCNN on the dataset with the two features, it
makes no sense to suddenly add a third feature. The network would not
know what to do with it, and would reject such inputs with three
features (or any other number of features that isn’t two, for that
matter).</p>
</section>
<section id="more-whys">
<h2>More whys<a class="headerlink" href="#more-whys" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Traditional feedforward networks process fixed-size inputs and ignore temporal order. RNNs incorporate recurrence to handle sequential data like time series or language ￼.</p></li>
<li><p>At each time step, an RNN cell processes input x_t and a hidden state h_{t-1} from the previous step, producing a new hidden state h_t and (optionally) an output y_t.</p></li>
<li><p>This hidden state acts as a “memory” carrying information forward. For example, predicting stock prices or words in a sentence relies on past inputs ￼ ￼.</p></li>
<li><p>RNNs share parameters across time steps, so they can generalize patterns regardless of sequence length ￼.</p></li>
</ol>
</section>
<section id="rnns-in-more-detail">
<h2>RNNs in more detail<a class="headerlink" href="#rnns-in-more-detail" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/RNN2.png, width=700 frac=0.9] -->
<!-- begin figure -->
<p><img src="figslides/RNN2.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="rnns-in-more-detail-part-2">
<h2>RNNs in more detail, part 2<a class="headerlink" href="#rnns-in-more-detail-part-2" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/RNN3.png, width=700 frac=0.9] -->
<!-- begin figure -->
<p><img src="figslides/RNN3.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="rnns-in-more-detail-part-3">
<h2>RNNs in more detail, part 3<a class="headerlink" href="#rnns-in-more-detail-part-3" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/RNN4.png, width=700 frac=0.9] -->
<!-- begin figure -->
<p><img src="figslides/RNN4.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="rnns-in-more-detail-part-4">
<h2>RNNs in more detail, part 4<a class="headerlink" href="#rnns-in-more-detail-part-4" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/RNN5.png, width=700 frac=0.9] -->
<!-- begin figure -->
<p><img src="figslides/RNN5.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="rnns-in-more-detail-part-5">
<h2>RNNs in more detail, part 5<a class="headerlink" href="#rnns-in-more-detail-part-5" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/RNN6.png, width=700 frac=0.9] -->
<!-- begin figure -->
<p><img src="figslides/RNN6.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="rnns-in-more-detail-part-6">
<h2>RNNs in more detail, part 6<a class="headerlink" href="#rnns-in-more-detail-part-6" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/RNN7.png, width=700 frac=0.9] -->
<!-- begin figure -->
<p><img src="figslides/RNN7.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="rnns-in-more-detail-part-7">
<h2>RNNs in more detail, part 7<a class="headerlink" href="#rnns-in-more-detail-part-7" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/RNN8.png, width=700 frac=0.9] -->
<!-- begin figure -->
<p><img src="figslides/RNN8.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="rnn-forward-pass-equations">
<h2>RNN Forward Pass Equations<a class="headerlink" href="#rnn-forward-pass-equations" title="Link to this heading">#</a></h2>
<p>For a simple (vanilla) RNN with one hidden layer and no bias, the state update and output are:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{h}_t = \sigma(\mathbf{W}_{xh}\mathbf{x}_t + \mathbf{W}_{hh}\mathbf{h}_{t-1})\,,\quad \mathbf{y}_t = \mathbf{W}_{yh}\mathbf{h}_t,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma\)</span> is an activation (e.g. tanh or ReLU) ￼.</p>
<p>In matrix form,</p>
<div class="math notranslate nohighlight">
\[
\mathbf{W}_{xh}\in\mathbb{R}^{h\times d}, \mathbf{W}_{hh}\in\mathbb{R}^{h\times h}, \mathbf{W}_{yh}\in\mathbb{R}^{q\times h},
\]</div>
<p>for input dimension  <span class="math notranslate nohighlight">\(d\)</span>, hidden dimension <span class="math notranslate nohighlight">\(h\)</span>, output dimension <span class="math notranslate nohighlight">\(q\)</span>.</p>
<p>Because the same <span class="math notranslate nohighlight">\(\mathbf{W}\)</span> are used each step, gradients during training will propagate through time.</p>
</section>
<section id="unrolled-rnn-in-time">
<h2>Unrolled RNN in Time<a class="headerlink" href="#unrolled-rnn-in-time" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Input <span class="math notranslate nohighlight">\(x_1,x_2,x_3,\dots\)</span> feed sequentially; the hidden state flows from one step to the next, capturing past context.</p></li>
<li><p>After processing the final input <span class="math notranslate nohighlight">\(x_T\)</span>, the network can make a prediction (many-to-one) or outputs can be produced at each step (many-to-many).</p></li>
<li><p>Unrolling clarifies that training an RNN is like training a deep feedforward network of depth T, with recurrent connections tying layers together.</p></li>
</ol>
</section>
<section id="example-task-character-level-rnn-classification">
<h2>Example Task: Character-level RNN Classification<a class="headerlink" href="#example-task-character-level-rnn-classification" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>A classic example: feed a name (sequence of characters) one char at a time, and classify its language of origin.</p></li>
<li><p>At each step, the RNN outputs a hidden state; we use the final hidden state to predict the class of the entire sequence.</p></li>
<li><p>A character-level RNN reads words as a series of characters—outputting a prediction and ‘hidden state’ at each step, feeding the previous hidden state into the next step. We take the final prediction to be the output” ￼.</p></li>
<li><p>This illustrates sequence-to-one modeling: every output depends on all previous inputs.</p></li>
</ol>
</section>
<section id="pytorch-defining-a-simple-rnn-using-tensorflow">
<h2>PyTorch: Defining a Simple RNN, using Tensorflow<a class="headerlink" href="#pytorch-defining-a-simple-rnn-using-tensorflow" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import tensorflow as tf
import numpy as np

# -----------------------
# 1. Hyperparameters
# -----------------------
input_size = 10        # Dimensionality of each time step
hidden_size = 20       # Number of recurrent units
num_classes = 2        # Binary classification
sequence_length = 5     # Sequence length
batch_size = 16

# -----------------------
# 2. Dummy dataset
#    X: [batch, seq, features]
#    y: [batch]
# -----------------------
X = np.random.randn(batch_size, sequence_length, input_size).astype(np.float32)
y = np.random.randint(0, num_classes, size=(batch_size,))

# -----------------------
# 3. Build simple RNN model
# -----------------------
model = tf.keras.Sequential([
    tf.keras.layers.SimpleRNN(
        units=hidden_size,
        activation=&quot;tanh&quot;,
        return_sequences=False,   # Only final hidden state
        input_shape=(sequence_length, input_size)
    ),
    tf.keras.layers.Dense(num_classes)
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-3),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=[&quot;accuracy&quot;]
)

# -----------------------
# 4. Train the model
# -----------------------
history = model.fit(
    X, y,
    epochs=5,
    batch_size=batch_size,
    verbose=1
)

# -----------------------
# 5. Evaluate
# -----------------------
logits = model.predict(X)
print(&quot;Logits from model:\n&quot;, logits)
</pre></div>
</div>
</div>
</div>
<p>This recurrent neural network uses the TensorFlow/Keras SimpleRNN, which is the counterpart to PyTorch’s nn.RNN.
In this code we have used</p>
<ol class="arabic simple">
<li><p>sequence<span class="math notranslate nohighlight">\(\_\)</span>length is the number of time steps in each input sequence fed into a recurrent neural network. It represents how many time points we provide at once. It is the number of ordered observations in each sample of our dataset.</p></li>
<li><p>return_sequences=False makes it output only the last hidden state, which is fed to the classifier. Also, we have</p></li>
<li><p>from_logits=True matches the PyTorch CrossEntropyLoss.</p></li>
</ol>
</section>
<section id="similar-example-using-pytorch">
<h2>Similar example using PyTorch<a class="headerlink" href="#similar-example-using-pytorch" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import torch
import torch.nn as nn
import torch.optim as optim

# -----------------------
# 1. Hyperparameters
# -----------------------
input_size = 10
hidden_size = 20
num_layers = 1
num_classes = 2
sequence_length = 5
batch_size = 16
lr = 1e-3

# -----------------------
# 2. Dummy dataset
# -----------------------
X = torch.randn(batch_size, sequence_length, input_size)
y = torch.randint(0, num_classes, (batch_size,))

# -----------------------
# 3. Simple RNN model
# -----------------------
class SimpleRNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):
        super(SimpleRNN, self).__init__()
        self.rnn = nn.RNN(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            nonlinearity=&quot;tanh&quot;
        )
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        out, h_n = self.rnn(x)   # out: [batch, seq, hidden]

        # ---- FIX: take only the last time-step tensor ----
        last_hidden = out[:, -1, :]  # [batch, hidden]

        logits = self.fc(last_hidden)
        return logits

model = SimpleRNN(input_size, hidden_size, num_layers, num_classes)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=lr)

# -----------------------
# 4. Training step
# -----------------------
model.train()
optimizer.zero_grad()

logits = model(X)
loss = criterion(logits, y)
loss.backward()
optimizer.step()

print(f&quot;Loss: {loss.item():.4f}&quot;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="backpropagation-through-time-bptt-and-gradients">
<h2>Backpropagation Through Time (BPTT) and Gradients<a class="headerlink" href="#backpropagation-through-time-bptt-and-gradients" title="Link to this heading">#</a></h2>
<p><strong>Backpropagation Through Time (BPTT).</strong></p>
<ol class="arabic simple">
<li><p>Training an RNN involves computing gradients through time by unfolding the network: treat the unrolled RNN as a very deep feedforward net.</p></li>
<li><p>We compute the loss <span class="math notranslate nohighlight">\(L = \frac{1}{T}\sum_{t=1}^T \ell(y_t,\hat y_t)\)</span> and backpropagate from <span class="math notranslate nohighlight">\(t=T\)</span> down to <span class="math notranslate nohighlight">\(t=1.\)</span></p></li>
<li><p>The computational graphs in the figures below shows how each hidden state depends on inputs and parameters across time ￼.</p></li>
<li><p>BPTT applies the chain rule along this graph, accumulating gradients from each time step into the shared parameters.</p></li>
</ol>
</section>
<section id="truncated-bptt-and-gradient-clipping">
<h2>Truncated BPTT and Gradient Clipping<a class="headerlink" href="#truncated-bptt-and-gradient-clipping" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Truncated BPTT: Instead of backpropagating through all T steps, we may backpropagate through a fixed window of length <span class="math notranslate nohighlight">\(\tau\)</span>. This approximates the full gradient and reduces computation.</p></li>
<li><p>Concretely, one computes gradients up to <span class="math notranslate nohighlight">\(\tau\)</span> steps and treats gradients beyond as zero. This still allows learning short-term patterns efficiently.</p></li>
<li><p>Gradient Clipping: Cap the gradient norm to a maximum value to prevent explosion. For example in PyTorch: torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) ensures <span class="math notranslate nohighlight">\(\|\nabla\|\le 1\)</span>.</p></li>
<li><p>These techniques help stabilize training, but the fundamental vanishing problem motivates using alternative RNN cells (LSTM/GRU) in practice (see below).</p></li>
</ol>
</section>
<section id="limitations-and-considerations">
<h2>Limitations and Considerations<a class="headerlink" href="#limitations-and-considerations" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Vanishing Gradients: Simple RNNs have fundamental difficulty learning long-term dependencies due to gradient decay ￼.</p></li>
<li><p>Capacity: Without gates, RNNs may struggle with tasks requiring remembering far-back inputs. Training can be slow as it’s inherently sequential.</p></li>
<li><p>Alternatives: In practice, gated RNNs (LSTM/GRU) or Transformers are often used for long-range dependencies. However, simple RNNs are still instructive and sometimes sufficient for short sequences ￼ ￼.</p></li>
<li><p>Regularization: Weight decay or dropout (on inputs/states) can help generalization but must be applied carefully due to temporal correlations.</p></li>
<li><p>Statefulness: For very long sequences, one can preserve hidden state across batches (stateful RNN) to avoid resetting memory.</p></li>
</ol>
</section>
<section id="pytorch-rnn-time-series-example">
<h2>PyTorch RNN Time Series Example<a class="headerlink" href="#pytorch-rnn-time-series-example" title="Link to this heading">#</a></h2>
<p>We first implement a simple RNN in PyTorch to forecast a univariate
time series (a sine wave). The steps are: (1) generate synthetic data
and form input/output sequences; (2) define an nn.RNN model; (3) train
the model with MSE loss and an optimizer; (4) evaluate on a held-out
test set. For example, using a sine wave as in prior tutorials ￼, we
create sliding windows of length seq_length. The code below shows each
step. We use nn.RNN (the basic recurrent layer) followed by a linear
output. The training loop (with MSELoss and Adam) updates the model to
minimize prediction error ￼.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import numpy as np
import torch
from torch import nn, optim

# 1. Data preparation: generate a sine wave and create input-output sequences
time_steps = np.linspace(0, 100, 500)
data = np.sin(time_steps)                   # shape (500,)
seq_length = 20
X, y = [], []
for i in range(len(data) - seq_length):
    X.append(data[i:i+seq_length])         # sequence of length seq_length
    y.append(data[i+seq_length])           # next value to predict
X = np.array(X)                            # shape (480, seq_length)
y = np.array(y)                            # shape (480,)
# Add feature dimension (1) for the RNN input
X = X[..., None]                           # shape (480, seq_length, 1)
y = y[..., None]                           # shape (480, 1)

# Split into train/test sets (80/20 split)
train_size = int(0.8 * len(X))
X_train = torch.tensor(X[:train_size], dtype=torch.float32)
y_train = torch.tensor(y[:train_size], dtype=torch.float32)
X_test  = torch.tensor(X[train_size:],  dtype=torch.float32)
y_test  = torch.tensor(y[train_size:],  dtype=torch.float32)

# 2. Model definition: simple RNN followed by a linear layer
class SimpleRNNModel(nn.Module):
    def __init__(self, input_size=1, hidden_size=16, num_layers=1):
        super(SimpleRNNModel, self).__init__()
        # nn.RNN for sequential data (batch_first=True expects (batch, seq_len, features))
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)    # output layer for prediction

    def forward(self, x):
        out, _ = self.rnn(x)                 # out: (batch, seq_len, hidden_size)
        out = out[:, -1, :]                  # take output of last time step
        return self.fc(out)                 # linear layer to 1D output

model = SimpleRNNModel(input_size=1, hidden_size=16, num_layers=1)
print(model)  # print model summary (structure)
</pre></div>
</div>
</div>
</div>
<p>Model Explanation: Here input<span class="math notranslate nohighlight">\(\_\)</span>size=1 because each time step has one
feature. The RNN hidden state has size 16, and batch<span class="math notranslate nohighlight">\(\_\)</span>first=True means
input tensors have shape (batch, seq<span class="math notranslate nohighlight">\(\_\)</span>len, features). We take the last
RNN output and feed it through a linear layer to predict the next
value .</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># 3. Training loop: MSE loss and Adam optimizer
criterion = nn.MSELoss()                  # mean squared error loss
optimizer = optim.Adam(model.parameters(), lr=0.01)

epochs = 50
for epoch in range(1, epochs+1):
    model.train()
    optimizer.zero_grad()
    output = model(X_train)               # forward pass
    loss = criterion(output, y_train)     # compute training loss
    loss.backward()                       # backpropagate
    optimizer.step()                      # update weights
    if epoch % 10 == 0:
        print(f&#39;Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}&#39;)
</pre></div>
</div>
</div>
</div>
<p>Training Details: We train for 50 epochs, printing the training loss
every 10 epochs. As training proceeds, the loss (MSE) typically
decreases, indicating the RNN is learning the sine-wave pattern ￼.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># 4. Evaluation on test set
model.eval()
with torch.no_grad():
    pred = model(X_test)
    test_loss = criterion(pred, y_test)
print(f&#39;Test Loss: {test_loss.item():.4f}&#39;)

# (Optional) View a few actual vs. predicted values
print(&quot;Actual:&quot;, y_test[:5].flatten().numpy())
print(&quot;Pred : &quot;, pred[:5].flatten().numpy())
</pre></div>
</div>
</div>
</div>
<p>Evaluation: We switch to eval mode and compute loss on the test
set. The lower test loss indicates how well the model generalizes. The
code prints a few sample predictions against actual values for
qualitative assessment.</p>
</section>
<section id="tensorflow-keras-rnn-time-series-example">
<h2>Tensorflow (Keras) RNN Time Series Example<a class="headerlink" href="#tensorflow-keras-rnn-time-series-example" title="Link to this heading">#</a></h2>
<p>Next, we use TensorFlow/Keras to do the same task. We build a
tf.keras.Sequential model with a SimpleRNN layer (the most basic
recurrent layer) ￼ followed by a Dense output. The workflow is
similar: create the same synthetic sine data and split it into
train/test sets; then define, train, and evaluate the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import numpy as np
import tensorflow as tf

# 1. Data preparation: same sine wave data and sequences as above
time_steps = np.linspace(0, 100, 500)
data = np.sin(time_steps)                     # (500,)
seq_length = 20
X, y = [], []
for i in range(len(data) - seq_length):
    X.append(data[i:i+seq_length])
    y.append(data[i+seq_length])
X = np.array(X)                               # (480, seq_length)
y = np.array(y)                               # (480,)
# reshape for RNN: (samples, timesteps, features)
X = X.reshape(-1, seq_length, 1)             # (480, 20, 1)
y = y.reshape(-1, 1)                         # (480, 1)

# Split into train/test (80/20)
split = int(0.8 * len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]
</pre></div>
</div>
</div>
</div>
<p>Data: We use the same sine-wave sequence and sliding-window split as
in the PyTorch example ￼. The arrays are reshaped to (batch,
timesteps, features) for Keras.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># 2. Model definition: Keras SimpleRNN and Dense
model = tf.keras.Sequential([
    tf.keras.layers.SimpleRNN(16, input_shape=(seq_length, 1)),
    tf.keras.layers.Dense(1)
])
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;)   # MSE loss and Adam optimizer
model.summary()
</pre></div>
</div>
</div>
</div>
<p>Explanation: Here SimpleRNN(16) creates 16 recurrent units. The model
summary shows the shapes and number of parameters. (Keras handles the
sequence dimension internally.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># 3. Training
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.2,    # use 20% of train data for validation
    verbose=1
)
</pre></div>
</div>
</div>
</div>
<p>Training: We train for 50 epochs. The fit call also reports validation
loss (using a 20<span class="math notranslate nohighlight">\(%\)</span> split of the training data) to monitor
generalization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># 4. Evaluation on test set
test_loss = model.evaluate(X_test, y_test, verbose=0)
print(f&#39;Test Loss: {test_loss:.4f}&#39;)

# (Optional) Predictions
predictions = model.predict(X_test)
print(&quot;Actual:&quot;, y_test.flatten()[:5])
print(&quot;Pred : &quot;, predictions.flatten()[:5])
</pre></div>
</div>
</div>
</div>
<p>Evaluation: After training, we call model.evaluate on the test set. A
low test loss indicates good forecasting accuracy. We also predict and
compare a few samples of actual vs. predicted values. This completes
the simple RNN forecasting example in TensorFlow.</p>
<p>Both examples use only basic RNN cells (no LSTM/GRU) and include data
preparation, model definition, training loop, and evaluation. The
PyTorch code uses nn.RNN as and the Keras
code uses SimpleRNN layer. Each code block above is self-contained
and can be run independently with standard libraries (NumPy, PyTorch
or TensorFlow).</p>
</section>
<section id="the-mathematics-of-rnns-the-basic-architecture">
<h2>The mathematics of RNNs, the basic architecture<a class="headerlink" href="#the-mathematics-of-rnns-the-basic-architecture" title="Link to this heading">#</a></h2>
<p>See notebook at <a class="github reference external" href="https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/week7/ipynb/rnnmath.ipynb">CompPhysics/AdvancedMachineLearning</a></p>
</section>
<section id="gating-mechanism-long-short-term-memory-lstm">
<h2>Gating mechanism: Long Short Term Memory (LSTM)<a class="headerlink" href="#gating-mechanism-long-short-term-memory-lstm" title="Link to this heading">#</a></h2>
<p>Besides a simple recurrent neural network layer, as discussed above, there are two other
commonly used types of recurrent neural network layers: Long Short
Term Memory (LSTM) and Gated Recurrent Unit (GRU).  For a short
introduction to these layers see <a class="reference external" href="https://medium.com/mindboard/lstm-vs-gru-experimental-comparison-955820c21e8b">https://medium.com/mindboard/lstm-vs-gru-experimental-comparison-955820c21e8b</a>
and <a class="reference external" href="https://medium.com/mindboard/lstm-vs-gru-experimental-comparison-955820c21e8b">https://medium.com/mindboard/lstm-vs-gru-experimental-comparison-955820c21e8b</a>.</p>
<p>LSTM uses a memory cell for
modeling long-range dependencies and avoid vanishing gradient
problems.
Capable of modeling longer term dependencies by having
memory cells and gates that controls the information flow along
with the memory cells.</p>
<ol class="arabic simple">
<li><p>Introduced by Hochreiter and Schmidhuber (1997) who solved the problem of getting an RNN to remember things for a long time (like hundreds of time steps).</p></li>
<li><p>They designed a memory cell using logistic and linear units with multiplicative interactions.</p></li>
<li><p>Information gets into the cell whenever its “write” gate is on.</p></li>
<li><p>The information stays in the cell so long as its <strong>keep</strong> gate is on.</p></li>
<li><p>Information can be read from the cell by turning on its <strong>read</strong> gate.</p></li>
</ol>
<p>The LSTM were first introduced to overcome the vanishing gradient problem.</p>
</section>
<section id="implementing-a-memory-cell-in-a-neural-network">
<h2>Implementing a memory cell in a neural network<a class="headerlink" href="#implementing-a-memory-cell-in-a-neural-network" title="Link to this heading">#</a></h2>
<p>To preserve information for a long time in
the activities of an RNN, we use a circuit
that implements an analog memory cell.</p>
<ol class="arabic simple">
<li><p>A linear unit that has a self-link with a weight of 1 will maintain its state.</p></li>
<li><p>Information is stored in the cell by activating its write gate.</p></li>
<li><p>Information is retrieved by activating the read gate.</p></li>
<li><p>We can backpropagate through this circuit because logistics are have nice derivatives.</p></li>
</ol>
</section>
<section id="lstm-details">
<h2>LSTM details<a class="headerlink" href="#lstm-details" title="Link to this heading">#</a></h2>
<p>The LSTM is a unit cell that is made of three gates:</p>
<ol class="arabic simple">
<li><p>the input gate,</p></li>
<li><p>the forget gate,</p></li>
<li><p>and the output gate.</p></li>
</ol>
<p>It also introduces a cell state <span class="math notranslate nohighlight">\(c\)</span>, which can be thought of as the
long-term memory, and a hidden state <span class="math notranslate nohighlight">\(h\)</span> which can be thought of as
the short-term memory.</p>
</section>
<section id="lstm-cell-and-gates">
<h2>LSTM Cell and Gates<a class="headerlink" href="#lstm-cell-and-gates" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Each LSTM cell contains a memory cell <span class="math notranslate nohighlight">\(C_t\)</span> and three gates (forget <span class="math notranslate nohighlight">\(f_t\)</span>, input <span class="math notranslate nohighlight">\(i_t\)</span>, output <span class="math notranslate nohighlight">\(o_t\)</span>) that control information flow.</p></li>
<li><p><strong>Forget gate</strong> (<span class="math notranslate nohighlight">\(f_t\)</span>): chooses which information to erase from the previous cell state <span class="math notranslate nohighlight">\(C_{t-1}\)</span></p></li>
<li><p><strong>Input gate</strong> (<span class="math notranslate nohighlight">\(i_t\)</span>): decides which new information <span class="math notranslate nohighlight">\(\tilde{C}_t\)</span> to add to the cell state.</p></li>
<li><p><strong>Output gate</strong> (<span class="math notranslate nohighlight">\(o_t\)</span>): controls which parts of the cell state become the output <span class="math notranslate nohighlight">\(h_t\)</span>.</p></li>
<li><p>The cell state update: <span class="math notranslate nohighlight">\(C_t = f_t \odot C_{t-1} + i_t \odot \tilde{C}_t\)</span></p></li>
</ol>
</section>
<section id="core-lstm-equations">
<h2>Core LSTM Equations<a class="headerlink" href="#core-lstm-equations" title="Link to this heading">#</a></h2>
<p><strong>The gate computations and state updates are given by:</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    f_t &amp;= \sigma(W_f [h_{t-1}, x_t] + b_f), \\
    i_t &amp;= \sigma(W_i [h_{t-1}, x_t] + b_i), \\
    \tilde{C}_t &amp;= \tanh(W_C [h_{t-1}, x_t] + b_C), \\
    C_t &amp;= f_t \odot C_{t-1} + i_t \odot \tilde{C}_t, \\
    o_t &amp;= \sigma(W_o [h_{t-1}, x_t] + b_o), \\
    h_t &amp;= o_t \odot \tanh(C_t).
  \end{align*}
\end{split}\]</div>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\sigma\)</span> is the sigmoid function, <span class="math notranslate nohighlight">\(\odot\)</span> is elementwise product <a class="reference external" href="https://jaketae.github.io/study/dissecting-lstm/#:~:text=%5C%5B%5Cbegin,align">oai_citation:4‡jaketae.github.io</a>.</p></li>
<li><p>These equations define how LSTM retains/updates memory and produces outputs.</p></li>
</ol>
</section>
<section id="gate-intuition-and-dynamics">
<h2>Gate Intuition and Dynamics<a class="headerlink" href="#gate-intuition-and-dynamics" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Forget gate <span class="math notranslate nohighlight">\(f_t\)</span> acts as a soft “erase” signal: <span class="math notranslate nohighlight">\(f_t \approx 0\)</span> forgets, <span class="math notranslate nohighlight">\(f_t \approx 1\)</span> retains previous memory.</p></li>
<li><p>Input gate <span class="math notranslate nohighlight">\(i_t\)</span> scales how much new candidate memory <span class="math notranslate nohighlight">\(\tilde{C}_t\)</span> is written.</p></li>
<li><p>Output gate <span class="math notranslate nohighlight">\(o_t\)</span> determines how much of the cell’s memory flows into the hidden state <span class="math notranslate nohighlight">\(h_t\)</span>.</p></li>
<li><p>By controlling these gates, LSTM effectively keeps long-term information when needed.</p></li>
</ol>
</section>
<section id="basic-layout-all-figures-from-raschka-et-al">
<h2>Basic layout (All figures from Raschka <em>et al.,</em>)<a class="headerlink" href="#basic-layout-all-figures-from-raschka-et-al" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/LSTM1.png, width=700 frac=1.0] -->
<!-- begin figure -->
<p><img src="figslides/LSTM1.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="id1">
<h2>LSTM details<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>The first stage is called the forget gate, where we combine the input
at (say, time <span class="math notranslate nohighlight">\(t\)</span>), and the hidden cell state input at <span class="math notranslate nohighlight">\(t-1\)</span>, passing
it through the Sigmoid activation function and then performing an
element-wise multiplication, denoted by <span class="math notranslate nohighlight">\(\odot\)</span>.</p>
<p>Mathematically we have (see also figure below)</p>
<div class="math notranslate nohighlight">
\[
\mathbf{f}^{(t)} = \sigma(W_{fx}\mathbf{x}^{(t)} + W_{fh}\mathbf{h}^{(t-1)} + \mathbf{b}_f)
\]</div>
<p>where the <span class="math notranslate nohighlight">\(W\)</span>s are the weights to be trained.</p>
</section>
<section id="comparing-with-a-standard-rnn">
<h2>Comparing with a standard  RNN<a class="headerlink" href="#comparing-with-a-standard-rnn" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/LSTM2.png, width=700 frac=1.0] -->
<!-- begin figure -->
<p><img src="figslides/LSTM2.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="lstm-details-i">
<h2>LSTM details I<a class="headerlink" href="#lstm-details-i" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/LSTM3.png, width=700 frac=1.0] -->
<!-- begin figure -->
<p><img src="figslides/LSTM3.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="lstm-details-ii">
<h2>LSTM details II<a class="headerlink" href="#lstm-details-ii" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/LSTM4.png, width=700 frac=1.0] -->
<!-- begin figure -->
<p><img src="figslides/LSTM4.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="lstm-details-iii">
<h2>LSTM details III<a class="headerlink" href="#lstm-details-iii" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/LSTM5.png, width=700 frac=1.0] -->
<!-- begin figure -->
<p><img src="figslides/LSTM5.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="forget-gate">
<h2>Forget gate<a class="headerlink" href="#forget-gate" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/LSTM6.png, width=700 frac=1.0] -->
<!-- begin figure -->
<p><img src="figslides/LSTM6.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="the-forget-gate">
<h2>The forget gate<a class="headerlink" href="#the-forget-gate" title="Link to this heading">#</a></h2>
<p>The naming forget gate stems from the fact that  the Sigmoid activation function’s
outputs are very close to <span class="math notranslate nohighlight">\(0\)</span> if the argument for the function is very
negative, and <span class="math notranslate nohighlight">\(1\)</span> if the argument is very positive. Hence we can
control the amount of information we want to take from the long-term
memory.</p>
<div class="math notranslate nohighlight">
\[
\mathbf{f}^{(t)} = \sigma(W_{fx}\mathbf{x}^{(t)} + W_{fh}\mathbf{h}^{(t-1)} + \mathbf{b}_f)
\]</div>
<p>where the <span class="math notranslate nohighlight">\(W\)</span>s are the weights to be trained.</p>
</section>
<section id="basic-layout">
<h2>Basic layout<a class="headerlink" href="#basic-layout" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/LSTM7.png, width=700 frac=1.0] -->
<!-- begin figure -->
<p><img src="figslides/LSTM7.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="input-gate">
<h2>Input gate<a class="headerlink" href="#input-gate" title="Link to this heading">#</a></h2>
<p>The next stage is the input gate, which consists of both a Sigmoid
function (<span class="math notranslate nohighlight">\(\sigma_i\)</span>), which decide what percentage of the input will
be stored in the long-term memory, and the <span class="math notranslate nohighlight">\(\tanh_i\)</span> function, which
decide what is the full memory that can be stored in the long term
memory. When these results are calculated and multiplied together, it
is added to the cell state or stored in the long-term memory, denoted
as <span class="math notranslate nohighlight">\(\oplus\)</span>.</p>
<p>We have</p>
<div class="math notranslate nohighlight">
\[
\mathbf{i}^{(t)} = \sigma_g(W_{ix}\mathbf{x}^{(t)} + W_{ih}\mathbf{h}^{(t-1)} + \mathbf{b}_i),
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
\mathbf{g}^{(t)} = \tanh(W_{gx}\mathbf{x}^{(t)} + W_{gh}\mathbf{h}^{(t-1)} + \mathbf{b}_g),
\]</div>
<p>again the <span class="math notranslate nohighlight">\(W\)</span>s are the weights to train.</p>
</section>
<section id="short-summary">
<h2>Short summary<a class="headerlink" href="#short-summary" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/LSTM8.png, width=700 frac=1.0] -->
<!-- begin figure -->
<p><img src="figslides/LSTM8.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="forget-and-input">
<h2>Forget and input<a class="headerlink" href="#forget-and-input" title="Link to this heading">#</a></h2>
<p>The forget gate and the input gate together also update the cell state with the following equation,</p>
<div class="math notranslate nohighlight">
\[
\mathbf{c}^{(t)} = \mathbf{f}^{(t)} \otimes \mathbf{c}^{(t-1)} + \mathbf{i}^{(t)} \otimes \mathbf{g}^{(t)},
\]</div>
<p>where <span class="math notranslate nohighlight">\(f^{(t)}\)</span> and <span class="math notranslate nohighlight">\(i^{(t)}\)</span> are the outputs of the forget gate and the input gate, respectively.</p>
</section>
<section id="id2">
<h2>Basic layout<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figslides/LSTM9.png, width=700 frac=1.0] -->
<!-- begin figure -->
<p><img src="figslides/LSTM9.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="output-gate">
<h2>Output gate<a class="headerlink" href="#output-gate" title="Link to this heading">#</a></h2>
<p>The final stage of the LSTM is the output gate, and its purpose is to
update the short-term memory.  To achieve this, we take the newly
generated long-term memory and process it through a hyperbolic tangent
(<span class="math notranslate nohighlight">\(\tanh\)</span>) function creating a potential new short-term memory. We then
multiply this potential memory by the output of the Sigmoid function
(<span class="math notranslate nohighlight">\(\sigma_o\)</span>). This multiplication generates the final output as well
as the input for the next hidden cell (<span class="math notranslate nohighlight">\(h^{\langle t \rangle}\)</span>) within
the LSTM cell.</p>
<p>We have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbf{o}^{(t)} &amp;= \sigma_g(W_o\mathbf{x}^{(t)} + U_o\mathbf{h}^{(t-1)} + \mathbf{b}_o), \\
\mathbf{h}^{(t)} &amp;= \mathbf{o}^{(t)} \otimes \sigma_h(\mathbf{c}^{(t)}). \\
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{W_o,U_o}\)</span> are the weights of the output gate and <span class="math notranslate nohighlight">\(\mathbf{b_o}\)</span> is the bias of the output gate.</p>
</section>
<section id="lstm-implementation-code-example">
<h2>LSTM Implementation (Code Example)<a class="headerlink" href="#lstm-implementation-code-example" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Using high-level libraries (Keras, PyTorch) simplifies LSTM usage.</p></li>
<li><p>define and train a Keras LSTM on a univariate time series:</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# X_train shape: (samples, timesteps, 1)
model = Sequential([
    LSTM(32, input_shape=(None, 1)),
    Dense(1)
])
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;)
model.fit(X_train, y_train, epochs=20, batch_size=16)
</pre></div>
</div>
</div>
</div>
<p>The model learns to map sequences to outputs; input sequences can be constructed via sliding windows.</p>
</section>
<section id="example-modeling-dynamical-systems">
<h2>Example: Modeling Dynamical Systems<a class="headerlink" href="#example-modeling-dynamical-systems" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>LSTMs can learn complex time evolution of physical systems (e.g. Lorenz attractor, fluid dynamics) from data.</p></li>
<li><p>Serve as data-driven surrogates for ODE/PDE solvers (trained on RK4-generated time series).</p></li>
<li><p>For example, an LSTM surrogate accurately forecast 36h lake hydrodynamics (velocity, temperature) with <span class="math notranslate nohighlight">\(&lt;6\%\)</span> error.</p></li>
<li><p>Such models dramatically speed up predictions compared to full numerical simulation.</p></li>
</ol>
</section>
<section id="example-biological-sequences">
<h2>Example: Biological Sequences<a class="headerlink" href="#example-biological-sequences" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Biological sequences (DNA/RNA/proteins) are effectively categorical time series.</p></li>
<li><p>LSTMs capture sequence motifs and long-range dependencies (akin to language models).</p></li>
<li><p>Widely used in genomics and proteomics (e.g., protein function, gene expression).</p></li>
<li><p>They naturally handle variable-length input by processing one element at a time.</p></li>
</ol>
</section>
<section id="training-tips-and-variants">
<h2>Training Tips and Variants<a class="headerlink" href="#training-tips-and-variants" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Preprocess time series (normalize features, windowing); handle variable lengths (padding/truncation).</p></li>
<li><p>Experiment with network depth, hidden units, and regularization (dropout) to avoid overfitting.</p></li>
<li><p>Consider bidirectional LSTM or stacking multiple LSTM layers for complex patterns.</p></li>
<li><p>GRU is a simpler gated RNN that combines forget/input gates into one update gate.</p></li>
<li><p>Monitor gradients during training; use gradient clipping to stabilize learning if needed.</p></li>
</ol>
</section>
<section id="lstm-summary">
<h2>LSTM Summary<a class="headerlink" href="#lstm-summary" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>LSTMs extend RNNs with gated cells to remember long-term context, addressing RNN gradient issues.</p></li>
<li><p>Core update: <span class="math notranslate nohighlight">\(C_t = f_t \odot C_{t-1} + i_t \odot \tilde{C}_t\)</span>, output <span class="math notranslate nohighlight">\(h_t = o_t \odot \tanh(C_t)\)</span>.</p></li>
<li><p>Implementation is straightforward in libraries like Keras/PyTorch with few lines of code.</p></li>
<li><p>Applications span science and engineering: forecasting dynamical systems, analyzing DNA/proteins, etc.</p></li>
<li><p>For more details, see Goodfellow et al. (2016) Deep Learning, chapter 14</p></li>
</ol>
</section>
<section id="summary-of-lstm">
<h2>Summary of LSTM<a class="headerlink" href="#summary-of-lstm" title="Link to this heading">#</a></h2>
<p>LSTMs provide a basic approach for modeling long-range dependencies in sequences.
If you wish to read more, see <strong>An Empirical Exploration of Recurrent Network Architectures</strong>, authored
by Rafal Jozefowicz <em>et al.,</em>  Proceedings of ICML, 2342-2350, 2015).</p>
<p>An important recent development are the so-called <strong>gated recurrent units (GRU)</strong>, see for example the article
by Junyoung Chung <em>et al.,</em>, at URL:”<a class="reference external" href="https://arxiv.org/abs/1412.3555">https://arxiv.org/abs/1412.3555</a>.
This article is an excellent read if you are interested in learning
more about these modern RNN architectures</p>
<p>The GRUs have a simpler
architecture than LSTMs. This leads to computationally more efficient methods, while their
performance in some tasks, such as polyphonic music modeling, is comparable to LSTMs.</p>
</section>
<section id="lstm-implementation-using-tensorflow">
<h2>LSTM implementation using TensorFlow<a class="headerlink" href="#lstm-implementation-using-tensorflow" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;&quot;&quot;
Key points:
1. The input images (28x28 pixels) are treated as sequences of 28 timesteps with 28 features each
2. The LSTM layer processes this sequential data
3. A final dense layer with softmax activation handles the classification
4. Typical accuracy ranges between 95-98% (lower than CNNs but reasonable for demonstration)

Note: LSTMs are not typically used for image classification (CNNs are more efficient), but this demonstrates how to adapt them for such tasks. Training might take longer compared to CNN architectures.

To improve performance, you could:
1. Add more LSTM layers
2. Use Bidirectional LSTMs
3. Increase the number of units
4. Add dropout for regularization
5. Use learning rate scheduling
&quot;&quot;&quot;

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.utils import to_categorical

# Load and preprocess data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Normalize pixel values to [0, 1]
x_train = x_train.astype(&#39;float32&#39;) / 255.0
x_test = x_test.astype(&#39;float32&#39;) / 255.0

# Reshape data for LSTM (samples, timesteps, features)
# MNIST images are 28x28, so we treat each image as 28 timesteps of 28 features
x_train = x_train.reshape((-1, 28, 28))
x_test = x_test.reshape((-1, 28, 28))

# Convert labels to one-hot encoding
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Build LSTM model
model = Sequential()
model.add(LSTM(128, input_shape=(28, 28)))  # 128 LSTM units
model.add(Dense(10, activation=&#39;softmax&#39;))

# Compile the model
model.compile(loss=&#39;categorical_crossentropy&#39;,
             optimizer=&#39;adam&#39;,
             metrics=[&#39;accuracy&#39;])

# Display model summary
model.summary()

# Train the model
history = model.fit(x_train, y_train,
                   batch_size=64,
                   epochs=10,
                   validation_split=0.2)

# Evaluate on test data
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f&#39;\nTest accuracy: {test_acc:.4f}&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="and-the-corresponding-one-with-pytorch">
<h2>And the corresponding one with PyTorch<a class="headerlink" href="#and-the-corresponding-one-with-pytorch" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;&quot;&quot;
Key components:
1. **Data Handling**: Uses PyTorch DataLoader with MNIST dataset
2. **LSTM Architecture**:
  - Input sequence of 28 timesteps (image rows)
  - 128 hidden units in LSTM layer
  - Fully connected layer for classification
3. **Training**:
  - Cross-entropy loss
  - Adam optimizer
  - Automatic GPU utilization if available

This implementation typically achieves **97-98% accuracy** after 10 epochs. The main differences from the TensorFlow/Keras version:
- Explicit device management (CPU/GPU)
- Manual training loop
- Different data loading pipeline
- More explicit tensor reshaping

To improve performance, you could:
1. Add dropout regularization
2. Use bidirectional LSTM
3. Implement learning rate scheduling
4. Add batch normalization
5. Increase model capacity (more layers/units)
&quot;&quot;&quot;

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Hyperparameters
input_size = 28     # Number of features (pixels per row)
hidden_size = 128   # LSTM hidden state size
num_classes = 10    # Digits 0-9
num_epochs = 10     # Training iterations
batch_size = 64     # Batch size
learning_rate = 0.001

# Device configuration
device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)

# MNIST dataset
transform = transforms.Compose([
   transforms.ToTensor(),
   transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std
])

train_dataset = datasets.MNIST(root=&#39;./data&#39;,
                              train=True,
                              transform=transform,
                              download=True)

test_dataset = datasets.MNIST(root=&#39;./data&#39;,
                             train=False,
                             transform=transform)

train_loader = DataLoader(dataset=train_dataset,
                         batch_size=batch_size,
                         shuffle=True)

test_loader = DataLoader(dataset=test_dataset,
                        batch_size=batch_size,
                        shuffle=False)

# LSTM model
class LSTMModel(nn.Module):
   def __init__(self, input_size, hidden_size, num_classes):
       super(LSTMModel, self).__init__()
       self.hidden_size = hidden_size
       self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
       self.fc = nn.Linear(hidden_size, num_classes)

   def forward(self, x):
       # Reshape input to (batch_size, sequence_length, input_size)
       x = x.reshape(-1, 28, 28)

       # Forward propagate LSTM
       out, _ = self.lstm(x)  # out: (batch_size, seq_length, hidden_size)

       # Decode the hidden state of the last time step
       out = out[:, -1, :]
       out = self.fc(out)
       return out

# Initialize model
model = LSTMModel(input_size, hidden_size, num_classes).to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Training loop
total_step = len(train_loader)
for epoch in range(num_epochs):
   model.train()
   for i, (images, labels) in enumerate(train_loader):
       images = images.to(device)
       labels = labels.to(device)

       # Forward pass
       outputs = model(images)
       loss = criterion(outputs, labels)

       # Backward and optimize
       optimizer.zero_grad()
       loss.backward()
       optimizer.step()

       if (i+1) % 100 == 0:
           print(f&#39;Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}&#39;)

   # Test the model
   model.eval()
   with torch.no_grad():
       correct = 0
       total = 0
       for images, labels in test_loader:
           images = images.to(device)
           labels = labels.to(device)
           outputs = model(images)
           _, predicted = torch.max(outputs.data, 1)
           total += labels.size(0)
           correct += (predicted == labels).sum().item()

       print(f&#39;Test Accuracy: {100 * correct / total:.2f}%&#39;)

print(&#39;Training finished.&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="dynamical-ordinary-differential-equation">
<h2>Dynamical ordinary differential equation<a class="headerlink" href="#dynamical-ordinary-differential-equation" title="Link to this heading">#</a></h2>
<p>Let us illustrate how we could train an RNN using data from the
solution of a well-known differential equation, namely Newton’s
equation for oscillatory motion for an object being forced into
harmonic oscillations by an applied external force.</p>
<p>We will start with the basic algorithm for solving this type of
equations using the Runge-Kutta-4 approach. The first code example is
a standalone differential equation solver. It yields positions and
velocities as function of time, starting with an initial time <span class="math notranslate nohighlight">\(t_0\)</span>
and ending with a final time.</p>
<p>The data the program produces will in turn be used to train an RNN for
a selected number of training data. With a trained RNN, we will then
use the network to make predictions for data not included in the
training. That is, we will train a model which should be able to
reproduce velocities and positions not included in training data.</p>
</section>
<section id="the-runge-kutta-4-code">
<h2>The Runge-Kutta-4 code<a class="headerlink" href="#the-runge-kutta-4-code" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>%matplotlib inline

import numpy as np
import pandas as pd
from math import *
import matplotlib.pyplot as plt
import os

# Where to save the figures and data files
PROJECT_ROOT_DIR = &quot;Results&quot;
FIGURE_ID = &quot;Results/FigureFiles&quot;
DATA_ID = &quot;DataFiles/&quot;

if not os.path.exists(PROJECT_ROOT_DIR):
    os.mkdir(PROJECT_ROOT_DIR)

if not os.path.exists(FIGURE_ID):
    os.makedirs(FIGURE_ID)

if not os.path.exists(DATA_ID):
    os.makedirs(DATA_ID)

def image_path(fig_id):
    return os.path.join(FIGURE_ID, fig_id)

def data_path(dat_id):
    return os.path.join(DATA_ID, dat_id)

def save_fig(fig_id):
    plt.savefig(image_path(fig_id) + &quot;.png&quot;, format=&#39;png&#39;)


def SpringForce(v,x,t):
#   note here that we have divided by mass and we return the acceleration
    return  -2*gamma*v-x+Ftilde*cos(t*Omegatilde)


def RK4(v,x,t,n,Force):
    for i in range(n-1):
# Setting up k1
        k1x = DeltaT*v[i]
        k1v = DeltaT*Force(v[i],x[i],t[i])
# Setting up k2
        vv = v[i]+k1v*0.5
        xx = x[i]+k1x*0.5
        k2x = DeltaT*vv
        k2v = DeltaT*Force(vv,xx,t[i]+DeltaT*0.5)
# Setting up k3
        vv = v[i]+k2v*0.5
        xx = x[i]+k2x*0.5
        k3x = DeltaT*vv
        k3v = DeltaT*Force(vv,xx,t[i]+DeltaT*0.5)
# Setting up k4
        vv = v[i]+k3v
        xx = x[i]+k3x
        k4x = DeltaT*vv
        k4v = DeltaT*Force(vv,xx,t[i]+DeltaT)
# Final result
        x[i+1] = x[i]+(k1x+2*k2x+2*k3x+k4x)/6.
        v[i+1] = v[i]+(k1v+2*k2v+2*k3v+k4v)/6.
        t[i+1] = t[i] + DeltaT


# Main part begins here

DeltaT = 0.001
#set up arrays 
tfinal = 20 # in dimensionless time
n = ceil(tfinal/DeltaT)
# set up arrays for t, v, and x
t = np.zeros(n)
v = np.zeros(n)
x = np.zeros(n)
# Initial conditions (can change to more than one dim)
x0 =  1.0 
v0 = 0.0
x[0] = x0
v[0] = v0
gamma = 0.2
Omegatilde = 0.5
Ftilde = 1.0
# Start integrating using Euler&#39;s method
# Note that we define the force function as a SpringForce
RK4(v,x,t,n,SpringForce)

# Plot position as function of time    
fig, ax = plt.subplots()
ax.set_ylabel(&#39;x[m]&#39;)
ax.set_xlabel(&#39;t[s]&#39;)
ax.plot(t, x)
fig.tight_layout()
save_fig(&quot;ForcedBlockRK4&quot;)
plt.show()
</pre></div>
</div>
</div>
</div>
</section>
<section id="using-the-above-data-to-train-an-rnn">
<h2>Using the above data to train an RNN<a class="headerlink" href="#using-the-above-data-to-train-an-rnn" title="Link to this heading">#</a></h2>
<p>In the code here we have reworked the previous example in order to
generate data that can be handled by recurrent neural networks in
order to train our model. The first code is written using Tensorflow/keras while the second example uses PyTorch.
In both cases we use the Runge Kutta to fourth order as a way to generate the data. We have implemented a simple RNN only.
We leave it as an exercise (possible path in project 3) to implement LSTMs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># train_rnn_from_rk4.py

import runpy
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import os

# ---------- Load RK4-generated data from your script ----------
# This runs rungekutta.py and collects its globals. It must populate &#39;t&#39; and &#39;x&#39; arrays.
g = runpy.run_path(&#39;rungekutta.py&#39;)

if not all(k in g for k in (&#39;t&#39;,&#39;x&#39;,&#39;v&#39;)):
    raise RuntimeError(&quot;rungekutta.py did not expose required variables &#39;t&#39;, &#39;x&#39;, &#39;v&#39; in its globals.&quot;)

t = np.array(g[&#39;t&#39;]).ravel()
x = np.array(g[&#39;x&#39;]).ravel()
v = np.array(g[&#39;v&#39;]).ravel()

print(&quot;Loaded shapes:&quot;, t.shape, x.shape, v.shape)

# Simple plot of the original trajectory
plt.figure(figsize=(8,3))
plt.plot(t, x)
plt.xlabel(&#39;t&#39;)
plt.ylabel(&#39;x&#39;)
plt.title(&#39;True trajectory from RK4&#39;)
plt.tight_layout()
plt.show()

# ---------- Prepare datasets ----------
def make_dataset(series, input_len):
    X, y = [], []
    N = len(series)
    for i in range(N - input_len):
        X.append(series[i:i+input_len])
        y.append(series[i+input_len])
    X = np.array(X).reshape(-1, input_len, 1)  # (samples, timesteps, 1)
    y = np.array(y).reshape(-1, 1)
    return X, y

# normalize using global mean/std
mean_x, std_x = x.mean(), x.std()
x_norm = (x - mean_x) / std_x

print(f&quot;Normalization: mean={mean_x:.6f}, std={std_x:.6f}&quot;)

# Model A: input_len = 1 (x_t -&gt; x_{t+1})
input_len_A = 1
X_A, y_A = make_dataset(x_norm, input_len_A)

# Model B: input_len = 10 (used for autoregressive generation)
input_len_B = 10
X_B, y_B = make_dataset(x_norm, input_len_B)

# train/test split
test_size = 0.2
random_seed = 42
Xa_train, Xa_test, ya_train, ya_test = train_test_split(X_A, y_A, test_size=test_size, random_state=random_seed)
Xb_train, Xb_test, yb_train, yb_test = train_test_split(X_B, y_B, test_size=test_size, random_state=random_seed)

print(&quot;Model A shapes:&quot;, Xa_train.shape, ya_train.shape, &quot;Model B shapes:&quot;, Xb_train.shape, yb_train.shape)

# ---------- Build models ----------
def build_simple_rnn(input_len, hidden_size=32):
    model = tf.keras.Sequential([
        tf.keras.Input(shape=(input_len,1)),
        tf.keras.layers.SimpleRNN(hidden_size, activation=&#39;tanh&#39;),
        tf.keras.layers.Dense(1)
    ])
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),
                  loss=&#39;mse&#39;,
                  metrics=[&#39;mse&#39;])
    return model

model_A = build_simple_rnn(input_len_A, hidden_size=32)
model_B = build_simple_rnn(input_len_B, hidden_size=64)

print(&quot;Model A summary:&quot;)
model_A.summary()
print(&quot;\nModel B summary:&quot;)
model_B.summary()

# ---------- Train ----------
epochs_A = 30
epochs_B = 40

hist_A = model_A.fit(Xa_train, ya_train, validation_data=(Xa_test, ya_test),
                     epochs=epochs_A, batch_size=32, verbose=1)

hist_B = model_B.fit(Xb_train, yb_train, validation_data=(Xb_test, yb_test),
                     epochs=epochs_B, batch_size=32, verbose=1)

# ---------- Plot training curves ----------
plt.figure(figsize=(10,3))
plt.subplot(1,2,1)
plt.plot(hist_A.history[&#39;loss&#39;], label=&#39;train&#39;)
plt.plot(hist_A.history[&#39;val_loss&#39;], label=&#39;val&#39;)
plt.title(&#39;Model A loss&#39;)
plt.xlabel(&#39;epoch&#39;); plt.ylabel(&#39;mse&#39;); plt.legend()

plt.subplot(1,2,2)
plt.plot(hist_B.history[&#39;loss&#39;], label=&#39;train&#39;)
plt.plot(hist_B.history[&#39;val_loss&#39;], label=&#39;val&#39;)
plt.title(&#39;Model B loss&#39;)
plt.xlabel(&#39;epoch&#39;); plt.ylabel(&#39;mse&#39;); plt.legend()

plt.tight_layout()
plt.show()

# ---------- Evaluate one-step predictions ----------
preds_A = model_A.predict(Xa_test)
preds_A_un = preds_A.flatten() * std_x + mean_x
ya_test_un = ya_test.flatten() * std_x + mean_x

print(&quot;Model A one-step MSE (unnormalized):&quot;, np.mean((preds_A_un - ya_test_un)**2))

plt.figure(figsize=(8,3))
nplot = min(100, len(ya_test_un))
plt.plot(ya_test_un[:nplot], label=&#39;true next x&#39;)
plt.plot(preds_A_un[:nplot], label=&#39;predicted next x (Model A)&#39;)
plt.title(&quot;Model A: one-step predictions (segment)&quot;)
plt.legend()
plt.show()

# ---------- Autoregressive generation using Model B ----------
# Start from the first input_len_B true values, then generate the remainder autoregressively
initial_window = x_norm[:input_len_B].reshape(1,input_len_B,1)
gen_steps = len(x_norm) - input_len_B
generated = []
current_window = initial_window.copy()

for i in range(gen_steps):
    pred_norm = model_B.predict(current_window, verbose=0)  # shape (1,1)
    generated.append(pred_norm.flatten()[0])
    # roll the window and append prediction
    current_window = np.concatenate([current_window[:,1:,:], pred_norm.reshape(1,1,1)], axis=1)

generated_un = np.array(generated) * std_x + mean_x
true_remainder = x[input_len_B:]

plt.figure(figsize=(8,3))
plt.plot(true_remainder, label=&#39;true remainder&#39;)
plt.plot(generated_un, label=&#39;generated (Model B)&#39;)
plt.title(&#39;Model B autoregressive generation&#39;)
plt.legend()
plt.show()

# ---------- Save models ----------
os.makedirs(&#39;saved_models&#39;, exist_ok=True)
path_A = os.path.join(&#39;saved_models&#39;,&#39;model_A_rnn.h5&#39;)
path_B = os.path.join(&#39;saved_models&#39;,&#39;model_B_rnn.h5&#39;)
model_A.save(path_A)
model_B.save(path_B)
print(&quot;Saved models to:&quot;, path_A, path_B)

# ---------- Final numeric summaries ----------
preds_B = model_B.predict(Xb_test)
preds_B_un = preds_B.flatten() * std_x + mean_x
yb_test_un = yb_test.flatten() * std_x + mean_x
mse_A = np.mean((preds_A_un - ya_test_un)**2)
mse_B = np.mean((preds_B_un - yb_test_un)**2)
print(f&quot;One-step MSE (Model A): {mse_A:.6e}&quot;)
print(f&quot;One-step MSE (Model B): {mse_B:.6e}&quot;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="similar-code-using-pytorch">
<h2>Similar code using PyTorch<a class="headerlink" href="#similar-code-using-pytorch" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import runpy
import matplotlib.pyplot as plt

# -------------------------------------------------------
# 1. Load your RK4 integrator and generate the dataset
# -------------------------------------------------------
data = runpy.run_path(&quot;rungekutta.py&quot;)

t = np.array(data[&quot;t&quot;])
x = np.array(data[&quot;x&quot;])

x = x.reshape(-1, 1)          # shape: (T, 1)
T = len(x)

# -------------------------------------------------------
# 2. Build supervised learning dataset
# -------------------------------------------------------

# ---------- Task 1: one-step predictor x_t → x_{t+1} ----------
X1 = x[:-1]
Y1 = x[1:]

X1_torch = torch.tensor(X1, dtype=torch.float32)
Y1_torch = torch.tensor(Y1, dtype=torch.float32)

# ---------- Task 2: sequence predictor ----------
seq_len = 20        # length of input window
pred_len = 20       # number of future steps to predict

X2 = []
Y2 = []

for i in range(T - seq_len - pred_len):
    X2.append(x[i : i + seq_len])
    Y2.append(x[i + seq_len : i + seq_len + pred_len])

X2 = np.array(X2)     # (N, seq_len, 1)
Y2 = np.array(Y2)     # (N, pred_len, 1)

X2_torch = torch.tensor(X2, dtype=torch.float32)
Y2_torch = torch.tensor(Y2, dtype=torch.float32)

# -------------------------------------------------------
# 3. Define RNN models
# -------------------------------------------------------

class RNNOneStep(nn.Module):
    &quot;&quot;&quot;Model 1: x_t → x_{t+1}&quot;&quot;&quot;
    def __init__(self, hidden=32):
        super().__init__()
        self.rnn = nn.RNN(1, hidden, batch_first=True)
        self.fc = nn.Linear(hidden, 1)

    def forward(self, x):
        out, _ = self.rnn(x.unsqueeze(1))   # shape (batch, 1, hidden)
        out = out[:, -1, :]                 # last time step
        return self.fc(out)


class RNNSequence(nn.Module):
    &quot;&quot;&quot;Model 2: Predict multiple future steps&quot;&quot;&quot;
    def __init__(self, hidden=64):
        super().__init__()
        self.rnn = nn.RNN(1, hidden, batch_first=True)
        self.fc = nn.Linear(hidden, 1)

    def forward(self, x):
        out, _ = self.rnn(x)           # out: (batch, seq_len, hidden)
        out = self.fc(out)             # (batch, seq_len, 1)
        return out


# -------------------------------------------------------
# 4. Train Model 1 (single-step predictor)
# -------------------------------------------------------

model1 = RNNOneStep()
criterion = nn.MSELoss()
optimizer = optim.Adam(model1.parameters(), lr=1e-3)

for epoch in range(200):
    optimizer.zero_grad()
    pred = model1(X1_torch)
    loss = criterion(pred, Y1_torch)
    loss.backward()
    optimizer.step()
    if epoch % 50 == 0:
        print(f&quot;One-step Epoch {epoch}, Loss: {loss.item():.6f}&quot;)

# -------------------------------------------------------
# 5. Train Model 2 (sequence predictor)
# -------------------------------------------------------

model2 = RNNSequence()
optimizer = optim.Adam(model4.parameters(), lr=1e-3)

for epoch in range(200):
    optimizer.zero_grad()
    pred = model2(X2_torch)
    loss = criterion(pred, Y2_torch)
    loss.backward()
    optimizer.step()
    if epoch % 50 == 0:
        print(f&quot;Sequence Epoch {epoch}, Loss: {loss.item():.6f}&quot;)

# -------------------------------------------------------
# 6. Evaluate: multi-step prediction
# -------------------------------------------------------

with torch.no_grad():
    sample_input = X2_torch[10:11]      # shape (1, seq_len, 1)
    predicted_seq = model4(sample_input).numpy().squeeze()
    true_seq = Y2[10].squeeze()

plt.plot(true_seq, label=&quot;True&quot;)
plt.plot(predicted_seq, label=&quot;Predicted&quot;, linestyle=&quot;--&quot;)
plt.legend()
plt.title(&quot;Sequence prediction (20 steps ahead)&quot;)
plt.show()
</pre></div>
</div>
</div>
</div>
</section>
<section id="autoencoders-overarching-view">
<h2>Autoencoders: Overarching view<a class="headerlink" href="#autoencoders-overarching-view" title="Link to this heading">#</a></h2>
<p>Autoencoders are artificial neural networks capable of learning
efficient representations of the input data (these representations are called codings)  without
any supervision (i.e., the training set is unlabeled). These codings
typically have a much lower dimensionality than the input data, making
autoencoders useful for dimensionality reduction.</p>
<p>Autoencoders learn to encode the
input data into a lower-dimensional representation, and then decode it
back to the original data. The goal of autoencoders is to minimize the
reconstruction error, which measures how well the output matches the
input. Autoencoders can be seen as a way of learning the latent
features or hidden structure of the data, and they can be used for
data compression, denoising, anomaly detection, and generative
modeling.</p>
</section>
<section id="powerful-detectors">
<h2>Powerful detectors<a class="headerlink" href="#powerful-detectors" title="Link to this heading">#</a></h2>
<p>More importantly, autoencoders act as powerful feature detectors, and
they can be used for unsupervised pretraining of deep neural networks.</p>
<p>Lastly, they are capable of randomly generating new data that looks
very similar to the training data; this is called a generative
model. For example, you could train an autoencoder on pictures of
faces, and it would then be able to generate new faces.  Surprisingly,
autoencoders work by simply learning to copy their inputs to their
outputs. This may sound like a trivial task, but we will see that
constraining the network in various ways can make it rather
difficult. For example, you can limit the size of the internal
representation, or you can add noise to the inputs and train the
network to recover the original inputs. These constraints prevent the
autoencoder from trivially copying the inputs directly to the outputs,
which forces it to learn efficient ways of representing the data. In
short, the codings are byproducts of the autoencoder’s attempt to
learn the identity function under some constraints.</p>
</section>
<section id="first-introduction-of-aes">
<h2>First introduction of AEs<a class="headerlink" href="#first-introduction-of-aes" title="Link to this heading">#</a></h2>
<p>Autoencoders were first introduced by Rumelhart, Hinton, and Williams
in 1986 with the goal of learning to reconstruct the input
observations with the lowest error possible.</p>
<p>Why would one want to learn to reconstruct the input observations? If
you have problems imagining what that means, think of having a dataset
made of images. An autoencoder would be an algorithm that can give as
output an image that is as similar as possible to the input one. You
may be confused, as there is no apparent reason of doing so. To better
understand why autoencoders are useful we need a more informative
(although not yet unambiguous) definition.</p>
<p>An autoencoder is a type of algorithm with the primary purpose of learning an “informative” representation of the data that can be used for different applications (<a class="reference external" href="https://arxiv.org/abs/2003.05991">see Bank, D., Koenigstein, N., and Giryes, R., Autoencoders</a>) by learning to reconstruct a set of input observations well enough.</p>
</section>
<section id="autoencoder-structure">
<h2>Autoencoder structure<a class="headerlink" href="#autoencoder-structure" title="Link to this heading">#</a></h2>
<p>Autoencoders are neural networks where the outputs are its own
inputs. They are split into an <strong>encoder part</strong>
which maps the input <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> via a function <span class="math notranslate nohighlight">\(f(\boldsymbol{x},\boldsymbol{W})\)</span> (this
is the encoder part) to a <strong>so-called code part</strong> (or intermediate part)
with the result <span class="math notranslate nohighlight">\(\boldsymbol{h}\)</span></p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{h} = f(\boldsymbol{x},\boldsymbol{W})),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{W}\)</span> are the weights to be determined.  The <strong>decoder</strong> parts maps, via its own parameters (weights given by the matrix <span class="math notranslate nohighlight">\(\boldsymbol{V}\)</span> and its own biases) to
the final ouput</p>
<div class="math notranslate nohighlight">
\[
\tilde{\boldsymbol{x}} = g(\boldsymbol{h},\boldsymbol{V})).
\]</div>
<p>The goal is to minimize the construction error.</p>
</section>
<section id="schematic-image-of-an-autoencoder">
<h2>Schematic image of an Autoencoder<a class="headerlink" href="#schematic-image-of-an-autoencoder" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figures/ae1.png, width=700 frac=1.0] -->
<!-- begin figure -->
<p><img src="figures/ae1.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="more-on-the-structure">
<h2>More on the structure<a class="headerlink" href="#more-on-the-structure" title="Link to this heading">#</a></h2>
<p>In most typical architectures, the encoder and the decoder are neural networks
since they can be easily trained with existing software libraries such as TensorFlow or PyTorch with back propagation.</p>
<p>In general, the encoder can be written as a function <span class="math notranslate nohighlight">\(g\)</span> that will depend on some parameters</p>
<div class="math notranslate nohighlight">
\[
\mathbf{h}_{i} = g(\mathbf{x}_{i}),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{h}_{i}\in\mathbb{R}^{q}\)</span>  (the latent feature representation) is the output of the encoder block where we evaluate
it using the input <span class="math notranslate nohighlight">\(\mathbf{x}_{i}\)</span>.</p>
</section>
<section id="decoder-part">
<h2>Decoder part<a class="headerlink" href="#decoder-part" title="Link to this heading">#</a></h2>
<p>Note that we have <span class="math notranslate nohighlight">\(g:\mathbb{R}^{n}\rightarrow\mathbb{R}^{q}\)</span>
The decoder and the output of the network <span class="math notranslate nohighlight">\(\tilde{\mathbf{x}}_{i}\)</span> can be written then as a second generic function
of the latent features</p>
<div class="math notranslate nohighlight">
\[
\tilde{\mathbf{x}}_{i} = f\left(\mathbf{h}_{i}\right) = f\left(g\left(\mathbf{x}_{i}\right)\right),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\tilde{\mathbf{x}}_{i}\mathbf{\in }\mathbb{R}^{n}\)</span>.</p>
<p>Training an autoencoder simply means finding the functions <span class="math notranslate nohighlight">\(g(\cdot)\)</span> and <span class="math notranslate nohighlight">\(f(\cdot)\)</span>
that satisfy</p>
<div class="math notranslate nohighlight">
\[
\textrm{arg}\min_{f,g}&lt;\left[\Delta (\mathbf{x}_{i}, f(g\left(\mathbf{x}_{i}\right))\right]&gt;.
\]</div>
</section>
<section id="typical-aes">
<h2>Typical AEs<a class="headerlink" href="#typical-aes" title="Link to this heading">#</a></h2>
<p>The standard setup is done via a standard feed forward neural network (FFNN), or what is called a Feed Forward Autoencoder.</p>
<p>A typical FFNN architecture has a given  number of layers and is symmetrical with respect to the middle layer.</p>
<p>Typically, the first layer has a number of neurons <span class="math notranslate nohighlight">\(n_{1} = n\)</span> which equals the size of the input observation <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathbf{i}}\)</span>.</p>
<p>As we move toward the center of the network, the number of neurons in each layer drops in some measure.
The middle layer usually has the smallest number of neurons.
The fact that the number of neurons in this layer is smaller than the size of the input, is often called the <strong>bottleneck</strong>.</p>
</section>
<section id="feed-forward-autoencoder">
<h2>Feed Forward Autoencoder<a class="headerlink" href="#feed-forward-autoencoder" title="Link to this heading">#</a></h2>
<!-- dom:FIGURE: [figures/ae2.png, width=700 frac=1.0] -->
<!-- begin figure -->
<p><img src="figures/ae2.png" width="700"><p style="font-size: 0.9em"><i>Figure 1: </i></p></p>
<!-- end figure --></section>
<section id="mirroring">
<h2>Mirroring<a class="headerlink" href="#mirroring" title="Link to this heading">#</a></h2>
<p>In almost all practical applications,
the layers after the middle one are a mirrored version of the layers before the middle one.
For example, an autoencoder with three layers could have the following numbers of neurons:</p>
<p><span class="math notranslate nohighlight">\(n_{1} = 10\)</span>, <span class="math notranslate nohighlight">\(n_{2} = 5\)</span> and then <span class="math notranslate nohighlight">\(n_{3} = n_{1} = 10\)</span> where the input dimension is equal to ten.</p>
<p>All the layers up to and including the middle one, make what is called the encoder, and all the layers from and including
the middle one (up to the output) make what is called the decoder.</p>
<p>If the FFNN training is successful, the result will
be a good approximation of the input <span class="math notranslate nohighlight">\(\tilde{\mathbf{x}}_{i}\approx\mathbf{x}_{i}\)</span>.</p>
<p>What is essential to notice is that the decoder can reconstruct the
input by using only a much smaller number of features than the input
observations initially have.</p>
</section>
<section id="output-of-middle-layer">
<h2>Output of middle layer<a class="headerlink" href="#output-of-middle-layer" title="Link to this heading">#</a></h2>
<p>The output of the middle layer
<span class="math notranslate nohighlight">\(\mathbf{h}_{\mathbf{i}}\)</span> are also called a <strong>learned representation</strong> of the input observation <span class="math notranslate nohighlight">\(\mathbf{x}_{i}\)</span>.</p>
<p>The encoder can reduce the number of dimensions of the input
observation and create a learned representation
<span class="math notranslate nohighlight">\(\mathbf{h}_{\mathbf{i}}\mathbf{) }\)</span> of the input that has a smaller
dimension <span class="math notranslate nohighlight">\(q&lt;n\)</span>.</p>
<p>This learned representation is enough for the decoder to reconstruct
the input accurately (if the autoencoder training was successful as
intended).</p>
</section>
<section id="activation-function-of-the-output-layer">
<h2>Activation Function of the Output Layer<a class="headerlink" href="#activation-function-of-the-output-layer" title="Link to this heading">#</a></h2>
<p>In autoencoders based on neural networks, the output layer’s
activation function plays a particularly important role.  The most
used functions are ReLU and Sigmoid.</p>
</section>
<section id="relu">
<h2>ReLU<a class="headerlink" href="#relu" title="Link to this heading">#</a></h2>
<p>The  ReLU activation function can assume all values in the range <span class="math notranslate nohighlight">\(\left[0,\infty\right]\)</span>. As a remainder, its formula is</p>
<div class="math notranslate nohighlight">
\[
\textrm{ReLU}\left(x\right) = \max\left(0,x\right).
\]</div>
<p>This choice is good when the input observations (\mathbf{x}_{i}) assume a wide range of positive values.
If the input <span class="math notranslate nohighlight">\(\mathbf{x}_{i}\)</span> can assume negative values, the ReLU is, of course, a terrible choice, and the identity function is a much better choice. It is then common to replace to the ReLU with the so-called <strong>Leaky ReLu</strong> or just modified ReLU.</p>
<p>The ReLU activation function for the output layer is well suited for cases when the input observations (\mathbf{x}_{i}) assume a wide range of positive real values.</p>
</section>
<section id="sigmoid">
<h2>Sigmoid<a class="headerlink" href="#sigmoid" title="Link to this heading">#</a></h2>
<p>The sigmoid function <span class="math notranslate nohighlight">\(\sigma\)</span> can assume all values in the range <span class="math notranslate nohighlight">\([0,1]\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\sigma\left(x\right) =\frac{1}{1+e^{-x}}.
\]</div>
<p>This activation function can only be used if the input observations
<span class="math notranslate nohighlight">\(\mathbf{x}_{i}\)</span> are all in the range <span class="math notranslate nohighlight">\([0,1]\)</span>  or if you have
normalized them to be in that range. Consider as an example the MNIST
dataset. Each value of the input observation <span class="math notranslate nohighlight">\(\mathbf{x}_{i}\)</span> (one
image) is the gray values of the pixels that can assume any value from
0 to 255. Normalizing the data by dividing the pixel values by 255
would make each observation (each image) have only pixel values
between 0 and 1. In this case, the sigmoid would be a good choice for
the output layer’s activation function.</p>
</section>
<section id="cost-loss-function">
<h2>Cost/Loss Function<a class="headerlink" href="#cost-loss-function" title="Link to this heading">#</a></h2>
<p>If an autoencoder is trying to solve a regression problem, the most
common choice as a loss function is the Mean Square Error</p>
<div class="math notranslate nohighlight">
\[
L_{\textrm{MSE}} = \textrm{MSE} = \frac{1}{n}\sum_{i = 1}^{n}\left\vert\vert\mathbf{x}_{i}-\tilde{\mathbf{x}}_{i}\right\vert\vert^{2}_2.
\]</div>
</section>
<section id="binary-cross-entropy">
<h2>Binary Cross-Entropy<a class="headerlink" href="#binary-cross-entropy" title="Link to this heading">#</a></h2>
<p>If the activation function of the output layer of the AE is a sigmoid
function, thus limiting neuron outputs to be between 0 and 1, and the
input features are normalized to be between 0 and 1 we can use as loss
function the binary cross-entropy. This cots/loss function is
typically used in classification problems, but it works well for
autoencoders. The formula for it is</p>
<div class="math notranslate nohighlight">
\[
L_{\textrm{CE}} = -\frac{1}{n}\sum_{i = 1}^{n}\sum_{j = 1}^{p}[x_{j,i} \log\tilde{x}_{j,i}+\left(1-x_{j,i}\right)\log (1-\tilde{x}_{j,i})].
\]</div>
</section>
<section id="reconstruction-error">
<h2>Reconstruction Error<a class="headerlink" href="#reconstruction-error" title="Link to this heading">#</a></h2>
<p>The reconstruction error (RE) is a metric that gives you an indication of how good (or bad) the autoencoder was able to reconstruct
the input observation <span class="math notranslate nohighlight">\(\mathbf{x}_{i}\)</span>. The most typical RE used is the MSE</p>
<div class="math notranslate nohighlight">
\[
\textrm{RE}\equiv \textrm{MSE} = \frac{1}{n}\sum_{i = 1}^{n}\left\vert\vert\mathbf{x}_{i}-\tilde{\mathbf{x}}_{i}\right\vert\vert^{2}_2.
\]</div>
</section>
<section id="implementation-using-tensorflow">
<h2>Implementation using TensorFlow<a class="headerlink" href="#implementation-using-tensorflow" title="Link to this heading">#</a></h2>
<p>The code here has the following structure</p>
<ol class="arabic simple">
<li><p>Data Loading: The MNIST dataset is loaded and normalized to a range of <span class="math notranslate nohighlight">\([0, 1]\)</span>. Each image is reshaped into a flat vector.</p></li>
<li><p>Model Definition: An autoencoder architecture is defined with an encoder that compresses the input and a decoder that reconstructs it back to its original form.</p></li>
<li><p>Training: The model is trained using binary crossentropy as the loss function over several epochs.</p></li>
<li><p>Visualization: After training completes, it visualizes original images alongside their reconstructions.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>### Autoencoder Implementation in TensorFlow/Keras
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import mnist

# Load MNIST dataset
(x_train, _), (x_test, _) = mnist.load_data()

# Normalize the images to [0, 1] range and reshape them to (num_samples, 28*28)
x_train = x_train.astype(&#39;float32&#39;) / 255.
x_test = x_test.astype(&#39;float32&#39;) / 255.
x_train = x_train.reshape((len(x_train), -1))
x_test = x_test.reshape((len(x_test), -1))

# Define the Autoencoder Model
input_dim = x_train.shape[1]
encoding_dim = 64  # Dimension of the encoding layer

# Encoder
input_img = layers.Input(shape=(input_dim,))
encoded = layers.Dense(256, activation=&#39;relu&#39;)(input_img)
encoded = layers.Dense(encoding_dim, activation=&#39;relu&#39;)(encoded)

# Decoder
decoded = layers.Dense(256, activation=&#39;relu&#39;)(encoded)
decoded = layers.Dense(input_dim, activation=&#39;sigmoid&#39;)(decoded)  # Use sigmoid since we normalized input between 0 and 1.

# Autoencoder Model
autoencoder = keras.Model(input_img, decoded)

# Compile the model
autoencoder.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;)

# Train the model
autoencoder.fit(x_train, x_train,
                epochs=10,
                batch_size=128,
                shuffle=True,
                validation_data=(x_test, x_test))

# Visualize some results after training
decoded_imgs = autoencoder.predict(x_test)

n = 8  # Number of digits to display
plt.figure(figsize=(9,4))
for i in range(n):
    # Display original images on top row 
    ax = plt.subplot(2,n,i+1)
    plt.imshow(x_test[i].reshape(28, 28), cmap=&#39;gray&#39;)
    ax.axis(&#39;off&#39;)

    # Display reconstructed images on bottom row 
    ax = plt.subplot(2,n,i+n+1)
    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap=&#39;gray&#39;)
    ax.axis(&#39;off&#39;)

plt.show()
</pre></div>
</div>
</div>
</div>
</section>
<section id="implementation-using-pytorch">
<h2>Implementation using PyTorch<a class="headerlink" href="#implementation-using-pytorch" title="Link to this heading">#</a></h2>
<p>The code here as the same structure as the previous one which uses TensorFlow.</p>
<ol class="arabic simple">
<li><p>Data Loading: The MNIST dataset is loaded with normalization applied.</p></li>
<li><p>Model Definition: An <em>Autoencoder</em> class defines both encoder and decoder networks.</p></li>
<li><p>Training part: The network is trained over several epochs using Mean Squared Error (MSE) as the loss function.</p></li>
<li><p>Visualization: After training completes, it visualizes original images alongside their reconstructions.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# Hyperparameters
batch_size = 128
learning_rate = 0.001
num_epochs = 10

# Transform to normalize the data
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Load MNIST dataset
train_dataset = datasets.MNIST(root=&#39;./data&#39;, train=True, transform=transform, download=True)
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)

# Define the Autoencoder Model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        # Encoder layers
        self.encoder = nn.Sequential(
            nn.Linear(28 * 28, 256),
            nn.ReLU(True),
            nn.Linear(256, 64),
            nn.ReLU(True)
        )
        # Decoder layers
        self.decoder = nn.Sequential(
            nn.Linear(64, 256),
            nn.ReLU(True),
            nn.Linear(256, 28 * 28),
            nn.Tanh()   # Use Tanh since we normalized input between -1 and 1.
        )

    def forward(self, x):
        x = x.view(-1, 28 * 28)  # Flatten the image tensor into vectors.
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded.view(-1, 1, 28, 28)   # Reshape back to original image dimensions.

# Initialize model, loss function and optimizer
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Training Loop
for epoch in range(num_epochs):
    for data in train_loader:
        img, _ = data
        
        # Forward pass 
        output = model(img)
        
        # Compute loss 
        loss = criterion(output, img)
        
        # Backward pass and optimization 
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f&#39;Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}&#39;)

# Visualize some results after training
with torch.no_grad():
    sample_data = next(iter(train_loader))[0]
    reconstructed_data = model(sample_data)

plt.figure(figsize=(9,4))
for i in range(8):
    ax = plt.subplot(2,8,i+1)
    plt.imshow(sample_data[i][0], cmap=&#39;gray&#39;)
    ax.axis(&#39;off&#39;)

    ax = plt.subplot(2,8,i+9)
    plt.imshow(reconstructed_data[i][0], cmap=&#39;gray&#39;)
    ax.axis(&#39;off&#39;)

plt.show()
</pre></div>
</div>
</div>
</div>
</section>
<section id="dimensionality-reduction-and-links-with-principal-component-analysis">
<h2>Dimensionality reduction and links with Principal component analysis<a class="headerlink" href="#dimensionality-reduction-and-links-with-principal-component-analysis" title="Link to this heading">#</a></h2>
<p>The hope is that the training of the autoencoder can unravel some
useful properties of the function <span class="math notranslate nohighlight">\(f\)</span>. They are often trained with
only single-layer neural networks (although deep networks can improve
the training) and are essentially given by feed forward neural
networks.</p>
</section>
<section id="linear-functions">
<h2>Linear functions<a class="headerlink" href="#linear-functions" title="Link to this heading">#</a></h2>
<p>If the function <span class="math notranslate nohighlight">\(f\)</span> and <span class="math notranslate nohighlight">\(g\)</span> are given by a linear dependence on the
weight matrices <span class="math notranslate nohighlight">\(\boldsymbol{W}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{V}\)</span>, we can show that for a
regression case, by miminizing the mean squared error between <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>
and <span class="math notranslate nohighlight">\(\tilde{\boldsymbol{x}}\)</span>, the autoencoder learns the same subspace as the
standard principal component analysis (PCA).</p>
<p>In order to see this, we define then</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{h} = f(\boldsymbol{x},\boldsymbol{W}))=\boldsymbol{W}\boldsymbol{x},
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
\tilde{\boldsymbol{x}} = g(\boldsymbol{h},\boldsymbol{V}))=\boldsymbol{V}\boldsymbol{h}=\boldsymbol{V}\boldsymbol{W}\boldsymbol{x}.
\]</div>
</section>
<section id="ae-mean-squared-error">
<h2>AE mean-squared error<a class="headerlink" href="#ae-mean-squared-error" title="Link to this heading">#</a></h2>
<p>With the above linear dependence we can in turn define our
optimization problem in terms of the optimization of the mean-squared
error, that is we wish to optimize</p>
<div class="math notranslate nohighlight">
\[
\min_{\boldsymbol{W},\boldsymbol{V}\in {\mathbb{R}}}\frac{1}{n}\sum_{i=0}^{n-1}\left(x_i-\tilde{x}_i\right)^2=\frac{1}{n}\vert\vert \boldsymbol{x}-\boldsymbol{V}\boldsymbol{W}\boldsymbol{x}\vert\vert_2^2,
\]</div>
<p>where we have used the definition of  a norm-2 vector, that is</p>
<div class="math notranslate nohighlight">
\[
\vert\vert \boldsymbol{x}\vert\vert_2 = \sqrt{\sum_i x_i^2}.
\]</div>
</section>
<section id="dimensionality-reduction">
<h2>Dimensionality reduction<a class="headerlink" href="#dimensionality-reduction" title="Link to this heading">#</a></h2>
<p>This is equivalent to our functions learning the same subspace as
the PCA method. This means that we can interpret AEs as a
dimensionality reduction method.  To see this, we need to remind
ourselves about the PCA method. This will be the topic of the last lecture, on Monday November 24. We will use this lecture (second lecture) to summarize the course as well. Stay tuned.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="week46.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Week 46: Decision Trees, Ensemble methods  and Random Forests</p>
      </div>
    </a>
    <a class="right-next"
       href="project1.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Project 1 on Machine Learning, deadline October 6 (midnight), 2025</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plan-for-week-47">Plan for week 47</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reading-recommendations-rnns">Reading recommendations RNNs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow-examples">TensorFlow examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reading-recommendations-autoencoders-ae">Reading recommendations: Autoencoders (AE)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-recurrent-nn">What is a recurrent NN?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-rnns">Why RNNs?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-whys">More whys</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail">RNNs in more detail</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-2">RNNs in more detail, part 2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-3">RNNs in more detail, part 3</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-4">RNNs in more detail, part 4</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-5">RNNs in more detail, part 5</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-6">RNNs in more detail, part 6</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnns-in-more-detail-part-7">RNNs in more detail, part 7</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rnn-forward-pass-equations">RNN Forward Pass Equations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unrolled-rnn-in-time">Unrolled RNN in Time</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-task-character-level-rnn-classification">Example Task: Character-level RNN Classification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-defining-a-simple-rnn-using-tensorflow">PyTorch: Defining a Simple RNN, using Tensorflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#similar-example-using-pytorch">Similar example using PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropagation-through-time-bptt-and-gradients">Backpropagation Through Time (BPTT) and Gradients</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#truncated-bptt-and-gradient-clipping">Truncated BPTT and Gradient Clipping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-and-considerations">Limitations and Considerations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-rnn-time-series-example">PyTorch RNN Time Series Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow-keras-rnn-time-series-example">Tensorflow (Keras) RNN Time Series Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mathematics-of-rnns-the-basic-architecture">The mathematics of RNNs, the basic architecture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gating-mechanism-long-short-term-memory-lstm">Gating mechanism: Long Short Term Memory (LSTM)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-a-memory-cell-in-a-neural-network">Implementing a memory cell in a neural network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-details">LSTM details</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-cell-and-gates">LSTM Cell and Gates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#core-lstm-equations">Core LSTM Equations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gate-intuition-and-dynamics">Gate Intuition and Dynamics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-layout-all-figures-from-raschka-et-al">Basic layout (All figures from Raschka <em>et al.,</em>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">LSTM details</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-with-a-standard-rnn">Comparing with a standard  RNN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-details-i">LSTM details I</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-details-ii">LSTM details II</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-details-iii">LSTM details III</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forget-gate">Forget gate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-forget-gate">The forget gate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-layout">Basic layout</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input-gate">Input gate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#short-summary">Short summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forget-and-input">Forget and input</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Basic layout</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#output-gate">Output gate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-implementation-code-example">LSTM Implementation (Code Example)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-modeling-dynamical-systems">Example: Modeling Dynamical Systems</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-biological-sequences">Example: Biological Sequences</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-tips-and-variants">Training Tips and Variants</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-summary">LSTM Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-lstm">Summary of LSTM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-implementation-using-tensorflow">LSTM implementation using TensorFlow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#and-the-corresponding-one-with-pytorch">And the corresponding one with PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamical-ordinary-differential-equation">Dynamical ordinary differential equation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-runge-kutta-4-code">The Runge-Kutta-4 code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-the-above-data-to-train-an-rnn">Using the above data to train an RNN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#similar-code-using-pytorch">Similar code using PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoders-overarching-view">Autoencoders: Overarching view</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#powerful-detectors">Powerful detectors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#first-introduction-of-aes">First introduction of AEs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoder-structure">Autoencoder structure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#schematic-image-of-an-autoencoder">Schematic image of an Autoencoder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-on-the-structure">More on the structure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decoder-part">Decoder part</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#typical-aes">Typical AEs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feed-forward-autoencoder">Feed Forward Autoencoder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mirroring">Mirroring</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#output-of-middle-layer">Output of middle layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-function-of-the-output-layer">Activation Function of the Output Layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#relu">ReLU</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sigmoid">Sigmoid</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-loss-function">Cost/Loss Function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#binary-cross-entropy">Binary Cross-Entropy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstruction-error">Reconstruction Error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-using-tensorflow">Implementation using TensorFlow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-using-pytorch">Implementation using PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensionality-reduction-and-links-with-principal-component-analysis">Dimensionality reduction and links with Principal component analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-functions">Linear functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ae-mean-squared-error">AE mean-squared error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensionality-reduction">Dimensionality reduction</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Morten Hjorth-Jensen
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>