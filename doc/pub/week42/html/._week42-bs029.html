<!--
Automatically generated HTML file from DocOnce source
(https://github.com/doconce/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 42 Solving differential equations and Convolutional (CNN)">

<title>Week 42 Solving differential equations and Convolutional (CNN)</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 42', 2, None, 'plan-for-week-42'),
              ('Using Automatic differentiation',
               2,
               None,
               'using-automatic-differentiation'),
              ('Solving ODEs with Deep Learning',
               2,
               None,
               'solving-odes-with-deep-learning'),
              ('Ordinary Differential Equations',
               2,
               None,
               'ordinary-differential-equations'),
              ('The trial solution', 2, None, 'the-trial-solution'),
              ('Minimization process', 2, None, 'minimization-process'),
              ('Minimizing the cost function using gradient descent and '
               'automatic differentiation',
               2,
               None,
               'minimizing-the-cost-function-using-gradient-descent-and-automatic-differentiation'),
              ('Example: Exponential decay',
               2,
               None,
               'example-exponential-decay'),
              ('The function to solve for',
               2,
               None,
               'the-function-to-solve-for'),
              ('The trial solution', 2, None, 'the-trial-solution'),
              ('Setup of Network', 2, None, 'setup-of-network'),
              ('Reformulating the problem',
               2,
               None,
               'reformulating-the-problem'),
              ('More technicalities', 2, None, 'more-technicalities'),
              ('More details', 2, None, 'more-details'),
              ('A possible implementation of a neural network',
               2,
               None,
               'a-possible-implementation-of-a-neural-network'),
              ('Technicalities', 2, None, 'technicalities'),
              ('Final technicalities I', 2, None, 'final-technicalities-i'),
              ('Final technicalities II', 2, None, 'final-technicalities-ii'),
              ('Final technicalities III', 2, None, 'final-technicalities-iii'),
              ('Final technicalities IV', 2, None, 'final-technicalities-iv'),
              ('Back propagation', 2, None, 'back-propagation'),
              ('Gradient descent', 2, None, 'gradient-descent'),
              ('The code for solving the ODE',
               2,
               None,
               'the-code-for-solving-the-ode'),
              ('The network with one input layer, specified number of hidden '
               'layers, and one output layer',
               2,
               None,
               'the-network-with-one-input-layer-specified-number-of-hidden-layers-and-one-output-layer'),
              ('Example: Population growth',
               2,
               None,
               'example-population-growth'),
              ('Setting up the problem', 2, None, 'setting-up-the-problem'),
              ('The trial solution', 2, None, 'the-trial-solution'),
              ('The program using Autograd',
               2,
               None,
               'the-program-using-autograd'),
              ('Using forward Euler to solve the ODE',
               2,
               None,
               'using-forward-euler-to-solve-the-ode'),
              ('Example: Solving the one dimensional Poisson equation',
               2,
               None,
               'example-solving-the-one-dimensional-poisson-equation'),
              ('The specific equation to solve for',
               2,
               None,
               'the-specific-equation-to-solve-for'),
              ('Solving the equation using Autograd',
               2,
               None,
               'solving-the-equation-using-autograd'),
              ('Comparing with a numerical scheme',
               2,
               None,
               'comparing-with-a-numerical-scheme'),
              ('Setting up the code', 2, None, 'setting-up-the-code'),
              ('Partial Differential Equations',
               2,
               None,
               'partial-differential-equations'),
              ('Type of problem', 2, None, 'type-of-problem'),
              ('Network requirements', 2, None, 'network-requirements'),
              ('More details', 2, None, 'more-details'),
              ('Example: The diffusion equation',
               2,
               None,
               'example-the-diffusion-equation'),
              ('Defining the problem', 2, None, 'defining-the-problem'),
              ('Setting up the network using Autograd',
               2,
               None,
               'setting-up-the-network-using-autograd'),
              ('Setting up the network using Autograd; The trial solution',
               2,
               None,
               'setting-up-the-network-using-autograd-the-trial-solution'),
              ('Why the jacobian?', 2, None, 'why-the-jacobian'),
              ('Setting up the network using Autograd; The full program',
               2,
               None,
               'setting-up-the-network-using-autograd-the-full-program'),
              ('Example: Solving the wave equation with Neural Networks',
               2,
               None,
               'example-solving-the-wave-equation-with-neural-networks'),
              ('The problem to solve for', 2, None, 'the-problem-to-solve-for'),
              ('The trial solution', 2, None, 'the-trial-solution'),
              ('The analytical solution', 2, None, 'the-analytical-solution'),
              ('Solving the wave equation - the full program using Autograd',
               2,
               None,
               'solving-the-wave-equation-the-full-program-using-autograd'),
              ('Resources on differential equations and deep learning',
               2,
               None,
               'resources-on-differential-equations-and-deep-learning'),
              ('Convolutional Neural Networks (recognizing images)',
               2,
               None,
               'convolutional-neural-networks-recognizing-images'),
              ('Neural Networks vs CNNs', 2, None, 'neural-networks-vs-cnns'),
              ('Why CNNS for images, sound files, medical images from CT scans '
               'etc?',
               2,
               None,
               'why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc'),
              ('Regular NNs don’t scale well to full images',
               2,
               None,
               'regular-nns-don-t-scale-well-to-full-images'),
              ('3D volumes of neurons', 2, None, '3d-volumes-of-neurons'),
              ('Layers used to build CNNs',
               2,
               None,
               'layers-used-to-build-cnns'),
              ('Transforming images', 2, None, 'transforming-images'),
              ('CNNs in brief', 2, None, 'cnns-in-brief'),
              ('Mathematics of CNNs', 2, None, 'mathematics-of-cnns'),
              ('Convolution Examples: Polynomial multiplication',
               2,
               None,
               'convolution-examples-polynomial-multiplication'),
              ('Convolution Examples: Probability Theory',
               2,
               None,
               'convolution-examples-probability-theory'),
              ('Convolution Examples: Principle of Superposition and Periodic '
               'Forces (Fourier Transforms)',
               2,
               None,
               'convolution-examples-principle-of-superposition-and-periodic-forces-fourier-transforms'),
              ('Principle of Superposition',
               2,
               None,
               'principle-of-superposition'),
              ('Simple Code Example', 2, None, 'simple-code-example'),
              ('Wrapping up Fourier transforms',
               2,
               None,
               'wrapping-up-fourier-transforms'),
              ('Finding the Coefficients', 2, None, 'finding-the-coefficients'),
              ('CNNs in more detail, building convolutional neural networks in '
               'Tensorflow and Keras',
               2,
               None,
               'cnns-in-more-detail-building-convolutional-neural-networks-in-tensorflow-and-keras'),
              ('Setting it up', 2, None, 'setting-it-up'),
              ('The MNIST dataset again', 2, None, 'the-mnist-dataset-again'),
              ('Strong correlations', 2, None, 'strong-correlations'),
              ('Layers of a CNN', 2, None, 'layers-of-a-cnn'),
              ('Systematic reduction', 2, None, 'systematic-reduction'),
              ('Prerequisites: Collect and pre-process data',
               2,
               None,
               'prerequisites-collect-and-pre-process-data'),
              ('Importing Keras and Tensorflow',
               2,
               None,
               'importing-keras-and-tensorflow'),
              ('Running with Keras', 2, None, 'running-with-keras'),
              ('Final part', 2, None, 'final-part'),
              ('Final visualization', 2, None, 'final-visualization'),
              ('The CIFAR01 data set', 2, None, 'the-cifar01-data-set'),
              ('Verifying the data set', 2, None, 'verifying-the-data-set'),
              ('Set up  the model', 2, None, 'set-up-the-model'),
              ('Add Dense layers on top', 2, None, 'add-dense-layers-on-top'),
              ('Compile and train the model',
               2,
               None,
               'compile-and-train-the-model'),
              ('Finally, evaluate the model',
               2,
               None,
               'finally-evaluate-the-model')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week42-bs.html">Week 42 Solving differential equations and Convolutional (CNN)</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week42-bs001.html#plan-for-week-42" style="font-size: 80%;">Plan for week 42</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs002.html#using-automatic-differentiation" style="font-size: 80%;">Using Automatic differentiation</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs003.html#solving-odes-with-deep-learning" style="font-size: 80%;">Solving ODEs with Deep Learning</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs004.html#ordinary-differential-equations" style="font-size: 80%;">Ordinary Differential Equations</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs047.html#the-trial-solution" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs006.html#minimization-process" style="font-size: 80%;">Minimization process</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs007.html#minimizing-the-cost-function-using-gradient-descent-and-automatic-differentiation" style="font-size: 80%;">Minimizing the cost function using gradient descent and automatic differentiation</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs008.html#example-exponential-decay" style="font-size: 80%;">Example: Exponential decay</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs009.html#the-function-to-solve-for" style="font-size: 80%;">The function to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs047.html#the-trial-solution" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs011.html#setup-of-network" style="font-size: 80%;">Setup of Network</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs012.html#reformulating-the-problem" style="font-size: 80%;">Reformulating the problem</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs013.html#more-technicalities" style="font-size: 80%;">More technicalities</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs038.html#more-details" style="font-size: 80%;">More details</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs015.html#a-possible-implementation-of-a-neural-network" style="font-size: 80%;">A possible implementation of a neural network</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs016.html#technicalities" style="font-size: 80%;">Technicalities</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs017.html#final-technicalities-i" style="font-size: 80%;">Final technicalities I</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs018.html#final-technicalities-ii" style="font-size: 80%;">Final technicalities II</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs019.html#final-technicalities-iii" style="font-size: 80%;">Final technicalities III</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs020.html#final-technicalities-iv" style="font-size: 80%;">Final technicalities IV</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs021.html#back-propagation" style="font-size: 80%;">Back propagation</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs022.html#gradient-descent" style="font-size: 80%;">Gradient descent</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs023.html#the-code-for-solving-the-ode" style="font-size: 80%;">The code for solving the ODE</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs024.html#the-network-with-one-input-layer-specified-number-of-hidden-layers-and-one-output-layer" style="font-size: 80%;">The network with one input layer, specified number of hidden layers, and one output layer</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs025.html#example-population-growth" style="font-size: 80%;">Example: Population growth</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs026.html#setting-up-the-problem" style="font-size: 80%;">Setting up the problem</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs047.html#the-trial-solution" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs028.html#the-program-using-autograd" style="font-size: 80%;">The program using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="#using-forward-euler-to-solve-the-ode" style="font-size: 80%;">Using forward Euler to solve the ODE</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs030.html#example-solving-the-one-dimensional-poisson-equation" style="font-size: 80%;">Example: Solving the one dimensional Poisson equation</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs031.html#the-specific-equation-to-solve-for" style="font-size: 80%;">The specific equation to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs032.html#solving-the-equation-using-autograd" style="font-size: 80%;">Solving the equation using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs033.html#comparing-with-a-numerical-scheme" style="font-size: 80%;">Comparing with a numerical scheme</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs034.html#setting-up-the-code" style="font-size: 80%;">Setting up the code</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs035.html#partial-differential-equations" style="font-size: 80%;">Partial Differential Equations</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs036.html#type-of-problem" style="font-size: 80%;">Type of problem</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs037.html#network-requirements" style="font-size: 80%;">Network requirements</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs038.html#more-details" style="font-size: 80%;">More details</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs039.html#example-the-diffusion-equation" style="font-size: 80%;">Example: The diffusion equation</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs040.html#defining-the-problem" style="font-size: 80%;">Defining the problem</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs041.html#setting-up-the-network-using-autograd" style="font-size: 80%;">Setting up the network using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs042.html#setting-up-the-network-using-autograd-the-trial-solution" style="font-size: 80%;">Setting up the network using Autograd; The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs043.html#why-the-jacobian" style="font-size: 80%;">Why the jacobian?</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs044.html#setting-up-the-network-using-autograd-the-full-program" style="font-size: 80%;">Setting up the network using Autograd; The full program</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs045.html#example-solving-the-wave-equation-with-neural-networks" style="font-size: 80%;">Example: Solving the wave equation with Neural Networks</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs046.html#the-problem-to-solve-for" style="font-size: 80%;">The problem to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs047.html#the-trial-solution" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs048.html#the-analytical-solution" style="font-size: 80%;">The analytical solution</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs049.html#solving-the-wave-equation-the-full-program-using-autograd" style="font-size: 80%;">Solving the wave equation - the full program using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs050.html#resources-on-differential-equations-and-deep-learning" style="font-size: 80%;">Resources on differential equations and deep learning</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs051.html#convolutional-neural-networks-recognizing-images" style="font-size: 80%;">Convolutional Neural Networks (recognizing images)</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs052.html#neural-networks-vs-cnns" style="font-size: 80%;">Neural Networks vs CNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs053.html#why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc" style="font-size: 80%;">Why CNNS for images, sound files, medical images from CT scans etc?</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs054.html#regular-nns-don-t-scale-well-to-full-images" style="font-size: 80%;">Regular NNs don’t scale well to full images</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs055.html#3d-volumes-of-neurons" style="font-size: 80%;">3D volumes of neurons</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs056.html#layers-used-to-build-cnns" style="font-size: 80%;">Layers used to build CNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs057.html#transforming-images" style="font-size: 80%;">Transforming images</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs058.html#cnns-in-brief" style="font-size: 80%;">CNNs in brief</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs059.html#mathematics-of-cnns" style="font-size: 80%;">Mathematics of CNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs060.html#convolution-examples-polynomial-multiplication" style="font-size: 80%;">Convolution Examples: Polynomial multiplication</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs061.html#convolution-examples-probability-theory" style="font-size: 80%;">Convolution Examples: Probability Theory</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs062.html#convolution-examples-principle-of-superposition-and-periodic-forces-fourier-transforms" style="font-size: 80%;">Convolution Examples: Principle of Superposition and Periodic Forces (Fourier Transforms)</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs063.html#principle-of-superposition" style="font-size: 80%;">Principle of Superposition</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs064.html#simple-code-example" style="font-size: 80%;">Simple Code Example</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs065.html#wrapping-up-fourier-transforms" style="font-size: 80%;">Wrapping up Fourier transforms</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs066.html#finding-the-coefficients" style="font-size: 80%;">Finding the Coefficients</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs067.html#cnns-in-more-detail-building-convolutional-neural-networks-in-tensorflow-and-keras" style="font-size: 80%;">CNNs in more detail, building convolutional neural networks in Tensorflow and Keras</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs068.html#setting-it-up" style="font-size: 80%;">Setting it up</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs069.html#the-mnist-dataset-again" style="font-size: 80%;">The MNIST dataset again</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs070.html#strong-correlations" style="font-size: 80%;">Strong correlations</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs071.html#layers-of-a-cnn" style="font-size: 80%;">Layers of a CNN</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs072.html#systematic-reduction" style="font-size: 80%;">Systematic reduction</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs073.html#prerequisites-collect-and-pre-process-data" style="font-size: 80%;">Prerequisites: Collect and pre-process data</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs074.html#importing-keras-and-tensorflow" style="font-size: 80%;">Importing Keras and Tensorflow</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs075.html#running-with-keras" style="font-size: 80%;">Running with Keras</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs076.html#final-part" style="font-size: 80%;">Final part</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs077.html#final-visualization" style="font-size: 80%;">Final visualization</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs078.html#the-cifar01-data-set" style="font-size: 80%;">The CIFAR01 data set</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs079.html#verifying-the-data-set" style="font-size: 80%;">Verifying the data set</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs080.html#set-up-the-model" style="font-size: 80%;">Set up  the model</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs081.html#add-dense-layers-on-top" style="font-size: 80%;">Add Dense layers on top</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs082.html#compile-and-train-the-model" style="font-size: 80%;">Compile and train the model</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs083.html#finally-evaluate-the-model" style="font-size: 80%;">Finally, evaluate the model</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0029"></a>
<!-- !split -->

<h2 id="using-forward-euler-to-solve-the-ode" class="anchor">Using forward Euler to solve the ODE </h2>

<p>
A straightforward way of solving an ODE numerically, is to use Euler's method.

<p>
Euler's method uses Taylor series to approximate the value at a function \( f \) at a step \( \Delta x \) from \( x \):

$$
f(x + \Delta x) \approx f(x) + \Delta x f'(x)
$$

<p>
In our case, using Euler's method to approximate the value of \( g \) at a step \( \Delta t \) from \( t \) yields

$$
\begin{aligned}
  g(t + \Delta t) &\approx g(t) + \Delta t g'(t) \\
  &= g(t) + \Delta t \big(\alpha g(t)(A - g(t))\big)
\end{aligned}
$$

along with the condition that \( g(0) = g_0 \).

<p>
Let \( t_i = i \cdot \Delta t \) where \( \Delta t = \frac{T}{N_t-1} \) where \( T \) is the final time our solver must solve for and \( N_t \) the number of values for \( t \in [0, T] \) for \( i = 0, \dots, N_t-1 \).

<p>
For \( i \geq 1 \), we have that
$$
\begin{aligned}
t_i &= i\Delta t \\
&= (i - 1)\Delta t + \Delta t \\
&= t_{i-1} + \Delta t
\end{aligned}
$$

<p>
Now, if \( g_i = g(t_i) \) then

$$
\begin{equation}
  \begin{aligned}
  g_i &= g(t_i) \\
  &= g(t_{i-1} + \Delta t) \\
  &\approx g(t_{i-1}) + \Delta t \big(\alpha g(t_{i-1})(A - g(t_{i-1}))\big) \\
  &= g_{i-1} + \Delta t \big(\alpha g_{i-1}(A - g_{i-1})\big)
  \end{aligned}
\end{equation} \tag{12}
$$

for \( i \geq 1 \) and \( g_0 = g(t_0) = g(0) = g_0 \).

<p>
Equation <a href="#mjx-eqn-12">(12)</a> could be implemented in the following way,
extending the program that uses the network using Autograd:

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><span style="color: #408080; font-style: italic"># Assume that all function definitions from the example program using Autograd</span>
<span style="color: #408080; font-style: italic"># are located here.</span>

<span style="color: #008000; font-weight: bold">if</span> <span style="color: #19177C">__name__</span> <span style="color: #666666">==</span> <span style="color: #BA2121">&#39;__main__&#39;</span>:
    npr<span style="color: #666666">.</span>seed(<span style="color: #666666">4155</span>)

    <span style="color: #408080; font-style: italic">## Decide the vales of arguments to the function to solve</span>
    Nt <span style="color: #666666">=</span> <span style="color: #666666">10</span>
    T <span style="color: #666666">=</span> <span style="color: #666666">1</span>
    t <span style="color: #666666">=</span> np<span style="color: #666666">.</span>linspace(<span style="color: #666666">0</span>,T, Nt)

    <span style="color: #408080; font-style: italic">## Set up the initial parameters</span>
    num_hidden_neurons <span style="color: #666666">=</span> [<span style="color: #666666">100</span>,<span style="color: #666666">50</span>,<span style="color: #666666">25</span>]
    num_iter <span style="color: #666666">=</span> <span style="color: #666666">1000</span>
    lmb <span style="color: #666666">=</span> <span style="color: #666666">1e-3</span>

    P <span style="color: #666666">=</span> solve_ode_deep_neural_network(t, num_hidden_neurons, num_iter, lmb)

    g_dnn_ag <span style="color: #666666">=</span> g_trial_deep(t,P)
    g_analytical <span style="color: #666666">=</span> g_analytic(t)

    <span style="color: #408080; font-style: italic"># Find the maximum absolute difference between the solutons:</span>
    diff_ag <span style="color: #666666">=</span> np<span style="color: #666666">.</span>max(np<span style="color: #666666">.</span>abs(g_dnn_ag <span style="color: #666666">-</span> g_analytical))
    <span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;The max absolute difference between the solutions is: </span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&quot;</span><span style="color: #666666">%</span>diff_ag)

    plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">10</span>,<span style="color: #666666">10</span>))

    plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&#39;Performance of neural network solving an ODE compared to the analytical solution&#39;</span>)
    plt<span style="color: #666666">.</span>plot(t, g_analytical)
    plt<span style="color: #666666">.</span>plot(t, g_dnn_ag[<span style="color: #666666">0</span>,:])
    plt<span style="color: #666666">.</span>legend([<span style="color: #BA2121">&#39;analytical&#39;</span>,<span style="color: #BA2121">&#39;nn&#39;</span>])
    plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;t&#39;</span>)
    plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;g(t)&#39;</span>)

    <span style="color: #408080; font-style: italic">## Find an approximation to the funtion using forward Euler</span>

    alpha, A, g0 <span style="color: #666666">=</span> get_parameters()
    dt <span style="color: #666666">=</span> T<span style="color: #666666">/</span>(Nt <span style="color: #666666">-</span> <span style="color: #666666">1</span>)

    <span style="color: #408080; font-style: italic"># Perform forward Euler to solve the ODE</span>
    g_euler <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros(Nt)
    g_euler[<span style="color: #666666">0</span>] <span style="color: #666666">=</span> g0

    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #666666">1</span>,Nt):
        g_euler[i] <span style="color: #666666">=</span> g_euler[i<span style="color: #666666">-1</span>] <span style="color: #666666">+</span> dt<span style="color: #666666">*</span>(alpha<span style="color: #666666">*</span>g_euler[i<span style="color: #666666">-1</span>]<span style="color: #666666">*</span>(A <span style="color: #666666">-</span> g_euler[i<span style="color: #666666">-1</span>]))

    <span style="color: #408080; font-style: italic"># Print the errors done by each method</span>
    diff1 <span style="color: #666666">=</span> np<span style="color: #666666">.</span>max(np<span style="color: #666666">.</span>abs(g_euler <span style="color: #666666">-</span> g_analytical))
    diff2 <span style="color: #666666">=</span> np<span style="color: #666666">.</span>max(np<span style="color: #666666">.</span>abs(g_dnn_ag[<span style="color: #666666">0</span>,:] <span style="color: #666666">-</span> g_analytical))

    <span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;Max absolute difference between Euler method and analytical: </span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>diff1)
    <span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;Max absolute difference between deep neural network and analytical: </span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>diff2)

    <span style="color: #408080; font-style: italic"># Plot results</span>
    plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">10</span>,<span style="color: #666666">10</span>))

    plt<span style="color: #666666">.</span>plot(t,g_euler)
    plt<span style="color: #666666">.</span>plot(t,g_analytical)
    plt<span style="color: #666666">.</span>plot(t,g_dnn_ag[<span style="color: #666666">0</span>,:])

    plt<span style="color: #666666">.</span>legend([<span style="color: #BA2121">&#39;euler&#39;</span>,<span style="color: #BA2121">&#39;analytical&#39;</span>,<span style="color: #BA2121">&#39;dnn&#39;</span>])
    plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;Time t&#39;</span>)
    plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;g(t)&#39;</span>)

    plt<span style="color: #666666">.</span>show()
</pre></div>
<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week42-bs028.html">&laquo;</a></li>
  <li><a href="._week42-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week42-bs021.html">22</a></li>
  <li><a href="._week42-bs022.html">23</a></li>
  <li><a href="._week42-bs023.html">24</a></li>
  <li><a href="._week42-bs024.html">25</a></li>
  <li><a href="._week42-bs025.html">26</a></li>
  <li><a href="._week42-bs026.html">27</a></li>
  <li><a href="._week42-bs027.html">28</a></li>
  <li><a href="._week42-bs028.html">29</a></li>
  <li class="active"><a href="._week42-bs029.html">30</a></li>
  <li><a href="._week42-bs030.html">31</a></li>
  <li><a href="._week42-bs031.html">32</a></li>
  <li><a href="._week42-bs032.html">33</a></li>
  <li><a href="._week42-bs033.html">34</a></li>
  <li><a href="._week42-bs034.html">35</a></li>
  <li><a href="._week42-bs035.html">36</a></li>
  <li><a href="._week42-bs036.html">37</a></li>
  <li><a href="._week42-bs037.html">38</a></li>
  <li><a href="._week42-bs038.html">39</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week42-bs083.html">84</a></li>
  <li><a href="._week42-bs030.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    

