<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="description" content="Data Analysis and Machine Learning: Using Neural networks to solve ODEs and PDEs">

<title>Data Analysis and Machine Learning: Using Neural networks to solve ODEs and PDEs</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Differential equations', 2, None, '___sec0'),
              ('Description of the equation to solve for', 2, None, '___sec1'),
              ('Ordinary Differential Equations', 2, None, '___sec2'),
              ('The trial solution', 2, None, '___sec3'),
              ('Minimizing the cost function using gradient descent and '
               'automatic differentiation',
               2,
               None,
               '___sec4'),
              ('Example: Exponential decay and setting up the network using '
               'Autograd',
               2,
               None,
               '___sec5'),
              ('The function to solve for', 2, None, '___sec6'),
              ('The trial solution', 2, None, '___sec7'),
              ('Reformulating the problem', 2, None, '___sec8'),
              ('A possible implementation of a neural network using Autograd',
               2,
               None,
               '___sec9'),
              ('Backpropagation using Autograd', 2, None, '___sec10'),
              ('Gradient descent', 2, None, '___sec11'),
              ('The network with one input, hidden, and output layer',
               2,
               None,
               '___sec12'),
              ('The network with one input layer, specified number of hidden '
               'layers, and one output layer  output layer',
               2,
               None,
               '___sec13'),
              ('Example: Population growth, comparing Autograd, TensorFlow, '
               "and Euler's scheme",
               2,
               None,
               '___sec14'),
              ('Setting up the problem', 2, None, '___sec15'),
              ('The trial solution', 2, None, '___sec16'),
              ('The program using Autograd', 2, None, '___sec17'),
              ('Using forward Euler to solve the ODE', 2, None, '___sec18'),
              ('Using TensorFlow to model logistic population growth',
               2,
               None,
               '___sec19'),
              ('The general program flow in TensorFlow', 2, None, '___sec20'),
              ('Program flow in TensorFlow - Construction phase',
               2,
               None,
               '___sec21'),
              ('Program flow in TensorFlow - Execution phase',
               2,
               None,
               '___sec22'),
              ('The full program modeling logistic population growth using '
               'TensorFlow',
               2,
               None,
               '___sec23'),
              ('Example: Solving the one dimensional Poisson equation using '
               'Autograd and TensorFlow',
               2,
               None,
               '___sec24'),
              ('The specific equation to solve for', 2, None, '___sec25'),
              ('Solving the equation using Autograd', 2, None, '___sec26'),
              ('Comparing with a numerical scheme', 2, None, '___sec27'),
              ('Using gradient descent in TensorFlow to solve Poisson equation',
               2,
               None,
               '___sec28'),
              ('Using a different optimization algorithm implemented in '
               'TensorFlow to solve Poisson equation',
               2,
               None,
               '___sec29'),
              ('Partial Differential Equations', 2, None, '___sec30'),
              ('Example: The diffusion equation', 2, None, '___sec31'),
              ('Defining the problem', 2, None, '___sec32'),
              ('Setting up the network using Autograd', 2, None, '___sec33'),
              ('Setting up the network using Autograd; The trial solution',
               2,
               None,
               '___sec34'),
              ('Setting up the network using Autograd; The full program',
               2,
               None,
               '___sec35'),
              ('Example: Solving the wave equation using Autograd and '
               'TensorFlow',
               2,
               None,
               '___sec36'),
              ('The problem to solve for', 2, None, '___sec37'),
              ('The trial solution', 2, None, '___sec38'),
              ('The analytical solution', 2, None, '___sec39'),
              ('Solving the wave equation - the full program using Autograd',
               2,
               None,
               '___sec40'),
              ('Solving the wave equation - the full program using TensorFlow',
               2,
               None,
               '___sec41'),
              ('Resources', 2, None, '___sec42')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="odenn-bs.html">Data Analysis and Machine Learning: Using Neural networks to solve ODEs and PDEs</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._odenn-bs001.html#___sec0" style="font-size: 80%;">Differential equations</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs002.html#___sec1" style="font-size: 80%;">Description of the equation to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs003.html#___sec2" style="font-size: 80%;">Ordinary Differential Equations</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs004.html#___sec3" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs005.html#___sec4" style="font-size: 80%;">Minimizing the cost function using gradient descent and automatic differentiation</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs006.html#___sec5" style="font-size: 80%;">Example: Exponential decay and setting up the network using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs007.html#___sec6" style="font-size: 80%;">The function to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs008.html#___sec7" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs009.html#___sec8" style="font-size: 80%;">Reformulating the problem</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs010.html#___sec9" style="font-size: 80%;">A possible implementation of a neural network using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs011.html#___sec10" style="font-size: 80%;">Backpropagation using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs012.html#___sec11" style="font-size: 80%;">Gradient descent</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs013.html#___sec12" style="font-size: 80%;">The network with one input, hidden, and output layer</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs014.html#___sec13" style="font-size: 80%;">The network with one input layer, specified number of hidden layers, and one output layer  output layer</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs015.html#___sec14" style="font-size: 80%;">Example: Population growth, comparing Autograd, TensorFlow, and Euler's scheme</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs016.html#___sec15" style="font-size: 80%;">Setting up the problem</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs017.html#___sec16" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs018.html#___sec17" style="font-size: 80%;">The program using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs019.html#___sec18" style="font-size: 80%;">Using forward Euler to solve the ODE</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs020.html#___sec19" style="font-size: 80%;">Using TensorFlow to model logistic population growth</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs021.html#___sec20" style="font-size: 80%;">The general program flow in TensorFlow</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs021.html#___sec21" style="font-size: 80%;">Program flow in TensorFlow - Construction phase</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs021.html#___sec22" style="font-size: 80%;">Program flow in TensorFlow - Execution phase</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs021.html#___sec23" style="font-size: 80%;">The full program modeling logistic population growth using TensorFlow</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs022.html#___sec24" style="font-size: 80%;">Example: Solving the one dimensional Poisson equation using Autograd and TensorFlow</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs023.html#___sec25" style="font-size: 80%;">The specific equation to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs024.html#___sec26" style="font-size: 80%;">Solving the equation using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs025.html#___sec27" style="font-size: 80%;">Comparing with a numerical scheme</a></li>
     <!-- navigation toc: --> <li><a href="#___sec28" style="font-size: 80%;">Using gradient descent in TensorFlow to solve Poisson equation</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs027.html#___sec29" style="font-size: 80%;">Using a different optimization algorithm implemented in TensorFlow to solve Poisson equation</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs028.html#___sec30" style="font-size: 80%;">Partial Differential Equations</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs029.html#___sec31" style="font-size: 80%;">Example: The diffusion equation</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs030.html#___sec32" style="font-size: 80%;">Defining the problem</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs031.html#___sec33" style="font-size: 80%;">Setting up the network using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs032.html#___sec34" style="font-size: 80%;">Setting up the network using Autograd; The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs033.html#___sec35" style="font-size: 80%;">Setting up the network using Autograd; The full program</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs034.html#___sec36" style="font-size: 80%;">Example: Solving the wave equation using Autograd and TensorFlow</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs035.html#___sec37" style="font-size: 80%;">The problem to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs036.html#___sec38" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs037.html#___sec39" style="font-size: 80%;">The analytical solution</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs038.html#___sec40" style="font-size: 80%;">Solving the wave equation - the full program using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs039.html#___sec41" style="font-size: 80%;">Solving the wave equation - the full program using TensorFlow</a></li>
     <!-- navigation toc: --> <li><a href="._odenn-bs040.html#___sec42" style="font-size: 80%;">Resources</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0026"></a>
<!-- !split -->

<h2 id="___sec28" class="anchor">Using gradient descent in TensorFlow to solve Poisson equation </h2>
The program follows the similar idea as for the logistic population model.

<p>
What has changed, is what the cost function minimizes and the trial solution.

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">tensorflow</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">tf</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #408080; font-style: italic">## Construction phase</span>

<span style="color: #408080; font-style: italic"># Just to reset the graph such that it is possible to rerun this in a</span>
<span style="color: #408080; font-style: italic"># Jupyter cell without resetting the whole kernel.</span>
tf<span style="color: #666666">.</span>reset_default_graph()

tf<span style="color: #666666">.</span>set_random_seed(<span style="color: #666666">4155</span>)

<span style="color: #408080; font-style: italic"># Convert the values the trial solution is evaluated at to a tensor.</span>
Nx <span style="color: #666666">=</span> <span style="color: #666666">10</span>
x <span style="color: #666666">=</span> np<span style="color: #666666">.</span>linspace(<span style="color: #666666">0</span>,<span style="color: #666666">1</span>, Nx)
x_tf <span style="color: #666666">=</span> tf<span style="color: #666666">.</span>convert_to_tensor(x<span style="color: #666666">.</span>reshape(<span style="color: #666666">-1</span>,<span style="color: #666666">1</span>),dtype<span style="color: #666666">=</span>tf<span style="color: #666666">.</span>float64)


num_iter <span style="color: #666666">=</span> <span style="color: #666666">10000</span>

<span style="color: #408080; font-style: italic"># Define the number of neurons at each hidden layer</span>
num_hidden_neurons <span style="color: #666666">=</span> [<span style="color: #666666">20</span>,<span style="color: #666666">10</span>]
num_hidden_layers <span style="color: #666666">=</span> np<span style="color: #666666">.</span>size(num_hidden_neurons)

<span style="color: #408080; font-style: italic"># Construct the network.</span>
<span style="color: #408080; font-style: italic"># tf.name_scope is used to group each step in the construction,</span>
<span style="color: #408080; font-style: italic"># just for a more organized visualization in TensorBoard</span>
<span style="color: #008000; font-weight: bold">with</span> tf<span style="color: #666666">.</span>name_scope(<span style="color: #BA2121">&#39;dnn&#39;</span>):

    <span style="color: #408080; font-style: italic"># Input layer</span>
    previous_layer <span style="color: #666666">=</span> x_tf

    <span style="color: #408080; font-style: italic"># Hidden layers</span>
    <span style="color: #008000; font-weight: bold">for</span> l <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(num_hidden_layers):
        current_layer <span style="color: #666666">=</span> tf<span style="color: #666666">.</span>layers<span style="color: #666666">.</span>dense(previous_layer, num_hidden_neurons[l], name<span style="color: #666666">=</span><span style="color: #BA2121">&#39;hidden</span><span style="color: #BB6688; font-weight: bold">%d</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>(l<span style="color: #666666">+1</span>), activation<span style="color: #666666">=</span>tf<span style="color: #666666">.</span>nn<span style="color: #666666">.</span>sigmoid)
        previous_layer <span style="color: #666666">=</span> current_layer

    <span style="color: #408080; font-style: italic"># Output layer</span>
    dnn_output <span style="color: #666666">=</span> tf<span style="color: #666666">.</span>layers<span style="color: #666666">.</span>dense(previous_layer, <span style="color: #666666">1</span>, name<span style="color: #666666">=</span><span style="color: #BA2121">&#39;output&#39;</span>)

<span style="color: #408080; font-style: italic"># Define the cost function</span>
<span style="color: #008000; font-weight: bold">with</span> tf<span style="color: #666666">.</span>name_scope(<span style="color: #BA2121">&#39;cost&#39;</span>):
    g_trial <span style="color: #666666">=</span> x_tf<span style="color: #666666">*</span>(<span style="color: #666666">1-</span>x_tf)<span style="color: #666666">*</span>dnn_output
    d_g_trial <span style="color: #666666">=</span> tf<span style="color: #666666">.</span>gradients(g_trial,x_tf)
    d2_g_trial <span style="color: #666666">=</span> tf<span style="color: #666666">.</span>gradients(d_g_trial,x_tf)

    right_side <span style="color: #666666">=</span> (<span style="color: #666666">3*</span>x_tf <span style="color: #666666">+</span> x_tf<span style="color: #666666">**2</span>)<span style="color: #666666">*</span>tf<span style="color: #666666">.</span>exp(x_tf)

    err <span style="color: #666666">=</span> tf<span style="color: #666666">.</span>square( <span style="color: #666666">-</span>d2_g_trial[<span style="color: #666666">0</span>] <span style="color: #666666">-</span> right_side)
    cost <span style="color: #666666">=</span> tf<span style="color: #666666">.</span>reduce_sum(err, name <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;cost&#39;</span>)

<span style="color: #408080; font-style: italic"># Choose the method to minimize the cost function, along with a learning rate</span>
learning_rate <span style="color: #666666">=</span> <span style="color: #666666">1e-2</span>
<span style="color: #008000; font-weight: bold">with</span> tf<span style="color: #666666">.</span>name_scope(<span style="color: #BA2121">&#39;train&#39;</span>):
    optimizer <span style="color: #666666">=</span> tf<span style="color: #666666">.</span>train<span style="color: #666666">.</span>GradientDescentOptimizer(learning_rate)
    traning_op <span style="color: #666666">=</span> optimizer<span style="color: #666666">.</span>minimize(cost)

g_dnn_tf <span style="color: #666666">=</span> <span style="color: #008000">None</span>

<span style="color: #408080; font-style: italic"># Define a node that initializes all of the other nodes in the computational graph</span>
<span style="color: #408080; font-style: italic"># used by TensorFlow:</span>
init <span style="color: #666666">=</span> tf<span style="color: #666666">.</span>global_variables_initializer()


<span style="color: #408080; font-style: italic">## Execution phase</span>

<span style="color: #408080; font-style: italic"># Start a session where the graph defined from the construction phase can be evaluated at:</span>

<span style="color: #008000; font-weight: bold">with</span> tf<span style="color: #666666">.</span>Session() <span style="color: #008000; font-weight: bold">as</span> sess:
    <span style="color: #408080; font-style: italic"># Initialize the whole graph</span>
    init<span style="color: #666666">.</span>run()

    <span style="color: #408080; font-style: italic"># Evaluate the initial cost:</span>
    <span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;Initial cost: </span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>cost<span style="color: #666666">.</span>eval())

    <span style="color: #408080; font-style: italic"># The traning of the network:</span>
    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(num_iter):
        sess<span style="color: #666666">.</span>run(traning_op)

    <span style="color: #408080; font-style: italic"># Training is done, and we have an approximate solution to the ODE</span>
    <span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;Final cost: </span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>cost<span style="color: #666666">.</span>eval())

    <span style="color: #408080; font-style: italic"># Store the result</span>
    g_dnn_tf <span style="color: #666666">=</span> g_trial<span style="color: #666666">.</span>eval()

    writer <span style="color: #666666">=</span> tf<span style="color: #666666">.</span>summary<span style="color: #666666">.</span>FileWriter(<span style="color: #BA2121">&quot;./output&quot;</span>, sess<span style="color: #666666">.</span>graph)
    writer<span style="color: #666666">.</span>close()

<span style="color: #408080; font-style: italic"># Evaluate the analytical function to compare with</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">g_analytic</span>(x):
    <span style="color: #008000; font-weight: bold">return</span> x<span style="color: #666666">*</span>(<span style="color: #666666">1-</span>x)<span style="color: #666666">*</span>np<span style="color: #666666">.</span>exp(x)

g_analytical <span style="color: #666666">=</span> g_analytic(x)

diff_tf <span style="color: #666666">=</span> g_dnn_tf <span style="color: #666666">-</span> g_analytical<span style="color: #666666">.</span>reshape(<span style="color: #666666">-1</span>,<span style="color: #666666">1</span>)

<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;</span><span style="color: #BB6622; font-weight: bold">\n</span><span style="color: #BA2121">Max absolute difference between the analytical solution and solution from TensorFlow DNN: </span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>np<span style="color: #666666">.</span>max(np<span style="color: #666666">.</span>abs(diff_tf)))

<span style="color: #408080; font-style: italic"># Plot the result</span>
plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">10</span>,<span style="color: #666666">10</span>))

plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&#39;Numerical solutions of the ODE&#39;</span>)

plt<span style="color: #666666">.</span>plot(x, g_dnn_tf)
plt<span style="color: #666666">.</span>plot(x, g_analytical)

plt<span style="color: #666666">.</span>legend([<span style="color: #BA2121">&#39;dnn, tensorflow&#39;</span>,<span style="color: #BA2121">&#39;exact&#39;</span>])
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;x&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;g(x)&#39;</span>)

plt<span style="color: #666666">.</span>show()
</pre></div>
<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._odenn-bs025.html">&laquo;</a></li>
  <li><a href="._odenn-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._odenn-bs018.html">19</a></li>
  <li><a href="._odenn-bs019.html">20</a></li>
  <li><a href="._odenn-bs020.html">21</a></li>
  <li><a href="._odenn-bs021.html">22</a></li>
  <li><a href="._odenn-bs022.html">23</a></li>
  <li><a href="._odenn-bs023.html">24</a></li>
  <li><a href="._odenn-bs024.html">25</a></li>
  <li><a href="._odenn-bs025.html">26</a></li>
  <li class="active"><a href="._odenn-bs026.html">27</a></li>
  <li><a href="._odenn-bs027.html">28</a></li>
  <li><a href="._odenn-bs028.html">29</a></li>
  <li><a href="._odenn-bs029.html">30</a></li>
  <li><a href="._odenn-bs030.html">31</a></li>
  <li><a href="._odenn-bs031.html">32</a></li>
  <li><a href="._odenn-bs032.html">33</a></li>
  <li><a href="._odenn-bs033.html">34</a></li>
  <li><a href="._odenn-bs034.html">35</a></li>
  <li><a href="._odenn-bs035.html">36</a></li>
  <li><a href="">...</a></li>
  <li><a href="._odenn-bs040.html">41</a></li>
  <li><a href="._odenn-bs027.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


</body>
</html>
    

