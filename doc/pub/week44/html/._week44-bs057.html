<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week44.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week44-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 44,  Convolutional Neural Networks (CNN)">
<title>Week 44,  Convolutional Neural Networks (CNN)</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week44.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week44-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 44', 2, None, 'plan-for-week-44'),
              ('Lab  sessions on Tuesday and Wednesday',
               2,
               None,
               'lab-sessions-on-tuesday-and-wednesday'),
              ('Material for Lecture Monday October 28',
               2,
               None,
               'material-for-lecture-monday-october-28'),
              ('Convolutional Neural Networks (recognizing images)',
               2,
               None,
               'convolutional-neural-networks-recognizing-images'),
              ('What is the Difference', 2, None, 'what-is-the-difference'),
              ('Neural Networks vs CNNs', 2, None, 'neural-networks-vs-cnns'),
              ('Why CNNS for images, sound files, medical images from CT scans '
               'etc?',
               2,
               None,
               'why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc'),
              ('Regular NNs don’t scale well to full images',
               2,
               None,
               'regular-nns-don-t-scale-well-to-full-images'),
              ('3D volumes of neurons', 2, None, '3d-volumes-of-neurons'),
              ('More on Dimensionalities', 2, None, 'more-on-dimensionalities'),
              ('Further remarks', 2, None, 'further-remarks'),
              ('Layers used to build CNNs',
               2,
               None,
               'layers-used-to-build-cnns'),
              ('Transforming images', 2, None, 'transforming-images'),
              ('CNNs in brief', 2, None, 'cnns-in-brief'),
              ('A deep CNN model ("From Raschka et '
               'al":"https://github.com/rasbt/machine-learning-book")',
               2,
               None,
               'a-deep-cnn-model-from-raschka-et-al-https-github-com-rasbt-machine-learning-book'),
              ('Key Idea', 2, None, 'key-idea'),
              ('How to do image compression before the era of deep learning',
               2,
               None,
               'how-to-do-image-compression-before-the-era-of-deep-learning'),
              ('The SVD example', 2, None, 'the-svd-example'),
              ('Mathematics of CNNs', 2, None, 'mathematics-of-cnns'),
              ('Convolution Examples: Polynomial multiplication',
               2,
               None,
               'convolution-examples-polynomial-multiplication'),
              ('Efficient Polynomial Multiplication',
               2,
               None,
               'efficient-polynomial-multiplication'),
              ('Further simplification', 2, None, 'further-simplification'),
              ('A more efficient way of coding the above Convolution',
               2,
               None,
               'a-more-efficient-way-of-coding-the-above-convolution'),
              ('Commutative process', 2, None, 'commutative-process'),
              ('Toeplitz matrices', 2, None, 'toeplitz-matrices'),
              ('Fourier series and Toeplitz matrices',
               2,
               None,
               'fourier-series-and-toeplitz-matrices'),
              ('Generalizing the above one-dimensional case',
               2,
               None,
               'generalizing-the-above-one-dimensional-case'),
              ('Memory considerations', 2, None, 'memory-considerations'),
              ('Padding', 2, None, 'padding'),
              ('New vector', 2, None, 'new-vector'),
              ('Rewriting as dot products',
               2,
               None,
               'rewriting-as-dot-products'),
              ('Cross correlation', 2, None, 'cross-correlation'),
              ('Two-dimensional objects', 2, None, 'two-dimensional-objects'),
              ('CNNs in more detail, simple example',
               2,
               None,
               'cnns-in-more-detail-simple-example'),
              ('The convolution stage', 2, None, 'the-convolution-stage'),
              ('Finding the number of parameters',
               2,
               None,
               'finding-the-number-of-parameters'),
              ('New image (or volume)', 2, None, 'new-image-or-volume'),
              ('Parameters to train, common settings',
               2,
               None,
               'parameters-to-train-common-settings'),
              ('Examples of CNN setups', 2, None, 'examples-of-cnn-setups'),
              ('Summarizing: Performing a general discrete convolution ("From '
               'Raschka et '
               'al":"https://github.com/rasbt/machine-learning-book")',
               2,
               None,
               'summarizing-performing-a-general-discrete-convolution-from-raschka-et-al-https-github-com-rasbt-machine-learning-book'),
              ('Pooling', 2, None, 'pooling'),
              ('Pooling arithmetic', 2, None, 'pooling-arithmetic'),
              ('Pooling types ("From Raschka et '
               'al":"https://github.com/rasbt/machine-learning-book")',
               2,
               None,
               'pooling-types-from-raschka-et-al-https-github-com-rasbt-machine-learning-book'),
              ('Building convolutional neural networks in Tensorflow and Keras',
               2,
               None,
               'building-convolutional-neural-networks-in-tensorflow-and-keras'),
              ('Setting it up', 2, None, 'setting-it-up'),
              ('The MNIST dataset again', 2, None, 'the-mnist-dataset-again'),
              ('Strong correlations', 2, None, 'strong-correlations'),
              ('Layers of a CNN', 2, None, 'layers-of-a-cnn'),
              ('Systematic reduction', 2, None, 'systematic-reduction'),
              ('Prerequisites: Collect and pre-process data',
               2,
               None,
               'prerequisites-collect-and-pre-process-data'),
              ('Importing Keras and Tensorflow',
               2,
               None,
               'importing-keras-and-tensorflow'),
              ('Running with Keras', 2, None, 'running-with-keras'),
              ('Final part', 2, None, 'final-part'),
              ('Final visualization', 2, None, 'final-visualization'),
              ('The CIFAR01 data set', 2, None, 'the-cifar01-data-set'),
              ('Verifying the data set', 2, None, 'verifying-the-data-set'),
              ('Set up  the model', 2, None, 'set-up-the-model'),
              ('Add Dense layers on top', 2, None, 'add-dense-layers-on-top'),
              ('Compile and train the model',
               2,
               None,
               'compile-and-train-the-model'),
              ('Finally, evaluate the model',
               2,
               None,
               'finally-evaluate-the-model'),
              ('Building our own CNN code',
               2,
               None,
               'building-our-own-cnn-code'),
              ('List of contents:', 3, None, 'list-of-contents'),
              ('Schedulers', 3, None, 'schedulers'),
              ('Usage of schedulers', 3, None, 'usage-of-schedulers'),
              ('Cost functions', 3, None, 'cost-functions'),
              ('Usage of cost functions', 3, None, 'usage-of-cost-functions'),
              ('Activation functions', 3, None, 'activation-functions'),
              ('Usage of activation functions',
               3,
               None,
               'usage-of-activation-functions'),
              ('Convolution', 3, None, 'convolution'),
              ('Layers', 3, None, 'layers'),
              ('Convolution2DLayer: convolution in a hidden layer',
               3,
               None,
               'convolution2dlayer-convolution-in-a-hidden-layer'),
              ('Backpropagation in the convolutional layer',
               3,
               None,
               'backpropagation-in-the-convolutional-layer'),
              ('Demonstration', 3, None, 'demonstration'),
              ('Pooling Layer', 3, None, 'pooling-layer'),
              ('Flattening Layer', 3, None, 'flattening-layer'),
              ('Fully Connected Layers', 3, None, 'fully-connected-layers'),
              ('Optimized Convolution2DLayer',
               3,
               None,
               'optimized-convolution2dlayer'),
              ('The Convolutional Neural Network (CNN)',
               3,
               None,
               'the-convolutional-neural-network-cnn'),
              ('Usage of CNN code', 3, None, 'usage-of-cnn-code'),
              ('Additional Remarks', 3, None, 'additional-remarks'),
              ('Remarks on the speed', 3, None, 'remarks-on-the-speed'),
              ('Convolution using separable kernels',
               3,
               None,
               'convolution-using-separable-kernels'),
              ('Convolution in the Fourier domain',
               3,
               None,
               'convolution-in-the-fourier-domain')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week44-bs.html">Week 44,  Convolutional Neural Networks (CNN)</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week44-bs001.html#plan-for-week-44" style="font-size: 80%;"><b>Plan for week 44</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs002.html#lab-sessions-on-tuesday-and-wednesday" style="font-size: 80%;"><b>Lab  sessions on Tuesday and Wednesday</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs003.html#material-for-lecture-monday-october-28" style="font-size: 80%;"><b>Material for Lecture Monday October 28</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs004.html#convolutional-neural-networks-recognizing-images" style="font-size: 80%;"><b>Convolutional Neural Networks (recognizing images)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs005.html#what-is-the-difference" style="font-size: 80%;"><b>What is the Difference</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs006.html#neural-networks-vs-cnns" style="font-size: 80%;"><b>Neural Networks vs CNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs007.html#why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc" style="font-size: 80%;"><b>Why CNNS for images, sound files, medical images from CT scans etc?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs008.html#regular-nns-don-t-scale-well-to-full-images" style="font-size: 80%;"><b>Regular NNs don’t scale well to full images</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs009.html#3d-volumes-of-neurons" style="font-size: 80%;"><b>3D volumes of neurons</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs010.html#more-on-dimensionalities" style="font-size: 80%;"><b>More on Dimensionalities</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs011.html#further-remarks" style="font-size: 80%;"><b>Further remarks</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs012.html#layers-used-to-build-cnns" style="font-size: 80%;"><b>Layers used to build CNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs013.html#transforming-images" style="font-size: 80%;"><b>Transforming images</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs014.html#cnns-in-brief" style="font-size: 80%;"><b>CNNs in brief</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs015.html#a-deep-cnn-model-from-raschka-et-al-https-github-com-rasbt-machine-learning-book" style="font-size: 80%;"><b>A deep CNN model ("From Raschka et al":"https://github.com/rasbt/machine-learning-book")</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs016.html#key-idea" style="font-size: 80%;"><b>Key Idea</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs017.html#how-to-do-image-compression-before-the-era-of-deep-learning" style="font-size: 80%;"><b>How to do image compression before the era of deep learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs018.html#the-svd-example" style="font-size: 80%;"><b>The SVD example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs019.html#mathematics-of-cnns" style="font-size: 80%;"><b>Mathematics of CNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs020.html#convolution-examples-polynomial-multiplication" style="font-size: 80%;"><b>Convolution Examples: Polynomial multiplication</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs021.html#efficient-polynomial-multiplication" style="font-size: 80%;"><b>Efficient Polynomial Multiplication</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs022.html#further-simplification" style="font-size: 80%;"><b>Further simplification</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs023.html#a-more-efficient-way-of-coding-the-above-convolution" style="font-size: 80%;"><b>A more efficient way of coding the above Convolution</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs024.html#commutative-process" style="font-size: 80%;"><b>Commutative process</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs025.html#toeplitz-matrices" style="font-size: 80%;"><b>Toeplitz matrices</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs026.html#fourier-series-and-toeplitz-matrices" style="font-size: 80%;"><b>Fourier series and Toeplitz matrices</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs027.html#generalizing-the-above-one-dimensional-case" style="font-size: 80%;"><b>Generalizing the above one-dimensional case</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs028.html#memory-considerations" style="font-size: 80%;"><b>Memory considerations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs029.html#padding" style="font-size: 80%;"><b>Padding</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs030.html#new-vector" style="font-size: 80%;"><b>New vector</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs031.html#rewriting-as-dot-products" style="font-size: 80%;"><b>Rewriting as dot products</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs032.html#cross-correlation" style="font-size: 80%;"><b>Cross correlation</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs032.html#two-dimensional-objects" style="font-size: 80%;"><b>Two-dimensional objects</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs033.html#cnns-in-more-detail-simple-example" style="font-size: 80%;"><b>CNNs in more detail, simple example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs034.html#the-convolution-stage" style="font-size: 80%;"><b>The convolution stage</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#finding-the-number-of-parameters" style="font-size: 80%;"><b>Finding the number of parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs036.html#new-image-or-volume" style="font-size: 80%;"><b>New image (or volume)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs037.html#parameters-to-train-common-settings" style="font-size: 80%;"><b>Parameters to train, common settings</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs038.html#examples-of-cnn-setups" style="font-size: 80%;"><b>Examples of CNN setups</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs039.html#summarizing-performing-a-general-discrete-convolution-from-raschka-et-al-https-github-com-rasbt-machine-learning-book" style="font-size: 80%;"><b>Summarizing: Performing a general discrete convolution ("From Raschka et al":"https://github.com/rasbt/machine-learning-book")</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs040.html#pooling" style="font-size: 80%;"><b>Pooling</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs041.html#pooling-arithmetic" style="font-size: 80%;"><b>Pooling arithmetic</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs042.html#pooling-types-from-raschka-et-al-https-github-com-rasbt-machine-learning-book" style="font-size: 80%;"><b>Pooling types ("From Raschka et al":"https://github.com/rasbt/machine-learning-book")</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs043.html#building-convolutional-neural-networks-in-tensorflow-and-keras" style="font-size: 80%;"><b>Building convolutional neural networks in Tensorflow and Keras</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs044.html#setting-it-up" style="font-size: 80%;"><b>Setting it up</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs045.html#the-mnist-dataset-again" style="font-size: 80%;"><b>The MNIST dataset again</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs046.html#strong-correlations" style="font-size: 80%;"><b>Strong correlations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs047.html#layers-of-a-cnn" style="font-size: 80%;"><b>Layers of a CNN</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#systematic-reduction" style="font-size: 80%;"><b>Systematic reduction</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs049.html#prerequisites-collect-and-pre-process-data" style="font-size: 80%;"><b>Prerequisites: Collect and pre-process data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs050.html#importing-keras-and-tensorflow" style="font-size: 80%;"><b>Importing Keras and Tensorflow</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs051.html#running-with-keras" style="font-size: 80%;"><b>Running with Keras</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs052.html#final-part" style="font-size: 80%;"><b>Final part</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs053.html#final-visualization" style="font-size: 80%;"><b>Final visualization</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs054.html#the-cifar01-data-set" style="font-size: 80%;"><b>The CIFAR01 data set</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs055.html#verifying-the-data-set" style="font-size: 80%;"><b>Verifying the data set</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs056.html#set-up-the-model" style="font-size: 80%;"><b>Set up  the model</b></a></li>
     <!-- navigation toc: --> <li><a href="#add-dense-layers-on-top" style="font-size: 80%;"><b>Add Dense layers on top</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs058.html#compile-and-train-the-model" style="font-size: 80%;"><b>Compile and train the model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs059.html#finally-evaluate-the-model" style="font-size: 80%;"><b>Finally, evaluate the model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#building-our-own-cnn-code" style="font-size: 80%;"><b>Building our own CNN code</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#list-of-contents" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;List of contents:</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#schedulers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Schedulers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#usage-of-schedulers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of schedulers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#cost-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Cost functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#usage-of-cost-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of cost functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#activation-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Activation functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#usage-of-activation-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of activation functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#convolution" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#layers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Layers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#convolution2dlayer-convolution-in-a-hidden-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution2DLayer: convolution in a hidden layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#backpropagation-in-the-convolutional-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Backpropagation in the convolutional layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#demonstration" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Demonstration</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#pooling-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Pooling Layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#flattening-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Flattening Layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#fully-connected-layers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Fully Connected Layers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#optimized-convolution2dlayer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Optimized Convolution2DLayer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#the-convolutional-neural-network-cnn" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The Convolutional Neural Network (CNN)</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#usage-of-cnn-code" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of CNN code</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#additional-remarks" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Additional Remarks</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#remarks-on-the-speed" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Remarks on the speed</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#convolution-using-separable-kernels" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution using separable kernels</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#convolution-in-the-fourier-domain" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution in the Fourier domain</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0057"></a>
<!-- !split -->
<h2 id="add-dense-layers-on-top" class="anchor">Add Dense layers on top </h2>

<p>To complete our model, you will feed the last output tensor from the
convolutional base (of shape (4, 4, 64)) into one or more Dense layers
to perform classification. Dense layers take vectors as input (which
are 1D), while the current output is a 3D tensor. First, you will
flatten (or unroll) the 3D output to 1D, then add one or more Dense
layers on top. CIFAR has 10 output classes, so you use a final Dense
layer with 10 outputs and a softmax activation.
</p>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">model<span style="color: #666666">.</span>add(layers<span style="color: #666666">.</span>Flatten())
model<span style="color: #666666">.</span>add(layers<span style="color: #666666">.</span>Dense(<span style="color: #666666">64</span>, activation<span style="color: #666666">=</span><span style="color: #BA2121">&#39;relu&#39;</span>))
model<span style="color: #666666">.</span>add(layers<span style="color: #666666">.</span>Dense(<span style="color: #666666">10</span>))
<span style="color: #408080; font-style: italic"># Here&#39;s the complete architecture of our model</span>

model<span style="color: #666666">.</span>summary()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>As you can see, our (4, 4, 64) outputs were flattened into vectors of shape (1024) before going through two Dense layers.</p>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week44-bs056.html">&laquo;</a></li>
  <li><a href="._week44-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week44-bs049.html">50</a></li>
  <li><a href="._week44-bs050.html">51</a></li>
  <li><a href="._week44-bs051.html">52</a></li>
  <li><a href="._week44-bs052.html">53</a></li>
  <li><a href="._week44-bs053.html">54</a></li>
  <li><a href="._week44-bs054.html">55</a></li>
  <li><a href="._week44-bs055.html">56</a></li>
  <li><a href="._week44-bs056.html">57</a></li>
  <li class="active"><a href="._week44-bs057.html">58</a></li>
  <li><a href="._week44-bs058.html">59</a></li>
  <li><a href="._week44-bs059.html">60</a></li>
  <li><a href="._week44-bs060.html">61</a></li>
  <li><a href="._week44-bs058.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

