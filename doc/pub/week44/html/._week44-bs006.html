<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week44.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week44-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 44,  Solving differential equations with neural networks and start Convolutional Neural Networks (CNN)">
<title>Week 44,  Solving differential equations with neural networks and start Convolutional Neural Networks (CNN)</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week44.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week44-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 44', 2, None, 'plan-for-week-44'),
              ('Lab  sessions on Tuesday and Wednesday',
               2,
               None,
               'lab-sessions-on-tuesday-and-wednesday'),
              ('Material for Lecture Monday October 27',
               2,
               None,
               'material-for-lecture-monday-october-27'),
              ('Solving differential equations  with Deep Learning',
               2,
               None,
               'solving-differential-equations-with-deep-learning'),
              ('Ordinary Differential Equations first',
               2,
               None,
               'ordinary-differential-equations-first'),
              ('The trial solution', 2, None, 'the-trial-solution'),
              ('Minimization process', 2, None, 'minimization-process'),
              ('Minimizing the cost function using gradient descent and '
               'automatic differentiation',
               2,
               None,
               'minimizing-the-cost-function-using-gradient-descent-and-automatic-differentiation'),
              ('Example: Exponential decay',
               2,
               None,
               'example-exponential-decay'),
              ('The function to solve for',
               2,
               None,
               'the-function-to-solve-for'),
              ('The trial solution', 2, None, 'the-trial-solution'),
              ('Setup of Network', 2, None, 'setup-of-network'),
              ('Reformulating the problem',
               2,
               None,
               'reformulating-the-problem'),
              ('More technicalities', 2, None, 'more-technicalities'),
              ('More details', 2, None, 'more-details'),
              ('A possible implementation of a neural network',
               2,
               None,
               'a-possible-implementation-of-a-neural-network'),
              ('Technicalities', 2, None, 'technicalities'),
              ('Final technicalities I', 2, None, 'final-technicalities-i'),
              ('Final technicalities II', 2, None, 'final-technicalities-ii'),
              ('Final technicalities III', 2, None, 'final-technicalities-iii'),
              ('Final technicalities IV', 2, None, 'final-technicalities-iv'),
              ('Back propagation', 2, None, 'back-propagation'),
              ('Gradient descent', 2, None, 'gradient-descent'),
              ('The code for solving the ODE',
               2,
               None,
               'the-code-for-solving-the-ode'),
              ('The network with one input layer, specified number of hidden '
               'layers, and one output layer',
               2,
               None,
               'the-network-with-one-input-layer-specified-number-of-hidden-layers-and-one-output-layer'),
              ('Example: Population growth',
               2,
               None,
               'example-population-growth'),
              ('Setting up the problem', 2, None, 'setting-up-the-problem'),
              ('The trial solution', 2, None, 'the-trial-solution'),
              ('The program using Autograd',
               2,
               None,
               'the-program-using-autograd'),
              ('Using forward Euler to solve the ODE',
               2,
               None,
               'using-forward-euler-to-solve-the-ode'),
              ('Example: Solving the one dimensional Poisson equation',
               2,
               None,
               'example-solving-the-one-dimensional-poisson-equation'),
              ('The specific equation to solve for',
               2,
               None,
               'the-specific-equation-to-solve-for'),
              ('Solving the equation using Autograd',
               2,
               None,
               'solving-the-equation-using-autograd'),
              ('Comparing with a numerical scheme',
               2,
               None,
               'comparing-with-a-numerical-scheme'),
              ('Setting up the code', 2, None, 'setting-up-the-code'),
              ('Partial Differential Equations',
               2,
               None,
               'partial-differential-equations'),
              ('Type of problem', 2, None, 'type-of-problem'),
              ('Network requirements', 2, None, 'network-requirements'),
              ('More details', 2, None, 'more-details'),
              ('Example: The diffusion equation',
               2,
               None,
               'example-the-diffusion-equation'),
              ('Defining the problem', 2, None, 'defining-the-problem'),
              ('Setting up the network using Autograd',
               2,
               None,
               'setting-up-the-network-using-autograd'),
              ('Setting up the network using Autograd; The trial solution',
               2,
               None,
               'setting-up-the-network-using-autograd-the-trial-solution'),
              ('Why the Jacobian?', 2, None, 'why-the-jacobian'),
              ('Setting up the network using Autograd; The full program',
               2,
               None,
               'setting-up-the-network-using-autograd-the-full-program'),
              ('Resources on differential equations and deep learning',
               2,
               None,
               'resources-on-differential-equations-and-deep-learning'),
              ('Convolutional Neural Networks (recognizing images)',
               2,
               None,
               'convolutional-neural-networks-recognizing-images'),
              ('What is the Difference', 2, None, 'what-is-the-difference'),
              ('Neural Networks vs CNNs', 2, None, 'neural-networks-vs-cnns'),
              ('Why CNNS for images, sound files, medical images from CT scans '
               'etc?',
               2,
               None,
               'why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc'),
              ('Regular NNs don’t scale well to full images',
               2,
               None,
               'regular-nns-don-t-scale-well-to-full-images'),
              ('3D volumes of neurons', 2, None, '3d-volumes-of-neurons'),
              ('More on Dimensionalities', 2, None, 'more-on-dimensionalities'),
              ('Further remarks', 2, None, 'further-remarks'),
              ('Layers used to build CNNs',
               2,
               None,
               'layers-used-to-build-cnns'),
              ('Transforming images', 2, None, 'transforming-images'),
              ('CNNs in brief', 2, None, 'cnns-in-brief'),
              ('A deep CNN model ("From Raschka et '
               'al":"https://github.com/rasbt/machine-learning-book")',
               2,
               None,
               'a-deep-cnn-model-from-raschka-et-al-https-github-com-rasbt-machine-learning-book'),
              ('Key Idea', 2, None, 'key-idea'),
              ('How to do image compression before the era of deep learning',
               2,
               None,
               'how-to-do-image-compression-before-the-era-of-deep-learning'),
              ('The SVD example', 2, None, 'the-svd-example'),
              ('Mathematics of CNNs', 2, None, 'mathematics-of-cnns'),
              ('Convolution Examples: Polynomial multiplication',
               2,
               None,
               'convolution-examples-polynomial-multiplication'),
              ('Efficient Polynomial Multiplication',
               2,
               None,
               'efficient-polynomial-multiplication'),
              ('Further simplification', 2, None, 'further-simplification'),
              ('A more efficient way of coding the above Convolution',
               2,
               None,
               'a-more-efficient-way-of-coding-the-above-convolution'),
              ('Commutative process', 2, None, 'commutative-process'),
              ('Toeplitz matrices', 2, None, 'toeplitz-matrices'),
              ('Fourier series and Toeplitz matrices',
               2,
               None,
               'fourier-series-and-toeplitz-matrices'),
              ('Generalizing the above one-dimensional case',
               2,
               None,
               'generalizing-the-above-one-dimensional-case'),
              ('Memory considerations', 2, None, 'memory-considerations'),
              ('Padding', 2, None, 'padding'),
              ('New vector', 2, None, 'new-vector'),
              ('Rewriting as dot products',
               2,
               None,
               'rewriting-as-dot-products'),
              ('Cross correlation', 2, None, 'cross-correlation'),
              ('Two-dimensional objects', 2, None, 'two-dimensional-objects'),
              ('CNNs in more detail, simple example',
               2,
               None,
               'cnns-in-more-detail-simple-example'),
              ('The convolution stage', 2, None, 'the-convolution-stage'),
              ('Finding the number of parameters',
               2,
               None,
               'finding-the-number-of-parameters'),
              ('New image (or volume)', 2, None, 'new-image-or-volume'),
              ('Parameters to train, common settings',
               2,
               None,
               'parameters-to-train-common-settings'),
              ('Examples of CNN setups', 2, None, 'examples-of-cnn-setups'),
              ('Summarizing: Performing a general discrete convolution ("From '
               'Raschka et '
               'al":"https://github.com/rasbt/machine-learning-book")',
               2,
               None,
               'summarizing-performing-a-general-discrete-convolution-from-raschka-et-al-https-github-com-rasbt-machine-learning-book'),
              ('Pooling', 2, None, 'pooling'),
              ('Pooling arithmetic', 2, None, 'pooling-arithmetic'),
              ('Pooling types ("From Raschka et '
               'al":"https://github.com/rasbt/machine-learning-book")',
               2,
               None,
               'pooling-types-from-raschka-et-al-https-github-com-rasbt-machine-learning-book'),
              ('Building convolutional neural networks in Tensorflow/Keras and '
               'PyTorch',
               2,
               None,
               'building-convolutional-neural-networks-in-tensorflow-keras-and-pytorch')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week44-bs.html">Week 44,  Solving differential equations with neural networks and start Convolutional Neural Networks (CNN)</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week44-bs001.html#plan-for-week-44" style="font-size: 80%;">Plan for week 44</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs002.html#lab-sessions-on-tuesday-and-wednesday" style="font-size: 80%;">Lab  sessions on Tuesday and Wednesday</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs003.html#material-for-lecture-monday-october-27" style="font-size: 80%;">Material for Lecture Monday October 27</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs004.html#solving-differential-equations-with-deep-learning" style="font-size: 80%;">Solving differential equations  with Deep Learning</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs005.html#ordinary-differential-equations-first" style="font-size: 80%;">Ordinary Differential Equations first</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs028.html#the-trial-solution" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs007.html#minimization-process" style="font-size: 80%;">Minimization process</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs008.html#minimizing-the-cost-function-using-gradient-descent-and-automatic-differentiation" style="font-size: 80%;">Minimizing the cost function using gradient descent and automatic differentiation</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs009.html#example-exponential-decay" style="font-size: 80%;">Example: Exponential decay</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs010.html#the-function-to-solve-for" style="font-size: 80%;">The function to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs028.html#the-trial-solution" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs012.html#setup-of-network" style="font-size: 80%;">Setup of Network</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs013.html#reformulating-the-problem" style="font-size: 80%;">Reformulating the problem</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs014.html#more-technicalities" style="font-size: 80%;">More technicalities</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs039.html#more-details" style="font-size: 80%;">More details</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs016.html#a-possible-implementation-of-a-neural-network" style="font-size: 80%;">A possible implementation of a neural network</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs017.html#technicalities" style="font-size: 80%;">Technicalities</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs018.html#final-technicalities-i" style="font-size: 80%;">Final technicalities I</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs019.html#final-technicalities-ii" style="font-size: 80%;">Final technicalities II</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs020.html#final-technicalities-iii" style="font-size: 80%;">Final technicalities III</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs021.html#final-technicalities-iv" style="font-size: 80%;">Final technicalities IV</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs022.html#back-propagation" style="font-size: 80%;">Back propagation</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs023.html#gradient-descent" style="font-size: 80%;">Gradient descent</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs024.html#the-code-for-solving-the-ode" style="font-size: 80%;">The code for solving the ODE</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs025.html#the-network-with-one-input-layer-specified-number-of-hidden-layers-and-one-output-layer" style="font-size: 80%;">The network with one input layer, specified number of hidden layers, and one output layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs026.html#example-population-growth" style="font-size: 80%;">Example: Population growth</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs027.html#setting-up-the-problem" style="font-size: 80%;">Setting up the problem</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs028.html#the-trial-solution" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs029.html#the-program-using-autograd" style="font-size: 80%;">The program using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs030.html#using-forward-euler-to-solve-the-ode" style="font-size: 80%;">Using forward Euler to solve the ODE</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs031.html#example-solving-the-one-dimensional-poisson-equation" style="font-size: 80%;">Example: Solving the one dimensional Poisson equation</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs032.html#the-specific-equation-to-solve-for" style="font-size: 80%;">The specific equation to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs033.html#solving-the-equation-using-autograd" style="font-size: 80%;">Solving the equation using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs034.html#comparing-with-a-numerical-scheme" style="font-size: 80%;">Comparing with a numerical scheme</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#setting-up-the-code" style="font-size: 80%;">Setting up the code</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs036.html#partial-differential-equations" style="font-size: 80%;">Partial Differential Equations</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs037.html#type-of-problem" style="font-size: 80%;">Type of problem</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs038.html#network-requirements" style="font-size: 80%;">Network requirements</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs039.html#more-details" style="font-size: 80%;">More details</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs040.html#example-the-diffusion-equation" style="font-size: 80%;">Example: The diffusion equation</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs041.html#defining-the-problem" style="font-size: 80%;">Defining the problem</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs042.html#setting-up-the-network-using-autograd" style="font-size: 80%;">Setting up the network using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs043.html#setting-up-the-network-using-autograd-the-trial-solution" style="font-size: 80%;">Setting up the network using Autograd; The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs044.html#why-the-jacobian" style="font-size: 80%;">Why the Jacobian?</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs045.html#setting-up-the-network-using-autograd-the-full-program" style="font-size: 80%;">Setting up the network using Autograd; The full program</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs046.html#resources-on-differential-equations-and-deep-learning" style="font-size: 80%;">Resources on differential equations and deep learning</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs047.html#convolutional-neural-networks-recognizing-images" style="font-size: 80%;">Convolutional Neural Networks (recognizing images)</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs048.html#what-is-the-difference" style="font-size: 80%;">What is the Difference</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs049.html#neural-networks-vs-cnns" style="font-size: 80%;">Neural Networks vs CNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs050.html#why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc" style="font-size: 80%;">Why CNNS for images, sound files, medical images from CT scans etc?</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs051.html#regular-nns-don-t-scale-well-to-full-images" style="font-size: 80%;">Regular NNs don’t scale well to full images</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs052.html#3d-volumes-of-neurons" style="font-size: 80%;">3D volumes of neurons</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs053.html#more-on-dimensionalities" style="font-size: 80%;">More on Dimensionalities</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs054.html#further-remarks" style="font-size: 80%;">Further remarks</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs055.html#layers-used-to-build-cnns" style="font-size: 80%;">Layers used to build CNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs056.html#transforming-images" style="font-size: 80%;">Transforming images</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs057.html#cnns-in-brief" style="font-size: 80%;">CNNs in brief</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs058.html#a-deep-cnn-model-from-raschka-et-al-https-github-com-rasbt-machine-learning-book" style="font-size: 80%;">A deep CNN model ("From Raschka et al":"https://github.com/rasbt/machine-learning-book")</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs059.html#key-idea" style="font-size: 80%;">Key Idea</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs060.html#how-to-do-image-compression-before-the-era-of-deep-learning" style="font-size: 80%;">How to do image compression before the era of deep learning</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs061.html#the-svd-example" style="font-size: 80%;">The SVD example</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs062.html#mathematics-of-cnns" style="font-size: 80%;">Mathematics of CNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs063.html#convolution-examples-polynomial-multiplication" style="font-size: 80%;">Convolution Examples: Polynomial multiplication</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs064.html#efficient-polynomial-multiplication" style="font-size: 80%;">Efficient Polynomial Multiplication</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs065.html#further-simplification" style="font-size: 80%;">Further simplification</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs066.html#a-more-efficient-way-of-coding-the-above-convolution" style="font-size: 80%;">A more efficient way of coding the above Convolution</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs067.html#commutative-process" style="font-size: 80%;">Commutative process</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs068.html#toeplitz-matrices" style="font-size: 80%;">Toeplitz matrices</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs069.html#fourier-series-and-toeplitz-matrices" style="font-size: 80%;">Fourier series and Toeplitz matrices</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs070.html#generalizing-the-above-one-dimensional-case" style="font-size: 80%;">Generalizing the above one-dimensional case</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs071.html#memory-considerations" style="font-size: 80%;">Memory considerations</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs072.html#padding" style="font-size: 80%;">Padding</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs073.html#new-vector" style="font-size: 80%;">New vector</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs074.html#rewriting-as-dot-products" style="font-size: 80%;">Rewriting as dot products</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs075.html#cross-correlation" style="font-size: 80%;">Cross correlation</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs075.html#two-dimensional-objects" style="font-size: 80%;">Two-dimensional objects</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs076.html#cnns-in-more-detail-simple-example" style="font-size: 80%;">CNNs in more detail, simple example</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs077.html#the-convolution-stage" style="font-size: 80%;">The convolution stage</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs078.html#finding-the-number-of-parameters" style="font-size: 80%;">Finding the number of parameters</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs079.html#new-image-or-volume" style="font-size: 80%;">New image (or volume)</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs080.html#parameters-to-train-common-settings" style="font-size: 80%;">Parameters to train, common settings</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs081.html#examples-of-cnn-setups" style="font-size: 80%;">Examples of CNN setups</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs082.html#summarizing-performing-a-general-discrete-convolution-from-raschka-et-al-https-github-com-rasbt-machine-learning-book" style="font-size: 80%;">Summarizing: Performing a general discrete convolution ("From Raschka et al":"https://github.com/rasbt/machine-learning-book")</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs083.html#pooling" style="font-size: 80%;">Pooling</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs084.html#pooling-arithmetic" style="font-size: 80%;">Pooling arithmetic</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs085.html#pooling-types-from-raschka-et-al-https-github-com-rasbt-machine-learning-book" style="font-size: 80%;">Pooling types ("From Raschka et al":"https://github.com/rasbt/machine-learning-book")</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs086.html#building-convolutional-neural-networks-in-tensorflow-keras-and-pytorch" style="font-size: 80%;">Building convolutional neural networks in Tensorflow/Keras and PyTorch</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0006"></a>
<!-- !split -->
<h2 id="the-trial-solution" class="anchor">The trial solution </h2>

<p>Let the trial solution \( g_t(x) \) be</p>

$$
\begin{equation}
	g_t(x) = h_1(x) + h_2(x,N(x,P))
\tag{2}
\end{equation}
$$

<p>where \( h_1(x) \) is a function that makes \( g_t(x) \) satisfy a given set
of conditions, \( N(x,P) \) a neural network with weights and biases
described by \( P \) and \( h_2(x, N(x,P)) \) some expression involving the
neural network.  The role of the function \( h_2(x, N(x,P)) \), is to
ensure that the output from \( N(x,P) \) is zero when \( g_t(x) \) is
evaluated at the values of \( x \) where the given conditions must be
satisfied.  The function \( h_1(x) \) should alone make \( g_t(x) \) satisfy
the conditions.
</p>

<p>But what about the network \( N(x,P) \)?</p>

<p>As described previously, an optimization method could be used to minimize the parameters of a neural network, that being its weights and biases, through backward propagation.</p>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week44-bs005.html">&laquo;</a></li>
  <li><a href="._week44-bs000.html">1</a></li>
  <li><a href="._week44-bs001.html">2</a></li>
  <li><a href="._week44-bs002.html">3</a></li>
  <li><a href="._week44-bs003.html">4</a></li>
  <li><a href="._week44-bs004.html">5</a></li>
  <li><a href="._week44-bs005.html">6</a></li>
  <li class="active"><a href="._week44-bs006.html">7</a></li>
  <li><a href="._week44-bs007.html">8</a></li>
  <li><a href="._week44-bs008.html">9</a></li>
  <li><a href="._week44-bs009.html">10</a></li>
  <li><a href="._week44-bs010.html">11</a></li>
  <li><a href="._week44-bs011.html">12</a></li>
  <li><a href="._week44-bs012.html">13</a></li>
  <li><a href="._week44-bs013.html">14</a></li>
  <li><a href="._week44-bs014.html">15</a></li>
  <li><a href="._week44-bs015.html">16</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week44-bs086.html">87</a></li>
  <li><a href="._week44-bs007.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

