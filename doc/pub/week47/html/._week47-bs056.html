<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week47.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week47-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 47: Recurrent neural networks and Autoencoders">
<title>Week 47: Recurrent neural networks and Autoencoders</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week47.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week47-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 47', 2, None, 'plan-for-week-47'),
              ('Reading recommendations RNNs',
               2,
               None,
               'reading-recommendations-rnns'),
              ('TensorFlow examples', 2, None, 'tensorflow-examples'),
              ('Reading recommendations: Autoencoders (AE)',
               2,
               None,
               'reading-recommendations-autoencoders-ae'),
              ('What is a recurrent NN?', 2, None, 'what-is-a-recurrent-nn'),
              ('Why RNNs?', 2, None, 'why-rnns'),
              ('More whys', 2, None, 'more-whys'),
              ('RNNs in more detail', 2, None, 'rnns-in-more-detail'),
              ('RNNs in more detail, part 2',
               2,
               None,
               'rnns-in-more-detail-part-2'),
              ('RNNs in more detail, part 3',
               2,
               None,
               'rnns-in-more-detail-part-3'),
              ('RNNs in more detail, part 4',
               2,
               None,
               'rnns-in-more-detail-part-4'),
              ('RNNs in more detail, part 5',
               2,
               None,
               'rnns-in-more-detail-part-5'),
              ('RNNs in more detail, part 6',
               2,
               None,
               'rnns-in-more-detail-part-6'),
              ('RNNs in more detail, part 7',
               2,
               None,
               'rnns-in-more-detail-part-7'),
              ('RNN Forward Pass Equations',
               2,
               None,
               'rnn-forward-pass-equations'),
              ('Unrolled RNN in Time', 2, None, 'unrolled-rnn-in-time'),
              ('Example Task: Character-level RNN Classification',
               2,
               None,
               'example-task-character-level-rnn-classification'),
              ('PyTorch: Defining a Simple RNN, using Tensorflow',
               2,
               None,
               'pytorch-defining-a-simple-rnn-using-tensorflow'),
              ('Similar example using PyTorch',
               2,
               None,
               'similar-example-using-pytorch'),
              ('Backpropagation Through Time (BPTT) and Gradients',
               2,
               None,
               'backpropagation-through-time-bptt-and-gradients'),
              ('Truncated BPTT and Gradient Clipping',
               2,
               None,
               'truncated-bptt-and-gradient-clipping'),
              ('Limitations and Considerations',
               2,
               None,
               'limitations-and-considerations'),
              ('PyTorch RNN Time Series Example',
               2,
               None,
               'pytorch-rnn-time-series-example'),
              ('Tensorflow (Keras) RNN Time Series Example',
               2,
               None,
               'tensorflow-keras-rnn-time-series-example'),
              ('The mathematics of RNNs, the basic architecture',
               2,
               None,
               'the-mathematics-of-rnns-the-basic-architecture'),
              ('Gating mechanism: Long Short Term Memory (LSTM)',
               2,
               None,
               'gating-mechanism-long-short-term-memory-lstm'),
              ('Implementing a memory cell in a neural network',
               2,
               None,
               'implementing-a-memory-cell-in-a-neural-network'),
              ('LSTM details', 2, None, 'lstm-details'),
              ('LSTM Cell and Gates', 2, None, 'lstm-cell-and-gates'),
              ('Core LSTM Equations', 2, None, 'core-lstm-equations'),
              ('Gate Intuition and Dynamics',
               2,
               None,
               'gate-intuition-and-dynamics'),
              ('Basic layout (All figures from Raschka *et al.,*)',
               2,
               None,
               'basic-layout-all-figures-from-raschka-et-al'),
              ('LSTM details', 2, None, 'lstm-details'),
              ('Comparing with a standard  RNN',
               2,
               None,
               'comparing-with-a-standard-rnn'),
              ('LSTM details I', 2, None, 'lstm-details-i'),
              ('LSTM details II', 2, None, 'lstm-details-ii'),
              ('LSTM details III', 2, None, 'lstm-details-iii'),
              ('Forget gate', 2, None, 'forget-gate'),
              ('The forget gate', 2, None, 'the-forget-gate'),
              ('Basic layout', 2, None, 'basic-layout'),
              ('Input gate', 2, None, 'input-gate'),
              ('Short summary', 2, None, 'short-summary'),
              ('Forget and input', 2, None, 'forget-and-input'),
              ('Basic layout', 2, None, 'basic-layout'),
              ('Output gate', 2, None, 'output-gate'),
              ('LSTM Implementation (Code Example)',
               2,
               None,
               'lstm-implementation-code-example'),
              ('Example: Modeling Dynamical Systems',
               2,
               None,
               'example-modeling-dynamical-systems'),
              ('Example: Biological Sequences',
               2,
               None,
               'example-biological-sequences'),
              ('Training Tips and Variants',
               2,
               None,
               'training-tips-and-variants'),
              ('LSTM Summary', 2, None, 'lstm-summary'),
              ('Summary of LSTM', 2, None, 'summary-of-lstm'),
              ('LSTM implementation using TensorFlow',
               2,
               None,
               'lstm-implementation-using-tensorflow'),
              ('And the corresponding one with PyTorch',
               2,
               None,
               'and-the-corresponding-one-with-pytorch'),
              ('Dynamical ordinary differential equation',
               2,
               None,
               'dynamical-ordinary-differential-equation'),
              ('The Runge-Kutta-4 code', 2, None, 'the-runge-kutta-4-code'),
              ('Using the above data to train an RNN',
               2,
               None,
               'using-the-above-data-to-train-an-rnn'),
              ('Similar code using PyTorch',
               2,
               None,
               'similar-code-using-pytorch'),
              ('Autoencoders: Overarching view',
               2,
               None,
               'autoencoders-overarching-view'),
              ('Powerful detectors', 2, None, 'powerful-detectors'),
              ('First introduction of AEs',
               2,
               None,
               'first-introduction-of-aes'),
              ('Autoencoder structure', 2, None, 'autoencoder-structure'),
              ('Schematic image of an Autoencoder',
               2,
               None,
               'schematic-image-of-an-autoencoder'),
              ('More on the structure', 2, None, 'more-on-the-structure'),
              ('Decoder part', 2, None, 'decoder-part'),
              ('Typical AEs', 2, None, 'typical-aes'),
              ('Feed Forward Autoencoder', 2, None, 'feed-forward-autoencoder'),
              ('Mirroring', 2, None, 'mirroring'),
              ('Output of middle layer', 2, None, 'output-of-middle-layer'),
              ('Activation Function of the Output Layer',
               2,
               None,
               'activation-function-of-the-output-layer'),
              ('ReLU', 2, None, 'relu'),
              ('Sigmoid', 2, None, 'sigmoid'),
              ('Cost/Loss Function', 2, None, 'cost-loss-function'),
              ('Binary Cross-Entropy', 2, None, 'binary-cross-entropy'),
              ('Reconstruction Error', 2, None, 'reconstruction-error'),
              ('Implementation using TensorFlow',
               2,
               None,
               'implementation-using-tensorflow'),
              ('Implementation using PyTorch',
               2,
               None,
               'implementation-using-pytorch'),
              ('Dimensionality reduction and links with Principal component '
               'analysis',
               2,
               None,
               'dimensionality-reduction-and-links-with-principal-component-analysis'),
              ('Linear functions', 2, None, 'linear-functions'),
              ('AE mean-squared error', 2, None, 'ae-mean-squared-error'),
              ('Dimensionality reduction',
               2,
               None,
               'dimensionality-reduction')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week47-bs.html">Week 47: Recurrent neural networks and Autoencoders</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week47-bs001.html#plan-for-week-47" style="font-size: 80%;">Plan for week 47</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs002.html#reading-recommendations-rnns" style="font-size: 80%;">Reading recommendations RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs003.html#tensorflow-examples" style="font-size: 80%;">TensorFlow examples</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs004.html#reading-recommendations-autoencoders-ae" style="font-size: 80%;">Reading recommendations: Autoencoders (AE)</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs005.html#what-is-a-recurrent-nn" style="font-size: 80%;">What is a recurrent NN?</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs006.html#why-rnns" style="font-size: 80%;">Why RNNs?</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs007.html#more-whys" style="font-size: 80%;">More whys</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs008.html#rnns-in-more-detail" style="font-size: 80%;">RNNs in more detail</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs009.html#rnns-in-more-detail-part-2" style="font-size: 80%;">RNNs in more detail, part 2</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs010.html#rnns-in-more-detail-part-3" style="font-size: 80%;">RNNs in more detail, part 3</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs011.html#rnns-in-more-detail-part-4" style="font-size: 80%;">RNNs in more detail, part 4</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs012.html#rnns-in-more-detail-part-5" style="font-size: 80%;">RNNs in more detail, part 5</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs013.html#rnns-in-more-detail-part-6" style="font-size: 80%;">RNNs in more detail, part 6</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs014.html#rnns-in-more-detail-part-7" style="font-size: 80%;">RNNs in more detail, part 7</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs015.html#rnn-forward-pass-equations" style="font-size: 80%;">RNN Forward Pass Equations</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs016.html#unrolled-rnn-in-time" style="font-size: 80%;">Unrolled RNN in Time</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs017.html#example-task-character-level-rnn-classification" style="font-size: 80%;">Example Task: Character-level RNN Classification</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs018.html#pytorch-defining-a-simple-rnn-using-tensorflow" style="font-size: 80%;">PyTorch: Defining a Simple RNN, using Tensorflow</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs019.html#similar-example-using-pytorch" style="font-size: 80%;">Similar example using PyTorch</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs020.html#backpropagation-through-time-bptt-and-gradients" style="font-size: 80%;">Backpropagation Through Time (BPTT) and Gradients</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs021.html#truncated-bptt-and-gradient-clipping" style="font-size: 80%;">Truncated BPTT and Gradient Clipping</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs022.html#limitations-and-considerations" style="font-size: 80%;">Limitations and Considerations</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs023.html#pytorch-rnn-time-series-example" style="font-size: 80%;">PyTorch RNN Time Series Example</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs024.html#tensorflow-keras-rnn-time-series-example" style="font-size: 80%;">Tensorflow (Keras) RNN Time Series Example</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs025.html#the-mathematics-of-rnns-the-basic-architecture" style="font-size: 80%;">The mathematics of RNNs, the basic architecture</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs026.html#gating-mechanism-long-short-term-memory-lstm" style="font-size: 80%;">Gating mechanism: Long Short Term Memory (LSTM)</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs027.html#implementing-a-memory-cell-in-a-neural-network" style="font-size: 80%;">Implementing a memory cell in a neural network</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs033.html#lstm-details" style="font-size: 80%;">LSTM details</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs029.html#lstm-cell-and-gates" style="font-size: 80%;">LSTM Cell and Gates</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs030.html#core-lstm-equations" style="font-size: 80%;">Core LSTM Equations</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs031.html#gate-intuition-and-dynamics" style="font-size: 80%;">Gate Intuition and Dynamics</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs032.html#basic-layout-all-figures-from-raschka-et-al" style="font-size: 80%;">Basic layout (All figures from Raschka <em>et al.,</em>)</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs033.html#lstm-details" style="font-size: 80%;">LSTM details</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs034.html#comparing-with-a-standard-rnn" style="font-size: 80%;">Comparing with a standard  RNN</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs035.html#lstm-details-i" style="font-size: 80%;">LSTM details I</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs036.html#lstm-details-ii" style="font-size: 80%;">LSTM details II</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs037.html#lstm-details-iii" style="font-size: 80%;">LSTM details III</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs038.html#forget-gate" style="font-size: 80%;">Forget gate</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs039.html#the-forget-gate" style="font-size: 80%;">The forget gate</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs044.html#basic-layout" style="font-size: 80%;">Basic layout</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs041.html#input-gate" style="font-size: 80%;">Input gate</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs042.html#short-summary" style="font-size: 80%;">Short summary</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs043.html#forget-and-input" style="font-size: 80%;">Forget and input</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs044.html#basic-layout" style="font-size: 80%;">Basic layout</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs045.html#output-gate" style="font-size: 80%;">Output gate</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs046.html#lstm-implementation-code-example" style="font-size: 80%;">LSTM Implementation (Code Example)</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs047.html#example-modeling-dynamical-systems" style="font-size: 80%;">Example: Modeling Dynamical Systems</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs048.html#example-biological-sequences" style="font-size: 80%;">Example: Biological Sequences</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs049.html#training-tips-and-variants" style="font-size: 80%;">Training Tips and Variants</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs050.html#lstm-summary" style="font-size: 80%;">LSTM Summary</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs051.html#summary-of-lstm" style="font-size: 80%;">Summary of LSTM</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs052.html#lstm-implementation-using-tensorflow" style="font-size: 80%;">LSTM implementation using TensorFlow</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs053.html#and-the-corresponding-one-with-pytorch" style="font-size: 80%;">And the corresponding one with PyTorch</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs054.html#dynamical-ordinary-differential-equation" style="font-size: 80%;">Dynamical ordinary differential equation</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs055.html#the-runge-kutta-4-code" style="font-size: 80%;">The Runge-Kutta-4 code</a></li>
     <!-- navigation toc: --> <li><a href="#using-the-above-data-to-train-an-rnn" style="font-size: 80%;">Using the above data to train an RNN</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs057.html#similar-code-using-pytorch" style="font-size: 80%;">Similar code using PyTorch</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs058.html#autoencoders-overarching-view" style="font-size: 80%;">Autoencoders: Overarching view</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs059.html#powerful-detectors" style="font-size: 80%;">Powerful detectors</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs060.html#first-introduction-of-aes" style="font-size: 80%;">First introduction of AEs</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs061.html#autoencoder-structure" style="font-size: 80%;">Autoencoder structure</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs062.html#schematic-image-of-an-autoencoder" style="font-size: 80%;">Schematic image of an Autoencoder</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs063.html#more-on-the-structure" style="font-size: 80%;">More on the structure</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs064.html#decoder-part" style="font-size: 80%;">Decoder part</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs065.html#typical-aes" style="font-size: 80%;">Typical AEs</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs066.html#feed-forward-autoencoder" style="font-size: 80%;">Feed Forward Autoencoder</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs067.html#mirroring" style="font-size: 80%;">Mirroring</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs068.html#output-of-middle-layer" style="font-size: 80%;">Output of middle layer</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs069.html#activation-function-of-the-output-layer" style="font-size: 80%;">Activation Function of the Output Layer</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs070.html#relu" style="font-size: 80%;">ReLU</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs071.html#sigmoid" style="font-size: 80%;">Sigmoid</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs072.html#cost-loss-function" style="font-size: 80%;">Cost/Loss Function</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs073.html#binary-cross-entropy" style="font-size: 80%;">Binary Cross-Entropy</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs074.html#reconstruction-error" style="font-size: 80%;">Reconstruction Error</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs075.html#implementation-using-tensorflow" style="font-size: 80%;">Implementation using TensorFlow</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs076.html#implementation-using-pytorch" style="font-size: 80%;">Implementation using PyTorch</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs077.html#dimensionality-reduction-and-links-with-principal-component-analysis" style="font-size: 80%;">Dimensionality reduction and links with Principal component analysis</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs078.html#linear-functions" style="font-size: 80%;">Linear functions</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs079.html#ae-mean-squared-error" style="font-size: 80%;">AE mean-squared error</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs080.html#dimensionality-reduction" style="font-size: 80%;">Dimensionality reduction</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0056"></a>
<!-- !split -->
<h2 id="using-the-above-data-to-train-an-rnn" class="anchor">Using the above data to train an RNN </h2>

<p>In the code here we have reworked the previous example in order to
generate data that can be handled by recurrent neural networks in
order to train our model. The first code is written using Tensorflow/keras while the second example uses PyTorch.
In both cases we use the Runge Kutta to fourth order as a way to generate the data. We have implemented a simple RNN only.
We leave it as an exercise (possible path in project 3) to implement LSTMs.
</p>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic"># train_rnn_from_rk4.py</span>

<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">runpy</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">tensorflow</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">tf</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.model_selection</span> <span style="color: #008000; font-weight: bold">import</span> train_test_split
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">os</span>

<span style="color: #408080; font-style: italic"># ---------- Load RK4-generated data from your script ----------</span>
<span style="color: #408080; font-style: italic"># This runs rungekutta.py and collects its globals. It must populate &#39;t&#39; and &#39;x&#39; arrays.</span>
g <span style="color: #666666">=</span> runpy<span style="color: #666666">.</span>run_path(<span style="color: #BA2121">&#39;rungekutta.py&#39;</span>)

<span style="color: #008000; font-weight: bold">if</span> <span style="color: #AA22FF; font-weight: bold">not</span> <span style="color: #008000">all</span>(k <span style="color: #AA22FF; font-weight: bold">in</span> g <span style="color: #008000; font-weight: bold">for</span> k <span style="color: #AA22FF; font-weight: bold">in</span> (<span style="color: #BA2121">&#39;t&#39;</span>,<span style="color: #BA2121">&#39;x&#39;</span>,<span style="color: #BA2121">&#39;v&#39;</span>)):
    <span style="color: #008000; font-weight: bold">raise</span> <span style="color: #D2413A; font-weight: bold">RuntimeError</span>(<span style="color: #BA2121">&quot;rungekutta.py did not expose required variables &#39;t&#39;, &#39;x&#39;, &#39;v&#39; in its globals.&quot;</span>)

t <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array(g[<span style="color: #BA2121">&#39;t&#39;</span>])<span style="color: #666666">.</span>ravel()
x <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array(g[<span style="color: #BA2121">&#39;x&#39;</span>])<span style="color: #666666">.</span>ravel()
v <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array(g[<span style="color: #BA2121">&#39;v&#39;</span>])<span style="color: #666666">.</span>ravel()

<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Loaded shapes:&quot;</span>, t<span style="color: #666666">.</span>shape, x<span style="color: #666666">.</span>shape, v<span style="color: #666666">.</span>shape)

<span style="color: #408080; font-style: italic"># Simple plot of the original trajectory</span>
plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">8</span>,<span style="color: #666666">3</span>))
plt<span style="color: #666666">.</span>plot(t, x)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;t&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;x&#39;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&#39;True trajectory from RK4&#39;</span>)
plt<span style="color: #666666">.</span>tight_layout()
plt<span style="color: #666666">.</span>show()

<span style="color: #408080; font-style: italic"># ---------- Prepare datasets ----------</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">make_dataset</span>(series, input_len):
    X, y <span style="color: #666666">=</span> [], []
    N <span style="color: #666666">=</span> <span style="color: #008000">len</span>(series)
    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(N <span style="color: #666666">-</span> input_len):
        X<span style="color: #666666">.</span>append(series[i:i<span style="color: #666666">+</span>input_len])
        y<span style="color: #666666">.</span>append(series[i<span style="color: #666666">+</span>input_len])
    X <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array(X)<span style="color: #666666">.</span>reshape(<span style="color: #666666">-1</span>, input_len, <span style="color: #666666">1</span>)  <span style="color: #408080; font-style: italic"># (samples, timesteps, 1)</span>
    y <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array(y)<span style="color: #666666">.</span>reshape(<span style="color: #666666">-1</span>, <span style="color: #666666">1</span>)
    <span style="color: #008000; font-weight: bold">return</span> X, y

<span style="color: #408080; font-style: italic"># normalize using global mean/std</span>
mean_x, std_x <span style="color: #666666">=</span> x<span style="color: #666666">.</span>mean(), x<span style="color: #666666">.</span>std()
x_norm <span style="color: #666666">=</span> (x <span style="color: #666666">-</span> mean_x) <span style="color: #666666">/</span> std_x

<span style="color: #008000">print</span>(<span style="color: #BA2121">f&quot;Normalization: mean=</span><span style="color: #BB6688; font-weight: bold">{</span>mean_x<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.6f</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">, std=</span><span style="color: #BB6688; font-weight: bold">{</span>std_x<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.6f</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&quot;</span>)

<span style="color: #408080; font-style: italic"># Model A: input_len = 1 (x_t -&gt; x_{t+1})</span>
input_len_A <span style="color: #666666">=</span> <span style="color: #666666">1</span>
X_A, y_A <span style="color: #666666">=</span> make_dataset(x_norm, input_len_A)

<span style="color: #408080; font-style: italic"># Model B: input_len = 10 (used for autoregressive generation)</span>
input_len_B <span style="color: #666666">=</span> <span style="color: #666666">10</span>
X_B, y_B <span style="color: #666666">=</span> make_dataset(x_norm, input_len_B)

<span style="color: #408080; font-style: italic"># train/test split</span>
test_size <span style="color: #666666">=</span> <span style="color: #666666">0.2</span>
random_seed <span style="color: #666666">=</span> <span style="color: #666666">42</span>
Xa_train, Xa_test, ya_train, ya_test <span style="color: #666666">=</span> train_test_split(X_A, y_A, test_size<span style="color: #666666">=</span>test_size, random_state<span style="color: #666666">=</span>random_seed)
Xb_train, Xb_test, yb_train, yb_test <span style="color: #666666">=</span> train_test_split(X_B, y_B, test_size<span style="color: #666666">=</span>test_size, random_state<span style="color: #666666">=</span>random_seed)

<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Model A shapes:&quot;</span>, Xa_train<span style="color: #666666">.</span>shape, ya_train<span style="color: #666666">.</span>shape, <span style="color: #BA2121">&quot;Model B shapes:&quot;</span>, Xb_train<span style="color: #666666">.</span>shape, yb_train<span style="color: #666666">.</span>shape)

<span style="color: #408080; font-style: italic"># ---------- Build models ----------</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">build_simple_rnn</span>(input_len, hidden_size<span style="color: #666666">=32</span>):
    model <span style="color: #666666">=</span> tf<span style="color: #666666">.</span>keras<span style="color: #666666">.</span>Sequential([
        tf<span style="color: #666666">.</span>keras<span style="color: #666666">.</span>Input(shape<span style="color: #666666">=</span>(input_len,<span style="color: #666666">1</span>)),
        tf<span style="color: #666666">.</span>keras<span style="color: #666666">.</span>layers<span style="color: #666666">.</span>SimpleRNN(hidden_size, activation<span style="color: #666666">=</span><span style="color: #BA2121">&#39;tanh&#39;</span>),
        tf<span style="color: #666666">.</span>keras<span style="color: #666666">.</span>layers<span style="color: #666666">.</span>Dense(<span style="color: #666666">1</span>)
    ])
    model<span style="color: #666666">.</span>compile(optimizer<span style="color: #666666">=</span>tf<span style="color: #666666">.</span>keras<span style="color: #666666">.</span>optimizers<span style="color: #666666">.</span>Adam(<span style="color: #666666">1e-3</span>),
                  loss<span style="color: #666666">=</span><span style="color: #BA2121">&#39;mse&#39;</span>,
                  metrics<span style="color: #666666">=</span>[<span style="color: #BA2121">&#39;mse&#39;</span>])
    <span style="color: #008000; font-weight: bold">return</span> model

model_A <span style="color: #666666">=</span> build_simple_rnn(input_len_A, hidden_size<span style="color: #666666">=32</span>)
model_B <span style="color: #666666">=</span> build_simple_rnn(input_len_B, hidden_size<span style="color: #666666">=64</span>)

<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Model A summary:&quot;</span>)
model_A<span style="color: #666666">.</span>summary()
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;</span><span style="color: #BB6622; font-weight: bold">\n</span><span style="color: #BA2121">Model B summary:&quot;</span>)
model_B<span style="color: #666666">.</span>summary()

<span style="color: #408080; font-style: italic"># ---------- Train ----------</span>
epochs_A <span style="color: #666666">=</span> <span style="color: #666666">30</span>
epochs_B <span style="color: #666666">=</span> <span style="color: #666666">40</span>

hist_A <span style="color: #666666">=</span> model_A<span style="color: #666666">.</span>fit(Xa_train, ya_train, validation_data<span style="color: #666666">=</span>(Xa_test, ya_test),
                     epochs<span style="color: #666666">=</span>epochs_A, batch_size<span style="color: #666666">=32</span>, verbose<span style="color: #666666">=1</span>)

hist_B <span style="color: #666666">=</span> model_B<span style="color: #666666">.</span>fit(Xb_train, yb_train, validation_data<span style="color: #666666">=</span>(Xb_test, yb_test),
                     epochs<span style="color: #666666">=</span>epochs_B, batch_size<span style="color: #666666">=32</span>, verbose<span style="color: #666666">=1</span>)

<span style="color: #408080; font-style: italic"># ---------- Plot training curves ----------</span>
plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">10</span>,<span style="color: #666666">3</span>))
plt<span style="color: #666666">.</span>subplot(<span style="color: #666666">1</span>,<span style="color: #666666">2</span>,<span style="color: #666666">1</span>)
plt<span style="color: #666666">.</span>plot(hist_A<span style="color: #666666">.</span>history[<span style="color: #BA2121">&#39;loss&#39;</span>], label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;train&#39;</span>)
plt<span style="color: #666666">.</span>plot(hist_A<span style="color: #666666">.</span>history[<span style="color: #BA2121">&#39;val_loss&#39;</span>], label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;val&#39;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&#39;Model A loss&#39;</span>)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;epoch&#39;</span>); plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;mse&#39;</span>); plt<span style="color: #666666">.</span>legend()

plt<span style="color: #666666">.</span>subplot(<span style="color: #666666">1</span>,<span style="color: #666666">2</span>,<span style="color: #666666">2</span>)
plt<span style="color: #666666">.</span>plot(hist_B<span style="color: #666666">.</span>history[<span style="color: #BA2121">&#39;loss&#39;</span>], label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;train&#39;</span>)
plt<span style="color: #666666">.</span>plot(hist_B<span style="color: #666666">.</span>history[<span style="color: #BA2121">&#39;val_loss&#39;</span>], label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;val&#39;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&#39;Model B loss&#39;</span>)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;epoch&#39;</span>); plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;mse&#39;</span>); plt<span style="color: #666666">.</span>legend()

plt<span style="color: #666666">.</span>tight_layout()
plt<span style="color: #666666">.</span>show()

<span style="color: #408080; font-style: italic"># ---------- Evaluate one-step predictions ----------</span>
preds_A <span style="color: #666666">=</span> model_A<span style="color: #666666">.</span>predict(Xa_test)
preds_A_un <span style="color: #666666">=</span> preds_A<span style="color: #666666">.</span>flatten() <span style="color: #666666">*</span> std_x <span style="color: #666666">+</span> mean_x
ya_test_un <span style="color: #666666">=</span> ya_test<span style="color: #666666">.</span>flatten() <span style="color: #666666">*</span> std_x <span style="color: #666666">+</span> mean_x

<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Model A one-step MSE (unnormalized):&quot;</span>, np<span style="color: #666666">.</span>mean((preds_A_un <span style="color: #666666">-</span> ya_test_un)<span style="color: #666666">**2</span>))

plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">8</span>,<span style="color: #666666">3</span>))
nplot <span style="color: #666666">=</span> <span style="color: #008000">min</span>(<span style="color: #666666">100</span>, <span style="color: #008000">len</span>(ya_test_un))
plt<span style="color: #666666">.</span>plot(ya_test_un[:nplot], label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;true next x&#39;</span>)
plt<span style="color: #666666">.</span>plot(preds_A_un[:nplot], label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;predicted next x (Model A)&#39;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&quot;Model A: one-step predictions (segment)&quot;</span>)
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()

<span style="color: #408080; font-style: italic"># ---------- Autoregressive generation using Model B ----------</span>
<span style="color: #408080; font-style: italic"># Start from the first input_len_B true values, then generate the remainder autoregressively</span>
initial_window <span style="color: #666666">=</span> x_norm[:input_len_B]<span style="color: #666666">.</span>reshape(<span style="color: #666666">1</span>,input_len_B,<span style="color: #666666">1</span>)
gen_steps <span style="color: #666666">=</span> <span style="color: #008000">len</span>(x_norm) <span style="color: #666666">-</span> input_len_B
generated <span style="color: #666666">=</span> []
current_window <span style="color: #666666">=</span> initial_window<span style="color: #666666">.</span>copy()

<span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(gen_steps):
    pred_norm <span style="color: #666666">=</span> model_B<span style="color: #666666">.</span>predict(current_window, verbose<span style="color: #666666">=0</span>)  <span style="color: #408080; font-style: italic"># shape (1,1)</span>
    generated<span style="color: #666666">.</span>append(pred_norm<span style="color: #666666">.</span>flatten()[<span style="color: #666666">0</span>])
    <span style="color: #408080; font-style: italic"># roll the window and append prediction</span>
    current_window <span style="color: #666666">=</span> np<span style="color: #666666">.</span>concatenate([current_window[:,<span style="color: #666666">1</span>:,:], pred_norm<span style="color: #666666">.</span>reshape(<span style="color: #666666">1</span>,<span style="color: #666666">1</span>,<span style="color: #666666">1</span>)], axis<span style="color: #666666">=1</span>)

generated_un <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array(generated) <span style="color: #666666">*</span> std_x <span style="color: #666666">+</span> mean_x
true_remainder <span style="color: #666666">=</span> x[input_len_B:]

plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">8</span>,<span style="color: #666666">3</span>))
plt<span style="color: #666666">.</span>plot(true_remainder, label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;true remainder&#39;</span>)
plt<span style="color: #666666">.</span>plot(generated_un, label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;generated (Model B)&#39;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&#39;Model B autoregressive generation&#39;</span>)
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()

<span style="color: #408080; font-style: italic"># ---------- Save models ----------</span>
os<span style="color: #666666">.</span>makedirs(<span style="color: #BA2121">&#39;saved_models&#39;</span>, exist_ok<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>)
path_A <span style="color: #666666">=</span> os<span style="color: #666666">.</span>path<span style="color: #666666">.</span>join(<span style="color: #BA2121">&#39;saved_models&#39;</span>,<span style="color: #BA2121">&#39;model_A_rnn.h5&#39;</span>)
path_B <span style="color: #666666">=</span> os<span style="color: #666666">.</span>path<span style="color: #666666">.</span>join(<span style="color: #BA2121">&#39;saved_models&#39;</span>,<span style="color: #BA2121">&#39;model_B_rnn.h5&#39;</span>)
model_A<span style="color: #666666">.</span>save(path_A)
model_B<span style="color: #666666">.</span>save(path_B)
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Saved models to:&quot;</span>, path_A, path_B)

<span style="color: #408080; font-style: italic"># ---------- Final numeric summaries ----------</span>
preds_B <span style="color: #666666">=</span> model_B<span style="color: #666666">.</span>predict(Xb_test)
preds_B_un <span style="color: #666666">=</span> preds_B<span style="color: #666666">.</span>flatten() <span style="color: #666666">*</span> std_x <span style="color: #666666">+</span> mean_x
yb_test_un <span style="color: #666666">=</span> yb_test<span style="color: #666666">.</span>flatten() <span style="color: #666666">*</span> std_x <span style="color: #666666">+</span> mean_x
mse_A <span style="color: #666666">=</span> np<span style="color: #666666">.</span>mean((preds_A_un <span style="color: #666666">-</span> ya_test_un)<span style="color: #666666">**2</span>)
mse_B <span style="color: #666666">=</span> np<span style="color: #666666">.</span>mean((preds_B_un <span style="color: #666666">-</span> yb_test_un)<span style="color: #666666">**2</span>)
<span style="color: #008000">print</span>(<span style="color: #BA2121">f&quot;One-step MSE (Model A): </span><span style="color: #BB6688; font-weight: bold">{</span>mse_A<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.6e</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&quot;</span>)
<span style="color: #008000">print</span>(<span style="color: #BA2121">f&quot;One-step MSE (Model B): </span><span style="color: #BB6688; font-weight: bold">{</span>mse_B<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.6e</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&quot;</span>)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week47-bs055.html">&laquo;</a></li>
  <li><a href="._week47-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week47-bs048.html">49</a></li>
  <li><a href="._week47-bs049.html">50</a></li>
  <li><a href="._week47-bs050.html">51</a></li>
  <li><a href="._week47-bs051.html">52</a></li>
  <li><a href="._week47-bs052.html">53</a></li>
  <li><a href="._week47-bs053.html">54</a></li>
  <li><a href="._week47-bs054.html">55</a></li>
  <li><a href="._week47-bs055.html">56</a></li>
  <li class="active"><a href="._week47-bs056.html">57</a></li>
  <li><a href="._week47-bs057.html">58</a></li>
  <li><a href="._week47-bs058.html">59</a></li>
  <li><a href="._week47-bs059.html">60</a></li>
  <li><a href="._week47-bs060.html">61</a></li>
  <li><a href="._week47-bs061.html">62</a></li>
  <li><a href="._week47-bs062.html">63</a></li>
  <li><a href="._week47-bs063.html">64</a></li>
  <li><a href="._week47-bs064.html">65</a></li>
  <li><a href="._week47-bs065.html">66</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week47-bs080.html">81</a></li>
  <li><a href="._week47-bs057.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

