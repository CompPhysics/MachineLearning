{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6509fd",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)\n",
    "doconce format html week48.do.txt  -->\n",
    "<!-- dom:TITLE: Week 48: Autoencoders and summary of course -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7776f8",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Week 48: Autoencoders and summary of course\n",
    "**Morten Hjorth-Jensen**, Department of Physics and Center for Computing in Science Education, University of Oslo, Norway\n",
    "\n",
    "Date: **Nov 24, 2025**\n",
    "\n",
    "Copyright 1999-2025, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202e43a9",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Overview of week 48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca22738",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Lecture Monday, November 24\n",
    "**Plans for the lecture Monday 24 November.**\n",
    "\n",
    "1. Discussion of Autoencoders and principal component analysis\n",
    "\n",
    "2. Summary of course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be5f31",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Readings and Videos\n",
    "1. These lecture notes at <https://github.com/CompPhysics/MachineLearning/blob/master/doc/pub/week48/ipynb/week48.ipynb>\n",
    "<!-- o Video of lecture at <https://youtu.be/iTaRdAPQnDA> -->\n",
    "<!-- o Whiteboard notes at <https://github.com/CompPhysics/MachineLearning/blob/master/doc/HandWrittenNotes/2025/FYSSTKweek48.pdf> -->\n",
    "\n",
    "2. Video on Autoencoders at <https://www.youtube.com/watch?v=hZ4a4NgM3u0>\n",
    "\n",
    "3. Goodfellow et al chapter 14.\n",
    "\n",
    "4. Rashcka et al. Their chapter 17 contains a brief introduction only.\n",
    "\n",
    "5. Deep Learning Tutorial on AEs from Stanford University at <http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/>\n",
    "\n",
    "6. Building AEs in Keras at <https://blog.keras.io/building-autoencoders-in-keras.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaaba1b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Lab sessions\n",
    "**Lab sessions on Tuesday and Wednesday.**\n",
    "\n",
    "1. Work on and discussion of project 3.\n",
    "\n",
    "2. See updated note on usage of LLMs at the beginning of project description\n",
    "\n",
    "3. Last weekly exercise, see exercises week 47 and 48, deadline November 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ea54ec",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Autoencoders: Overarching view\n",
    "\n",
    "Autoencoders are artificial neural networks capable of learning\n",
    "efficient representations of the input data (these representations are called codings)  without\n",
    "any supervision (i.e., the training set is unlabeled). These codings\n",
    "typically have a much lower dimensionality than the input data, making\n",
    "autoencoders useful for dimensionality reduction. \n",
    "\n",
    "Autoencoders learn to encode the\n",
    "input data into a lower-dimensional representation, and then decode it\n",
    "back to the original data. The goal of autoencoders is to minimize the\n",
    "reconstruction error, which measures how well the output matches the\n",
    "input. Autoencoders can be seen as a way of learning the latent\n",
    "features or hidden structure of the data, and they can be used for\n",
    "data compression, denoising, anomaly detection, and generative\n",
    "modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffff13",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Powerful detectors\n",
    "\n",
    "More importantly, autoencoders act as powerful feature detectors, and\n",
    "they can be used for unsupervised pretraining of deep neural networks.\n",
    "\n",
    "Lastly, they are capable of randomly generating new data that looks\n",
    "very similar to the training data; this is called a generative\n",
    "model. For example, you could train an autoencoder on pictures of\n",
    "faces, and it would then be able to generate new faces.  Surprisingly,\n",
    "autoencoders work by simply learning to copy their inputs to their\n",
    "outputs. This may sound like a trivial task, but we will see that\n",
    "constraining the network in various ways can make it rather\n",
    "difficult. For example, you can limit the size of the internal\n",
    "representation, or you can add noise to the inputs and train the\n",
    "network to recover the original inputs. These constraints prevent the\n",
    "autoencoder from trivially copying the inputs directly to the outputs,\n",
    "which forces it to learn efficient ways of representing the data. In\n",
    "short, the codings are byproducts of the autoencoderâ€™s attempt to\n",
    "learn the identity function under some constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f477e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## First introduction of AEs\n",
    "\n",
    "Autoencoders were first introduced by Rumelhart, Hinton, and Williams\n",
    "in 1986 with the goal of learning to reconstruct the input\n",
    "observations with the lowest error possible.\n",
    "\n",
    "Why would one want to learn to reconstruct the input observations? If\n",
    "you have problems imagining what that means, think of having a dataset\n",
    "made of images. An autoencoder would be an algorithm that can give as\n",
    "output an image that is as similar as possible to the input one. You\n",
    "may be confused, as there is no apparent reason of doing so. To better\n",
    "understand why autoencoders are useful we need a more informative\n",
    "(although not yet unambiguous) definition.\n",
    "\n",
    "An autoencoder is a type of algorithm with the primary purpose of learning an \"informative\" representation of the data that can be used for different applications ([see Bank, D., Koenigstein, N., and Giryes, R., Autoencoders](https://arxiv.org/abs/2003.05991)) by learning to reconstruct a set of input observations well enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b19cf6",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Autoencoder structure\n",
    "\n",
    "Autoencoders are neural networks where the outputs are its own\n",
    "inputs. They are split into an **encoder part**\n",
    "which maps the input $\\boldsymbol{x}$ via a function $f(\\boldsymbol{x},\\boldsymbol{W})$ (this\n",
    "is the encoder part) to a **so-called code part** (or intermediate part)\n",
    "with the result $\\boldsymbol{h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da16f69",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\boldsymbol{h} = f(\\boldsymbol{x},\\boldsymbol{W})),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ad2e9",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\boldsymbol{W}$ are the weights to be determined.  The **decoder** parts maps, via its own parameters (weights given by the matrix $\\boldsymbol{V}$ and its own biases) to \n",
    "the final ouput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fec939f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\tilde{\\boldsymbol{x}} = g(\\boldsymbol{h},\\boldsymbol{V})).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bccc691",
   "metadata": {
    "editable": true
   },
   "source": [
    "The goal is to minimize the construction error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c54f31",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Schematic image of an Autoencoder\n",
    "\n",
    "<!-- dom:FIGURE: [figures/ae1.png, width=700 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/ae1.png\" width=\"700\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7bf2e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More on the structure\n",
    "\n",
    "In most typical architectures, the encoder and the decoder are neural networks\n",
    "since they can be easily trained with existing software libraries such as TensorFlow or PyTorch with back propagation.\n",
    "\n",
    "In general, the encoder can be written as a function $g$ that will depend on some parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82126f17",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{h}_{i} = g(\\mathbf{x}_{i}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c34ea",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\mathbf{h}_{i}\\in\\mathbb{R}^{q}$  (the latent feature representation) is the output of the encoder block where we evaluate\n",
    "it using the input $\\mathbf{x}_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3167bf",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Decoder part\n",
    "\n",
    "Note that we have $g:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{q}$\n",
    "The decoder and the output of the network $\\tilde{\\mathbf{x}}_{i}$ can be written then as a second generic function\n",
    "of the latent features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357be7c9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\tilde{\\mathbf{x}}_{i} = f\\left(\\mathbf{h}_{i}\\right) = f\\left(g\\left(\\mathbf{x}_{i}\\right)\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd9055",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\tilde{\\mathbf{x}}_{i}\\mathbf{\\in }\\mathbb{R}^{n}$.\n",
    "\n",
    "Training an autoencoder simply means finding the functions $g(\\cdot)$ and $f(\\cdot)$\n",
    "that satisfy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5514d41c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\textrm{arg}\\min_{f,g}<\\left[\\Delta (\\mathbf{x}_{i}, f(g\\left(\\mathbf{x}_{i}\\right))\\right]>.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12ff17",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Typical AEs\n",
    "\n",
    "The standard setup is done via a standard feed forward neural network (FFNN), or what is called a Feed Forward Autoencoder.\n",
    "\n",
    "A typical FFNN architecture has an odd number of layers and is symmetrical with respect to the middle layer.\n",
    "\n",
    "Typically, the first layer has a number of neurons $n_{1} = n$ which equals the size of the input observation $\\mathbf{x}_{\\mathbf{i}}$.\n",
    "\n",
    "As we move toward the center of the network, the number of neurons in each layer drops in some measure.\n",
    "The middle layer usually has the smallest number of neurons.\n",
    "The fact that the number of neurons in this layer is smaller than the size of the input, is often called the **bottleneck**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c7e70",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Feed Forward Autoencoder\n",
    "\n",
    "<!-- dom:FIGURE: [figures/ae2.png, width=700 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/ae2.png\" width=\"700\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430b5eb",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Mirroring\n",
    "\n",
    "In almost all practical applications,\n",
    "the layers after the middle one are a mirrored version of the layers before the middle one.\n",
    "For example, an autoencoder with three layers could have the following numbers of neurons:\n",
    "\n",
    "$n_{1} = 10$, $n_{2} = 5$ and then $n_{3} = n_{1} = 10$ where the input dimension is equal to ten.\n",
    "\n",
    "All the layers up to and including the middle one, make what is called the encoder, and all the layers from and including\n",
    "the middle one (up to the output) make what is called the decoder.\n",
    "\n",
    "If the FFNN training is successful, the result will\n",
    "be a good approximation of the input $\\tilde{\\mathbf{x}}_{i}\\approx\\mathbf{x}_{i}$.\n",
    "\n",
    "What is essential to notice is that the decoder can reconstruct the\n",
    "input by using only a much smaller number of features than the input\n",
    "observations initially have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2daaa00",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Output of middle layer\n",
    "\n",
    "The output of the middle layer\n",
    "$\\mathbf{h}_{\\mathbf{i}}$ are also called a **learned representation** of the input observation $\\mathbf{x}_{i}$.\n",
    "\n",
    "The encoder can reduce the number of dimensions of the input\n",
    "observation and create a learned representation\n",
    "$\\mathbf{h}_{\\mathbf{i}}\\mathbf{) }$ of the input that has a smaller\n",
    "dimension $q<n$.\n",
    "\n",
    "This learned representation is enough for the decoder to reconstruct\n",
    "the input accurately (if the autoencoder training was successful as\n",
    "intended)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8b91c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Activation Function of the Output Layer\n",
    "\n",
    "In autoencoders based on neural networks, the output layer's\n",
    "activation function plays a particularly important role.  The most\n",
    "used functions are ReLU and Sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf0616",
   "metadata": {
    "editable": true
   },
   "source": [
    "## ReLU\n",
    "\n",
    "The  ReLU activation function can assume all values in the range $\\left[0,\\infty\\right]$. As a remainder, its formula is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ddf34",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\textrm{ReLU}\\left(x\\right) = \\max\\left(0,x\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafe71f1",
   "metadata": {
    "editable": true
   },
   "source": [
    "This choice is good when the input observations \\(\\mathbf{x}_{i}\\) assume a wide range of positive values.\n",
    "If the input $\\mathbf{x}_{i}$ can assume negative values, the ReLU is, of course, a terrible choice, and the identity function is a much better choice. It is then common to replace to the ReLU with the so-called **Leaky ReLu** or just modified ReLU.\n",
    "\n",
    "The ReLU activation function for the output layer is well suited for cases when the input observations \\(\\mathbf{x}_{i}\\) assume a wide range of positive real values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427792f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Sigmoid\n",
    "\n",
    "The sigmoid function $\\sigma$ can assume all values in the range $[0,1]$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6506ac06",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\sigma\\left(x\\right) =\\frac{1}{1+e^{-x}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23c0d0d",
   "metadata": {
    "editable": true
   },
   "source": [
    "This activation function can only be used if the input observations\n",
    "$\\mathbf{x}_{i}$ are all in the range $[0,1]$  or if you have\n",
    "normalized them to be in that range. Consider as an example the MNIST\n",
    "dataset. Each value of the input observation $\\mathbf{x}_{i}$ (one\n",
    "image) is the gray values of the pixels that can assume any value from\n",
    "0 to 255. Normalizing the data by dividing the pixel values by 255\n",
    "would make each observation (each image) have only pixel values\n",
    "between 0 and 1. In this case, the sigmoid would be a good choice for\n",
    "the output layer's activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c31fb7",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Cost/Loss Function\n",
    "\n",
    "If an autoencoder is trying to solve a regression problem, the most\n",
    "common choice as a loss function is the Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033bb37b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "L_{\\textrm{MSE}} = \\textrm{MSE} = \\frac{1}{n}\\sum_{i = 1}^{n}\\left\\vert\\vert\\mathbf{x}_{i}-\\tilde{\\mathbf{x}}_{i}\\right\\vert\\vert^{2}_2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe2d5b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Binary Cross-Entropy\n",
    "\n",
    "If the activation function of the output layer of the AE is a sigmoid\n",
    "function, thus limiting neuron outputs to be between 0 and 1, and the\n",
    "input features are normalized to be between 0 and 1 we can use as loss\n",
    "function the binary cross-entropy. This cots/loss function is\n",
    "typically used in classification problems, but it works well for\n",
    "autoencoders. The formula for it is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f960415",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "L_{\\textrm{CE}} = -\\frac{1}{n}\\sum_{i = 1}^{n}\\sum_{j = 1}^{p}[x_{j,i} \\log\\tilde{x}_{j,i}+\\left(1-x_{j,i}\\right)\\log (1-\\tilde{x}_{j,i})].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207437ee",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Reconstruction Error\n",
    "\n",
    "The reconstruction error (RE) is a metric that gives you an indication of how good (or bad) the autoencoder was able to reconstruct\n",
    "the input observation $\\mathbf{x}_{i}$. The most typical RE used is the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1eae5",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\textrm{RE}\\equiv \\textrm{MSE} = \\frac{1}{n}\\sum_{i = 1}^{n}\\left\\vert\\vert\\mathbf{x}_{i}-\\tilde{\\mathbf{x}}_{i}\\right\\vert\\vert^{2}_2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d35b81d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Towards the PCA theorem\n",
    "\n",
    "We have from last week that the covariance matrix (the correlation matrix involves a simple rescaling) is given as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde0c93",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\boldsymbol{C}[\\boldsymbol{x}] = \\frac{1}{n}\\boldsymbol{X}^T\\boldsymbol{X}= \\mathbb{E}[\\boldsymbol{X}^T\\boldsymbol{X}].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e477cbc5",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let us now assume that we can perform a series of orthogonal transformations where we employ some orthogonal matrices $\\boldsymbol{S}$.\n",
    "These matrices are defined as $\\boldsymbol{S}\\in {\\mathbb{R}}^{p\\times p}$ and obey the orthogonality requirements $\\boldsymbol{S}\\boldsymbol{S}^T=\\boldsymbol{S}^T\\boldsymbol{S}=\\boldsymbol{I}$. The matrix can be written out in terms of the column vectors $\\boldsymbol{s}_i$ as $\\boldsymbol{S}=[\\boldsymbol{s}_0,\\boldsymbol{s}_1,\\dots,\\boldsymbol{s}_{p-1}]$ and $\\boldsymbol{s}_i \\in {\\mathbb{R}}^{p}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de93db",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More details\n",
    "\n",
    "Assume also that there is a transformation $\\boldsymbol{S}^T\\boldsymbol{C}[\\boldsymbol{x}]\\boldsymbol{S}=\\boldsymbol{C}[\\boldsymbol{y}]$ such that the new matrix $\\boldsymbol{C}[\\boldsymbol{y}]$ is diagonal with elements $[\\lambda_0,\\lambda_1,\\lambda_2,\\dots,\\lambda_{p-1}]$.  \n",
    "\n",
    "That is we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91170128",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\boldsymbol{C}[\\boldsymbol{y}] = \\mathbb{E}[\\boldsymbol{S}^T\\boldsymbol{X}^T\\boldsymbol{X}T\\boldsymbol{S}]=\\boldsymbol{S}^T\\boldsymbol{C}[\\boldsymbol{x}]\\boldsymbol{S},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bec822d",
   "metadata": {
    "editable": true
   },
   "source": [
    "since the matrix $\\boldsymbol{S}$ is not a data dependent matrix.   Multiplying with $\\boldsymbol{S}$ from the left we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038374f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\boldsymbol{S}\\boldsymbol{C}[\\boldsymbol{y}] = \\boldsymbol{C}[\\boldsymbol{x}]\\boldsymbol{S},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e00198",
   "metadata": {
    "editable": true
   },
   "source": [
    "and since $\\boldsymbol{C}[\\boldsymbol{y}]$ is diagonal we have for a given eigenvalue $i$ of the covariance matrix that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68dcf91",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\boldsymbol{S}_i\\lambda_i = \\boldsymbol{C}[\\boldsymbol{x}]\\boldsymbol{S}_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c707a",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More on the PCA Theorem\n",
    "\n",
    "In the derivation of the PCA theorem we will assume that the eigenvalues are ordered in descending order, that is\n",
    "$\\lambda_0 > \\lambda_1 > \\dots > \\lambda_{p-1}$. \n",
    "\n",
    "The eigenvalues tell us then how much we need to stretch the\n",
    "corresponding eigenvectors. Dimensions with large eigenvalues have\n",
    "thus large variations (large variance) and define therefore useful\n",
    "dimensions. The data points are more spread out in the direction of\n",
    "these eigenvectors.  Smaller eigenvalues mean on the other hand that\n",
    "the corresponding eigenvectors are shrunk accordingly and the data\n",
    "points are tightly bunched together and there is not much variation in\n",
    "these specific directions. Hopefully then we could leave it out\n",
    "dimensions where the eigenvalues are very small. If $p$ is very large,\n",
    "we could then aim at reducing $p$ to $l << p$ and handle only $l$\n",
    "features/predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59128953",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The Algorithm before theorem\n",
    "\n",
    "Here's how we would proceed in setting up the algorithm for the PCA, see also discussion below here. \n",
    "Set up the datapoints for the design/feature matrix $\\boldsymbol{X}$ with $\\boldsymbol{X}\\in {\\mathbb{R}}^{n\\times p}$, with the predictors/features $p$  referring to the column numbers and the entries $n$ being the row elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4979b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\boldsymbol{X}=\\begin{bmatrix}\n",
    "x_{0,0} & x_{0,1} & x_{0,2}& \\dots & \\dots x_{0,p-1}\\\\\n",
    "x_{1,0} & x_{1,1} & x_{1,2}& \\dots & \\dots x_{1,p-1}\\\\\n",
    "x_{2,0} & x_{2,1} & x_{2,2}& \\dots & \\dots x_{2,p-1}\\\\\n",
    "\\dots & \\dots & \\dots & \\dots \\dots & \\dots \\\\\n",
    "x_{n-2,0} & x_{n-2,1} & x_{n-2,2}& \\dots & \\dots x_{n-2,p-1}\\\\\n",
    "x_{n-1,0} & x_{n-1,1} & x_{n-1,2}& \\dots & \\dots x_{n-1,p-1}\\\\\n",
    "\\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eccf422",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Further steps\n",
    "\n",
    "* Center the data by subtracting the mean value for each column. This leads to a new matrix $\\boldsymbol{X}\\rightarrow \\overline{\\boldsymbol{X}}$.\n",
    "\n",
    "* Compute then the covariance/correlation matrix $\\mathbb{E}[\\overline{\\boldsymbol{X}}^T\\overline{\\boldsymbol{X}}]$.\n",
    "\n",
    "* Find the eigenpairs of $\\boldsymbol{C}$ with eigenvalues $[\\lambda_0,\\lambda_1,\\dots,\\lambda_{p-1}]$ and eigenvectors $[\\boldsymbol{s}_0,\\boldsymbol{s}_1,\\dots,\\boldsymbol{s}_{p-1}]$.\n",
    "\n",
    "* Order the eigenvalue (and the eigenvectors accordingly) in order of decreasing eigenvalues.\n",
    "\n",
    "* Keep only those $l$ eigenvalues larger than a selected threshold value, discarding thus $p-l$ features since we expect small variations in the data here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6d3cbf",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Writing our own PCA code\n",
    "\n",
    "We will use a simple example first with two-dimensional data\n",
    "drawn from a multivariate normal distribution with the following mean and covariance matrix (we have fixed these quantities but will play around with them below):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0904791",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mu = (-1,2) \\qquad \\Sigma = \\begin{bmatrix} 4 & 2 \\\\\n",
    "2 & 2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe903a4",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note that the mean refers to each column of data. \n",
    "We will generate $n = 10000$ points $X = \\{ x_1, \\ldots, x_N \\}$ from\n",
    "this distribution, and store them in the $1000 \\times 2$ matrix $\\boldsymbol{X}$. This is our design matrix where we have forced the covariance and mean values to take specific values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd26ef76",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Implementing it\n",
    "The following Python code aids in setting up the data and writing out the design matrix.\n",
    "Note that the function **multivariate** returns also the covariance discussed above and that it is defined by dividing by $n-1$ instead of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3853a0b",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "n = 10000\n",
    "mean = (-1, 2)\n",
    "cov = [[4, 0.05], [0.05, 0.05]]\n",
    "X = np.random.multivariate_normal(mean, cov, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce1a34",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we are going to implement the PCA algorithm. We will break it down into various substeps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e89725",
   "metadata": {
    "editable": true
   },
   "source": [
    "## First Step\n",
    "\n",
    "The first step of PCA is to compute the sample mean of the data and use it to center the data. Recall that the sample mean is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e745e6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mu_n = \\frac{1}{n} \\sum_{i=1}^n x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c125c4",
   "metadata": {
    "editable": true
   },
   "source": [
    "and the mean-centered data $\\bar{X} = \\{ \\bar{x}_1, \\ldots, \\bar{x}_n \\}$ takes the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da2c70f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\bar{x}_i = x_i - \\mu_n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e2cef",
   "metadata": {
    "editable": true
   },
   "source": [
    "When you are done with these steps, print out $\\mu_n$ to verify it is\n",
    "close to $\\mu$ and plot your mean centered data to verify it is\n",
    "centered at the origin! \n",
    "The following code elements perform these operations using **pandas** or using our own functionality for doing so. The latter, using **numpy** is rather simple through the **mean()** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c1d8ef",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "# Pandas does the centering for us\n",
    "df = df -df.mean()\n",
    "# we center it ourselves\n",
    "X_centered = X - X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8cd52c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Scaling\n",
    "Alternatively, we could use the functions we discussed\n",
    "earlier for scaling the data set.  That is, we could have used the\n",
    "**StandardScaler** function in **Scikit-Learn**, a function which ensures\n",
    "that for each feature/predictor we study the mean value is zero and\n",
    "the variance is one (every column in the design/feature matrix).  You\n",
    "would then not get the same results, since we divide by the\n",
    "variance. The diagonal covariance matrix elements will then be one,\n",
    "while the non-diagonal ones need to be divided by $2\\sqrt{2}$ for our\n",
    "specific case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d1893",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Centered Data\n",
    "\n",
    "Now we are going to use the mean centered data to compute the sample covariance of the data by using the following equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c486ca",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Sigma_n = \\frac{1}{n-1} \\sum_{i=1}^n \\bar{x}_i^T \\bar{x}_i = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\mu_n)^T (x_i - \\mu_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be9615c",
   "metadata": {
    "editable": true
   },
   "source": [
    "where the data points $x_i \\in \\mathbb{R}^p$ (here in this example $p = 2$) are column vectors and $x^T$ is the transpose of $x$.\n",
    "We can write our own code or simply use either the functionaly of **numpy** or that of **pandas**, as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c04ee1cc",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1\n",
      "0  4.020866  0.048173\n",
      "1  0.048173  0.049853\n",
      "[[4.02086622 0.04817314]\n",
      " [0.04817314 0.04985332]]\n"
     ]
    }
   ],
   "source": [
    "print(df.cov())\n",
    "print(np.cov(X_centered.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb1cc3",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note that the way we define the covariance matrix here has a factor $n-1$ instead of $n$. This is included in the **cov()** function by **numpy** and **pandas**. \n",
    "Our own code here is not very elegant and asks for obvious improvements. It is tailored to this specific $2\\times 2$ covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fdfbacb",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centered covariance using own code\n",
      "[[4.02086622 0.04817314]\n",
      " [0.04817314 0.04985332]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract the relevant columns from the centered design matrix of dim n x 2\n",
    "x = X_centered[:,0]\n",
    "y = X_centered[:,1]\n",
    "Cov = np.zeros((2,2))\n",
    "Cov[0,1] = np.sum(x.T@y)/(n-1.0)\n",
    "Cov[0,0] = np.sum(x.T@x)/(n-1.0)\n",
    "Cov[1,1] = np.sum(y.T@y)/(n-1.0)\n",
    "Cov[1,0]= Cov[0,1]\n",
    "print(\"Centered covariance using own code\")\n",
    "print(Cov)\n",
    "plt.plot(x, y, 'x')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34156d52",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exploring\n",
    "\n",
    "Depending on the number of points $n$, we will get results that are close to the covariance values defined above.\n",
    "The plot shows how the data are clustered around a line with slope close to one. Is this expected?  Try to change the covariance and the mean values. For example, try to make the variance of the first element much larger than that of the second diagonal element. Try also to shrink the covariance  (the non-diagonal elements) and see how the data points are distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a77a6b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diagonalize the sample covariance matrix to obtain the principal components\n",
    "\n",
    "Now we are ready to solve for the principal components! To do so we\n",
    "diagonalize the sample covariance matrix $\\Sigma$. We can use the\n",
    "function **np.linalg.eig** to do so. It will return the eigenvalues and\n",
    "eigenvectors of $\\Sigma$. Once we have these we can perform the \n",
    "following tasks:\n",
    "\n",
    "* We compute the percentage of the total variance captured by the first principal component\n",
    "\n",
    "* We plot the mean centered data and lines along the first and second principal components\n",
    "\n",
    "* Then we project the mean centered data onto the first and second principal components, and plot the projected data. \n",
    "\n",
    "* Finally, we approximate the data as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7b4de",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "x_i \\approx \\tilde{x}_i = \\mu_n + \\langle x_i, v_0 \\rangle v_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50802aed",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $v_0$ is the first principal component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9df42c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Collecting all Steps\n",
    "\n",
    "Collecting all these steps we can write our own PCA function and\n",
    "compare this with the functionality included in **Scikit-Learn**.  \n",
    "\n",
    "The code here outlines some of the elements we could include in the\n",
    "analysis. Feel free to extend upon this in order to address the above\n",
    "questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80c0ef2c",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues of Covariance matrix\n",
      "4.021450531239688\n",
      "0.04926900380527363\n",
      "First eigenvector\n",
      "[0.99992645 0.01212852]\n",
      "Second eigenvector\n",
      "[-0.01212852  0.99992645]\n",
      "Eigenvector of largest eigenvalue\n",
      "[0.99992645 0.01212852]\n"
     ]
    }
   ],
   "source": [
    "# diagonalize and obtain eigenvalues, not necessarily sorted\n",
    "EigValues, EigVectors = np.linalg.eig(Cov)\n",
    "# sort eigenvectors and eigenvalues\n",
    "#permute = EigValues.argsort()\n",
    "#EigValues = EigValues[permute]\n",
    "#EigVectors = EigVectors[:,permute]\n",
    "print(\"Eigenvalues of Covariance matrix\")\n",
    "for i in range(2):\n",
    "    print(EigValues[i])\n",
    "FirstEigvector = EigVectors[:,0]\n",
    "SecondEigvector = EigVectors[:,1]\n",
    "print(\"First eigenvector\")\n",
    "print(FirstEigvector)\n",
    "print(\"Second eigenvector\")\n",
    "print(SecondEigvector)\n",
    "#thereafter we do a PCA with Scikit-learn\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "X2Dsl = pca.fit_transform(X)\n",
    "print(\"Eigenvector of largest eigenvalue\")\n",
    "print(pca.components_.T[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2016b3e",
   "metadata": {
    "editable": true
   },
   "source": [
    "This code does not contain all the above elements, but it shows how we can use **Scikit-Learn** to extract the eigenvector which corresponds to the largest eigenvalue. Try to address the questions we pose before the above code.  Try also to change the values of the covariance matrix by making one of the diagonal elements much larger than the other. What do you observe then?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce609c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Classical PCA Theorem\n",
    "\n",
    "We assume now that we have a design matrix $\\boldsymbol{X}$ which has been\n",
    "centered as discussed above. For the sake of simplicity we skip the\n",
    "overline symbol. The matrix is defined in terms of the various column\n",
    "vectors $[\\boldsymbol{x}_0,\\boldsymbol{x}_1,\\dots, \\boldsymbol{x}_{p-1}]$ each with dimension\n",
    "$\\boldsymbol{x}\\in {\\mathbb{R}}^{n}$.\n",
    "\n",
    "The PCA theorem states that minimizing the above reconstruction error\n",
    "corresponds to setting $\\boldsymbol{W}=\\boldsymbol{S}$, the orthogonal matrix which\n",
    "diagonalizes the empirical covariance(correlation) matrix. The optimal\n",
    "low-dimensional encoding of the data is then given by a set of vectors\n",
    "$\\boldsymbol{z}_i$ with at most $l$ vectors, with $l << p$, defined by the\n",
    "orthogonal projection of the data onto the columns spanned by the\n",
    "eigenvectors of the covariance(correlations matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d51db",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The PCA Theorem\n",
    "\n",
    "To show the PCA theorem let us start with the assumption that there is one vector $\\boldsymbol{s}_0$ which corresponds to a solution which minimized the reconstruction error $J$. This is an orthogonal vector. It means that we now approximate the reconstruction error in terms of $\\boldsymbol{w}_0$ and $\\boldsymbol{z}_0$ as\n",
    "\n",
    "We are almost there, we have obtained a relation between minimizing\n",
    "the reconstruction error and the variance and the covariance\n",
    "matrix. Minimizing the error is equivalent to maximizing the variance\n",
    "of the projected data.\n",
    "\n",
    "We could trivially maximize the variance of the projection (and\n",
    "thereby minimize the error in the reconstruction function) by letting\n",
    "the norm-2 of $\\boldsymbol{w}_0$ go to infinity. However, this norm since we\n",
    "want the matrix $\\boldsymbol{W}$ to be an orthogonal matrix, is constrained by\n",
    "$\\vert\\vert \\boldsymbol{w}_0 \\vert\\vert_2^2=1$. Imposing this condition via a\n",
    "Lagrange multiplier we can then in turn maximize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd4c3f1",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "J(\\boldsymbol{w}_0)= \\boldsymbol{w}_0^T\\boldsymbol{C}[\\boldsymbol{x}]\\boldsymbol{w}_0+\\lambda_0(1-\\boldsymbol{w}_0^T\\boldsymbol{w}_0).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52661aea",
   "metadata": {
    "editable": true
   },
   "source": [
    "Taking the derivative with respect to $\\boldsymbol{w}_0$ we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd4368c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial J(\\boldsymbol{w}_0)}{\\partial \\boldsymbol{w}_0}= 2\\boldsymbol{C}[\\boldsymbol{x}]\\boldsymbol{w}_0-2\\lambda_0\\boldsymbol{w}_0=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b344cb",
   "metadata": {
    "editable": true
   },
   "source": [
    "meaning that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f52153c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\boldsymbol{C}[\\boldsymbol{x}]\\boldsymbol{w}_0=\\lambda_0\\boldsymbol{w}_0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3604ee",
   "metadata": {
    "editable": true
   },
   "source": [
    "**The direction that maximizes the variance (or minimizes the construction error) is an eigenvector of the covariance matrix**! If we left multiply with $\\boldsymbol{w}_0^T$ we have the variance of the projected data is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f3d30e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\boldsymbol{w}_0^T\\boldsymbol{C}[\\boldsymbol{x}]\\boldsymbol{w}_0=\\lambda_0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd1297",
   "metadata": {
    "editable": true
   },
   "source": [
    "If we want to maximize the variance (minimize the construction error)\n",
    "we simply pick the eigenvector of the covariance matrix with the\n",
    "largest eigenvalue. This establishes the link between the minimization\n",
    "of the reconstruction function $J$ in terms of an orthogonal matrix\n",
    "and the maximization of the variance and thereby the covariance of our\n",
    "observations encoded in the design/feature matrix $\\boldsymbol{X}$.\n",
    "\n",
    "The proof\n",
    "for the other eigenvectors $\\boldsymbol{w}_1,\\boldsymbol{w}_2,\\dots$ can be\n",
    "established by applying the above arguments and using the fact that\n",
    "our basis of eigenvectors is orthogonal, see [Murphy chapter\n",
    "12.2](https://mitpress.mit.edu/books/machine-learning-1).  The\n",
    "discussion in chapter 12.2 of Murphy's text has also a nice link with\n",
    "the Singular Value Decomposition theorem. For categorical data, see\n",
    "chapter 12.4 and discussion therein.\n",
    "\n",
    "For more details, see for example [Vidal, Ma and Sastry, chapter 2](https://www.springer.com/gp/book/9780387878102)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c7c66d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Geometric Interpretation and link with Singular Value Decomposition\n",
    "\n",
    "For a detailed demonstration of the geometric interpretation, see [Vidal, Ma and Sastry, section 2.1.2](https://www.springer.com/gp/book/9780387878102).\n",
    "\n",
    "Principal Component Analysis (PCA) is by far the most popular dimensionality reduction algorithm.\n",
    "First it identifies the hyperplane that lies closest to the data, and then it projects the data onto it.\n",
    "\n",
    "The following Python code uses NumPyâ€™s **svd()** function to obtain all the principal components of the\n",
    "training set, then extracts the first two principal components. First we center the data using either **pandas** or our own code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9c5227",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.574465</td>\n",
       "      <td>0.259153</td>\n",
       "      <td>1.197370</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.649382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.689519</td>\n",
       "      <td>0.137652</td>\n",
       "      <td>-1.025709</td>\n",
       "      <td>0.210340</td>\n",
       "      <td>-0.076938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.282727</td>\n",
       "      <td>0.351636</td>\n",
       "      <td>-0.539261</td>\n",
       "      <td>1.216683</td>\n",
       "      <td>0.340782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070889</td>\n",
       "      <td>-0.614808</td>\n",
       "      <td>1.074067</td>\n",
       "      <td>-0.038300</td>\n",
       "      <td>-1.450257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.794282</td>\n",
       "      <td>1.458078</td>\n",
       "      <td>-0.207545</td>\n",
       "      <td>-0.442600</td>\n",
       "      <td>-0.147420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.112383</td>\n",
       "      <td>0.647473</td>\n",
       "      <td>1.405890</td>\n",
       "      <td>0.073598</td>\n",
       "      <td>-0.276263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.397700</td>\n",
       "      <td>-1.526744</td>\n",
       "      <td>-0.712018</td>\n",
       "      <td>1.216290</td>\n",
       "      <td>0.418506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.280647</td>\n",
       "      <td>1.106095</td>\n",
       "      <td>-1.646283</td>\n",
       "      <td>-0.956563</td>\n",
       "      <td>-1.564374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.369139</td>\n",
       "      <td>-0.751699</td>\n",
       "      <td>0.051649</td>\n",
       "      <td>-0.213103</td>\n",
       "      <td>0.967809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.557795</td>\n",
       "      <td>-1.066837</td>\n",
       "      <td>0.401842</td>\n",
       "      <td>-1.213743</td>\n",
       "      <td>1.138775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0 -1.574465  0.259153  1.197370  0.147400  0.649382\n",
       "1  0.689519  0.137652 -1.025709  0.210340 -0.076938\n",
       "2 -0.282727  0.351636 -0.539261  1.216683  0.340782\n",
       "3  0.070889 -0.614808  1.074067 -0.038300 -1.450257\n",
       "4  1.794282  1.458078 -0.207545 -0.442600 -0.147420\n",
       "5  1.112383  0.647473  1.405890  0.073598 -0.276263\n",
       "6  0.397700 -1.526744 -0.712018  1.216290  0.418506\n",
       "7 -0.280647  1.106095 -1.646283 -0.956563 -1.564374\n",
       "8 -0.369139 -0.751699  0.051649 -0.213103  0.967809\n",
       "9 -1.557795 -1.066837  0.401842 -1.213743  1.138775"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4\n",
      "0  0.0  0.0  0.0  0.0  0.0\n",
      "1  0.0  0.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  0.0  0.0  0.0\n",
      "3  0.0  0.0  0.0  0.0  0.0\n",
      "4  0.0  0.0  0.0  0.0  0.0\n",
      "5  0.0  0.0  0.0  0.0  0.0\n",
      "6  0.0  0.0  0.0  0.0  0.0\n",
      "7  0.0  0.0  0.0  0.0  0.0\n",
      "8  0.0  0.0  0.0  0.0  0.0\n",
      "9  0.0  0.0  0.0  0.0  0.0\n",
      "[[-1.5378811   0.94639099]\n",
      " [ 0.86145244 -0.89288636]\n",
      " [-0.00445655 -0.81633628]\n",
      " [ 0.07145103  1.00433417]\n",
      " [ 2.03707133  0.48476997]\n",
      " [ 0.72174172  1.4557763 ]\n",
      " [-0.55854694 -1.60673226]\n",
      " [ 1.6999536  -0.43766686]\n",
      " [-1.10405456 -0.31718909]\n",
      " [-2.18673098  0.17953942]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "np.random.seed(100)\n",
    "# setting up a 10 x 5 vanilla matrix \n",
    "rows = 10\n",
    "cols = 5\n",
    "X = np.random.randn(rows,cols)\n",
    "df = pd.DataFrame(X)\n",
    "# Pandas does the centering for us\n",
    "df = df -df.mean()\n",
    "display(df)\n",
    "\n",
    "# we center it ourselves\n",
    "X_centered = X - X.mean(axis=0)\n",
    "# Then check the difference between pandas and our own set up\n",
    "print(X_centered-df)\n",
    "#Now we do an SVD\n",
    "U, s, V = np.linalg.svd(X_centered)\n",
    "c1 = V.T[:, 0]\n",
    "c2 = V.T[:, 1]\n",
    "W2 = V.T[:, :2]\n",
    "X2D = X_centered.dot(W2)\n",
    "print(X2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18c016",
   "metadata": {
    "editable": true
   },
   "source": [
    "PCA assumes that the dataset is centered around the origin. Scikit-Learnâ€™s PCA classes take care of centering\n",
    "the data for you. However, if you implement PCA yourself (as in the preceding example), or if you use other libraries, donâ€™t\n",
    "forget to center the data first.\n",
    "\n",
    "Once you have identified all the principal components, you can reduce the dimensionality of the dataset\n",
    "down to $d$ dimensions by projecting it onto the hyperplane defined by the first $d$ principal components.\n",
    "Selecting this hyperplane ensures that the projection will preserve as much variance as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f7d439",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "W2 = V.T[:, :2]\n",
    "X2D = X_centered.dot(W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4380bd",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PCA and scikit-learn\n",
    "\n",
    "Scikit-Learnâ€™s PCA class implements PCA using SVD decomposition just like we did before. The\n",
    "following code applies PCA to reduce the dimensionality of the dataset down to two dimensions (note\n",
    "that it automatically takes care of centering the data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c86b9e1",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5378811   0.94639099]\n",
      " [ 0.86145244 -0.89288636]\n",
      " [-0.00445655 -0.81633628]\n",
      " [ 0.07145103  1.00433417]\n",
      " [ 2.03707133  0.48476997]\n",
      " [ 0.72174172  1.4557763 ]\n",
      " [-0.55854694 -1.60673226]\n",
      " [ 1.6999536  -0.43766686]\n",
      " [-1.10405456 -0.31718909]\n",
      " [-2.18673098  0.17953942]]\n"
     ]
    }
   ],
   "source": [
    "#thereafter we do a PCA with Scikit-learn\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "X2D = pca.fit_transform(X)\n",
    "print(X2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658be821",
   "metadata": {
    "editable": true
   },
   "source": [
    "After fitting the PCA transformer to the dataset, you can access the principal components using the\n",
    "components variable (note that it contains the PCs as horizontal vectors, so, for example, the first\n",
    "principal component is equal to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e1bf78",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pca.components_.T[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8772fde",
   "metadata": {
    "editable": true
   },
   "source": [
    "Another very useful piece of information is the explained variance ratio of each principal component,\n",
    "available via the $explained\\_variance\\_ratio$ variable. It indicates the proportion of the datasetâ€™s\n",
    "variance that lies along the axis of each principal component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a30449",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Example of Cancer Data\n",
    "We can now repeat the above but applied to real data, in this case the Wisconsin breast cancer data.\n",
    "Here we compute performance scores on the training data using logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b00fb4",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy from Logistic Regression: 0.96\n",
      "Train set accuracy scaled data: 0.99\n",
      "Train set accuracy scaled and PCA data: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhjensen/miniforge3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import  train_test_split \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data,cancer.target,random_state=0)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Train set accuracy from Logistic Regression: {:.2f}\".format(logreg.score(X_train,y_train)))\n",
    "# We scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Then perform again a log reg fit\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "print(\"Train set accuracy scaled data: {:.2f}\".format(logreg.score(X_train_scaled,y_train)))\n",
    "#thereafter we do a PCA with Scikit-learn\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "X2D_train = pca.fit_transform(X_train_scaled)\n",
    "# and finally compute the log reg fit and the score on the training data\t\n",
    "logreg.fit(X2D_train,y_train)\n",
    "print(\"Train set accuracy scaled and PCA data: {:.2f}\".format(logreg.score(X2D_train,y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c6107",
   "metadata": {
    "editable": true
   },
   "source": [
    "We see that our training data after the PCA decomposition has a performance similar to the non-scaled data. \n",
    "\n",
    "Instead of arbitrarily choosing the number of dimensions to reduce down to, it is generally preferable to\n",
    "choose the number of dimensions that add up to a sufficiently large portion of the variance (e.g., 95%).\n",
    "Unless, of course, you are reducing dimensionality for data visualization â€” in that case you will\n",
    "generally want to reduce the dimensionality down to 2 or 3.\n",
    "The following code computes PCA without reducing dimensionality, then computes the minimum number\n",
    "of dimensions required to preserve 95% of the training setâ€™s variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d57f27f6",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2075098",
   "metadata": {
    "editable": true
   },
   "source": [
    "You could then set $n\\_components=d$ and run PCA again. However, there is a much better option: instead\n",
    "of specifying the number of principal components you want to preserve, you can set $n\\_components$ to be\n",
    "a float between 0.0 and 1.0, indicating the ratio of variance you wish to preserve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53bcfe0a",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf80343c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Incremental PCA\n",
    "\n",
    "One problem with the preceding implementation of PCA is that it requires the whole training set to fit in\n",
    "memory in order for the SVD algorithm to run. Fortunately, Incremental PCA (IPCA) algorithms have\n",
    "been developed: you can split the training set into mini-batches and feed an IPCA algorithm one minibatch\n",
    "at a time. This is useful for large training sets, and also to apply PCA online (i.e., on the fly, as new\n",
    "instances arrive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7b0902",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Randomized PCA\n",
    "\n",
    "Scikit-Learn offers yet another option to perform PCA, called Randomized PCA. This is a stochastic\n",
    "algorithm that quickly finds an approximation of the first d principal components. Its computational\n",
    "complexity is $O(m \\times d^2)+O(d^3)$, instead of $O(m \\times n^2) + O(n^3)$, so it is dramatically faster than the\n",
    "previous algorithms when $d$ is much smaller than $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a87e7d",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Kernel PCA\n",
    "\n",
    "The kernel trick is a mathematical technique that implicitly maps instances into a\n",
    "very high-dimensional space (called the feature space), enabling nonlinear classification and regression\n",
    "with Support Vector Machines. Recall that a linear decision boundary in the high-dimensional feature\n",
    "space corresponds to a complex nonlinear decision boundary in the original space.\n",
    "It turns out that the same trick can be applied to PCA, making it possible to perform complex nonlinear\n",
    "projections for dimensionality reduction. This is called Kernel PCA (kPCA). It is often good at\n",
    "preserving clusters of instances after projection, or sometimes even unrolling datasets that lie close to a\n",
    "twisted manifold.\n",
    "For example, the following code uses Scikit-Learnâ€™s KernelPCA class to perform kPCA with an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dca53466",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.04)\n",
    "X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aad9a26",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Other techniques\n",
    "\n",
    "There are many other dimensionality reduction techniques, several of which are available in Scikit-Learn.\n",
    "\n",
    "Here are some of the most popular:\n",
    "* **Multidimensional Scaling (MDS)** reduces dimensionality while trying to preserve the distances between the instances.\n",
    "\n",
    "* **Isomap** creates a graph by connecting each instance to its nearest neighbors, then reduces dimensionality while trying to preserve the geodesic distances between the instances.\n",
    "\n",
    "* **t-Distributed Stochastic Neighbor Embedding** (t-SNE) reduces dimensionality while trying to keep similar instances close and dissimilar instances apart. It is mostly used for visualization, in particular to visualize clusters of instances in high-dimensional space (e.g., to visualize the MNIST images in 2D).\n",
    "\n",
    "* Linear Discriminant Analysis (LDA) is actually a classification algorithm, but during training it learns the most discriminative axes between the classes, and these axes can then be used to define a hyperplane onto which to project the data. The benefit is that the projection will keep classes as far apart as possible, so LDA is a good technique to reduce dimensionality before running another classification algorithm such as a Support Vector Machine (SVM) classifier discussed in the SVM lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74e472",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Back to Autoencoders: Linear Autoencoders\n",
    "\n",
    "These examples here are based the codes from A. Geron's textbook. They\n",
    "can be easily  modified and adapted to different data sets. The first example is a straightforward AE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca1dbbc",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:54:55.156967: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure linear_autoencoder_pca_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "# Scikit-Learn >=0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow >= 2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"autoencoders\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "np.random.seed(4)\n",
    "\n",
    "def generate_3d_data(m, w1=0.1, w2=0.3, noise=0.1):\n",
    "    angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "    data = np.empty((m, 3))\n",
    "    data[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "    data[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "    data[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * np.random.randn(m)\n",
    "    return data\n",
    "\n",
    "X_train = generate_3d_data(60)\n",
    "X_train = X_train - X_train.mean(axis=0, keepdims=0)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder = keras.models.Sequential([keras.layers.Dense(2, input_shape=[3])])\n",
    "decoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\n",
    "autoencoder = keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "autoencoder.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1.5))\n",
    "\n",
    "codings = encoder.predict(X_train)\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "plt.plot(codings[:,0], codings[:, 1], \"b.\")\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)\n",
    "save_fig(\"linear_autoencoder_pca_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8214443",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More advanced features, stacked AEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cd463ff",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# You can select the so-called fashion data as well, here we just use the MNIST standard set\n",
    "#(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa014c2",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can now train all layers at once by building a stacked AE with 3 hidden layers and 1 output layer (i.e., 2 stacked Autoencoders)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd8c36d1",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def rounded_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "stacked_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "])\n",
    "stacked_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=1.5), metrics=[rounded_accuracy])\n",
    "history = stacked_ae.fit(X_train, X_train, epochs=20,\n",
    "                         validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666bb9a7",
   "metadata": {
    "editable": true
   },
   "source": [
    "This function processes a few test images through the autoencoder and\n",
    "displays the original images and their reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "529a52ba",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def show_reconstructions(model, images=X_valid, n_images=5):\n",
    "    reconstructions = model.predict(images[:n_images])\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(images[image_index])\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index])\n",
    "show_reconstructions(stacked_ae)\n",
    "save_fig(\"reconstruction_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1920fe",
   "metadata": {
    "editable": true
   },
   "source": [
    "Then visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "670a712a",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "from sklearn.manifold import TSNE\n",
    "X_valid_compressed = stacked_encoder.predict(X_valid)\n",
    "tsne = TSNE()\n",
    "X_valid_2D = tsne.fit_transform(X_valid_compressed)\n",
    "X_valid_2D = (X_valid_2D - X_valid_2D.min()) / (X_valid_2D.max() - X_valid_2D.min())\n",
    "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=\"tab10\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4046cd86",
   "metadata": {
    "editable": true
   },
   "source": [
    "And visualize in a nicer way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfb68e06",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# adapted from https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n",
    "plt.figure(figsize=(10, 8))\n",
    "cmap = plt.cm.tab10\n",
    "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=cmap)\n",
    "image_positions = np.array([[1., 1.]])\n",
    "for index, position in enumerate(X_valid_2D):\n",
    "    dist = np.sum((position - image_positions) ** 2, axis=1)\n",
    "    if np.min(dist) > 0.02: # if far enough from other images\n",
    "        image_positions = np.r_[image_positions, [position]]\n",
    "        imagebox = mpl.offsetbox.AnnotationBbox(\n",
    "            mpl.offsetbox.OffsetImage(X_valid[index], cmap=\"binary\"),\n",
    "            position, bboxprops={\"edgecolor\": cmap(y_valid[index]), \"lw\": 2})\n",
    "        plt.gca().add_artist(imagebox)\n",
    "plt.axis(\"off\")\n",
    "save_fig(\"fashion_mnist_visualization_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569080d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Using Convolutional Layers Instead of Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e7801a5",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "conv_encoder = keras.models.Sequential([\n",
    "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
    "    keras.layers.Conv2D(16, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    keras.layers.Conv2D(32, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
    "    keras.layers.MaxPool2D(pool_size=2)\n",
    "])\n",
    "conv_decoder = keras.models.Sequential([\n",
    "    keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"VALID\", activation=\"selu\",\n",
    "                                 input_shape=[3, 3, 64]),\n",
    "    keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"SAME\", activation=\"selu\"),\n",
    "    keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"SAME\", activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n",
    "\n",
    "conv_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
    "                metrics=[rounded_accuracy])\n",
    "history = conv_ae.fit(X_train, X_train, epochs=5,\n",
    "                      validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05619e30",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "conv_encoder.summary()\n",
    "conv_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8eff86d",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_reconstructions(conv_ae)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a39abf",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Recurrent Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "502f6114",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "recurrent_encoder = keras.models.Sequential([\n",
    "    keras.layers.LSTM(100, return_sequences=True, input_shape=[28, 28]),\n",
    "    keras.layers.LSTM(30)\n",
    "])\n",
    "recurrent_decoder = keras.models.Sequential([\n",
    "    keras.layers.RepeatVector(28, input_shape=[30]),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(28, activation=\"sigmoid\"))\n",
    "])\n",
    "recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])\n",
    "recurrent_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(0.1),\n",
    "                     metrics=[rounded_accuracy])\n",
    "history = recurrent_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31fbb792",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_reconstructions(recurrent_ae)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e8233",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Stacked denoising Autoencoder with Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fec0d6c",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "denoising_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.GaussianNoise(0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\")\n",
    "])\n",
    "denoising_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "denoising_ae = keras.models.Sequential([denoising_encoder, denoising_decoder])\n",
    "denoising_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
    "                     metrics=[rounded_accuracy])\n",
    "history = denoising_ae.fit(X_train, X_train, epochs=10,\n",
    "                           validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30d1af80",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "noise = keras.layers.GaussianNoise(0.2)\n",
    "show_reconstructions(denoising_ae, noise(X_valid, training=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82240b17",
   "metadata": {
    "editable": true
   },
   "source": [
    "And using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "302797e5",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "dropout_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\")\n",
    "])\n",
    "dropout_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])\n",
    "dropout_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.0),\n",
    "                   metrics=[rounded_accuracy])\n",
    "history = dropout_ae.fit(X_train, X_train, epochs=10,\n",
    "                         validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74cfb4b4",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "dropout = keras.layers.Dropout(0.5)\n",
    "show_reconstructions(dropout_ae, dropout(X_valid, training=True))\n",
    "save_fig(\"dropout_denoising_plot\", tight_layout=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3aa044",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PyTorch example\n",
    "We will continue with the MNIST database, which has $60000$ training examples and a test set of 10000 handwritten numbers. The images have\n",
    "only one color channel and have a size of $28\\times 28$ pixels.\n",
    "We start by uploading the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e71cebc",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9912422/9912422 [00:03<00:00, 3193744.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28881/28881 [00:00<00:00, 268400.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1648877/1648877 [00:00<00:00, 2012340.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4542/4542 [00:00<00:00, 2184693.67it/s]"
     ]
    }
   ],
   "source": [
    "# import the Torch packages\n",
    "# transforms are used to preprocess the images, e.g. crop, rotate, normalize, etc\n",
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "# specify the data path in which you would like to store the downloaded files\n",
    "# ToTensor() here is used to convert data type to tensor\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "print(train_dataset)\n",
    "batchSize=128\n",
    "\n",
    "#only after packed in DataLoader, can we feed the data into the neural network iteratively\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batchSize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba62ad4",
   "metadata": {
    "editable": true
   },
   "source": [
    "We visualize the images here using the $imshow$ function  function and the $make\\_grid$ function from PyTorch to arrange and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df4c89b4",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# package we used to manipulate matrix\n",
    "import numpy as np\n",
    "# package we used for image processing\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    #transpose: change array axis to correspond to the plt.imshow() function     \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "    plt.show()\n",
    "\n",
    "# load the first 16 training samples from next iteration\n",
    "# [:16,:,:,:] for the 4 dimension of examples, first dimension take first 16, other dimension take all data\n",
    "# arrange the image in grid\n",
    "examples, _ = next(iter(train_loader))\n",
    "example_show=make_grid(examples[:16,:,:,:], 4)\n",
    "\n",
    "# then display them\n",
    "imshow(example_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b589f37",
   "metadata": {
    "editable": true
   },
   "source": [
    "Our autoencoder consists of two parts, see also the TensorFlow example\n",
    "above. The encoder and decoder parts are represented by two fully\n",
    "connected feed forward neural networks where we use the standard\n",
    "Sigmoid function.  In the encoder part we reduce the dimensionality of\n",
    "the image from $28\\times 28=784$ pixels to first $16\\times 16=256$\n",
    "pixels and then to 128 pixels. The 128 pixel representation is then\n",
    "used to define the representation of the input and the input to the\n",
    "decoder part.  The latter attempts to reconstruct the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38db38f8",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Network Parameters\n",
    "num_hidden_1 = 256  # 1st layer num features\n",
    "num_hidden_2 = 128  # 2nd layer num features (the latent dim)\n",
    "num_input = 784  # MNIST data input (img shape: 28*28)\n",
    "\n",
    "\n",
    "# Building the encoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        # decoder part\n",
    "        self.fc3 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc4 = nn.Linear(h_dim1, x_dim)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "    def decoder(self, x):\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# When initializing, it will run __init__() function as above\n",
    "model = Autoencoder(num_input, num_hidden_1, num_hidden_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec55a9e",
   "metadata": {
    "editable": true
   },
   "source": [
    "We define here the cost/loss function and the optimizer we employ (Adam here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27d0c305",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define loss function and parameters\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "epoch = 100\n",
    "# MSE loss will calculate Mean Squared Error between the inputs \n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "print('====Training start====')\n",
    "for i in range(epoch):\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        # prepare input data\n",
    "        inputs = torch.reshape(data,(-1, 784)) # -1 can be any value.\n",
    "        # set gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        # feed inputs into model\n",
    "        recon_x = model(inputs)\n",
    "        # calculating loss \n",
    "        loss = loss_function(recon_x, inputs)\n",
    "        # calculate gradient of each parameter\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        # update the weight based on the gradient calculated\n",
    "        optimizer.step()\n",
    "    if i%10==0:    \n",
    "        print('====> Epoch: {} Average loss: {:.9f}'.format(i, train_loss ))\n",
    "print('====Training finish====')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f43f6b",
   "metadata": {
    "editable": true
   },
   "source": [
    "As we have trained the network, we will now reconstruct various test samples to see if the model can generalize to data which\n",
    "were not included in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "801ee340",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# load 16 images from testset\n",
    "inputs, _ = next(iter(test_loader))\n",
    "inputs_example = make_grid(inputs[:16,:,:,:],4)\n",
    "imshow(inputs_example)\n",
    "\n",
    "#convert from image to tensor\n",
    "#inputs=inputs.cuda()\n",
    "inputs=torch.reshape(inputs,(-1,784))\n",
    "\n",
    "# get the outputs from the trained model\n",
    "outputs=model(inputs)\n",
    "\n",
    "#convert from tensor to image\n",
    "outputs=torch.reshape(outputs,(-1,1,28,28))\n",
    "outputs=outputs.detach().cpu()\n",
    "\n",
    "#show the output images\n",
    "outputs_example = make_grid(outputs[:16,:,:,:],4)\n",
    "imshow(outputs_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f192d97",
   "metadata": {
    "editable": true
   },
   "source": [
    "After training the auto-encoder, we can now use the model to reconstruct some images.\n",
    "In order to reconstruct different training images, the model\n",
    "has learned to recognize how the image looks like and describe it in\n",
    "the 128-dimensional  latent space. In other words, the visual information of\n",
    "images is compressed and encoded in the 128-dimensional representations. As we\n",
    "assume that samples from the same categories should be more visually\n",
    "similar than those from different classes, the representations can\n",
    "then be used for image recognition, i.e., handwritten digit images\n",
    "recognition in our case.\n",
    "\n",
    "One simple way to recognize images is to randomly select ten training\n",
    "samples from each class and annotate them with the corresponding label.\n",
    "Then given the\n",
    "test data, we can predict which classes they belong to by finding the\n",
    "most similar labelled training samples to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc5704ea",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get 100 image-label pairs from training set\n",
    "x_train, y_train = next(iter(train_loader))\n",
    "\n",
    "# 10 classes, 10 samples per class, 100 in total\n",
    "candidates = np.random.choice(batchSize, 10*10)\n",
    "\n",
    "# randomly select 100 samples\n",
    "x_train = x_train[candidates]\n",
    "y_train = y_train[candidates]\n",
    "\n",
    "# display the selected samples and print their labels\n",
    "\n",
    "imshow(make_grid(x_train[:100,:,:,:],10))\n",
    "print(y_train.reshape(10, 10))\n",
    "\n",
    "# get 100 image-label pairs from test set\n",
    "x_test, y_test = next(iter(train_loader))\n",
    "candidates_test = np.random.choice(batchSize, 10*10)\n",
    "\n",
    "x_test = x_test[candidates_test]\n",
    "y_test = y_test[candidates_test]\n",
    "\n",
    "# display the selected samples and print their labels\n",
    "imshow(make_grid(x_test[:100,:,:,:],10))\n",
    "\n",
    "print(y_test.reshape(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6ac1921",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# compute the representations of training and test samples\n",
    "#h_train=model.encoder(torch.reshape(x_train.cuda(),(-1,784)))\n",
    "#h_test=model.encoder(torch.reshape(x_test.cuda(),(-1,784)))\n",
    "h_train=model.encoder(torch.reshape(x_train,(-1,784)))\n",
    "h_test=model.encoder(torch.reshape(x_test,(-1,784)))\n",
    "\n",
    "# find the nearest training samples to each test instance, in terms of MSE\n",
    "MSEs = np.mean(np.power(np.expand_dims(h_test.detach().cpu(), axis=1) - np.expand_dims(h_train.detach().cpu(), axis=0), 2), axis=2)\n",
    "neighbours = MSEs.argmin(axis=1)\n",
    "predicts = y_train[neighbours]\n",
    "\n",
    "# print(np.stack([y_test, predicts], axis=1))\n",
    "print('Recognition accuracy according to the learned representation is %.1f%%' % (100 * (y_test == predicts).numpy().astype(np.float32).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c463a16b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Summary of course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef380cb",
   "metadata": {
    "editable": true
   },
   "source": [
    "## What? Me worry? No final exam in this course!\n",
    "<!-- dom:FIGURE: [figures/exam1.jpeg, width=500 frac=0.6] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/exam1.jpeg\" width=\"500\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda3d8b8",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Topics we have covered this year\n",
    "\n",
    "The course has two central parts\n",
    "\n",
    "1. Statistical analysis and optimization of data\n",
    "\n",
    "2. Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a11a46",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Statistical analysis and optimization of data\n",
    "\n",
    "The following topics have been discussed:\n",
    "1. Basic concepts, expectation values, variance, covariance, correlation functions and errors;\n",
    "\n",
    "2. Simpler models, binomial distribution, the Poisson distribution, simple and multivariate normal distributions;\n",
    "\n",
    "3. Central elements from linear algebra, matrix inversion and SVD\n",
    "\n",
    "4. Gradient methods for data optimization\n",
    "\n",
    "5. Estimation of errors using cross-validation, bootstrapping and jackknife methods;\n",
    "\n",
    "6. Practical optimization using Singular-value decomposition and least squares for parameterizing data.\n",
    "\n",
    "7. Not discussed: Principal Component Analysis to reduce the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ee12b0",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Machine learning\n",
    "\n",
    "* Linear methods for regression and classification:\n",
    "\n",
    "a. Ordinary Least Squares\n",
    "\n",
    "b. Ridge regression\n",
    "\n",
    "c. Lasso regression\n",
    "\n",
    "d. Logistic regression\n",
    "\n",
    "* Neural networks and deep learning:\n",
    "\n",
    "a. Feed Forward Neural Networks\n",
    "\n",
    "b. Convolutional Neural Networks\n",
    "\n",
    "c. Recurrent Neural Networks\n",
    "\n",
    "d. Autoencoders and PCA\n",
    "\n",
    "* Not discussed this year Decisions trees and ensemble methods:\n",
    "\n",
    "a. Decision trees\n",
    "\n",
    "b. Bagging and voting\n",
    "\n",
    "c. Random forests\n",
    "\n",
    "d. Boosting and gradient boosting\n",
    "\n",
    "* Not discussed this year: Support vector machines\n",
    "\n",
    "a. Binary classification and multiclass classification\n",
    "\n",
    "b. Kernel methods\n",
    "\n",
    "c. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e159a",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Learning outcomes and overarching aims of this course\n",
    "\n",
    "The course introduces a variety of central algorithms and methods\n",
    "essential for studies of data analysis and machine learning. The\n",
    "course is project based and through the various projects, normally\n",
    "three, you will be exposed to fundamental research problems\n",
    "in these fields, with the aim to reproduce state of the art scientific\n",
    "results. The students will learn to develop and structure large codes\n",
    "for studying these systems, get acquainted with computing facilities\n",
    "and learn to handle large scientific projects. A good scientific and\n",
    "ethical conduct is emphasized throughout the course. \n",
    "\n",
    "* Understand linear methods for regression and classification;\n",
    "\n",
    "* Learn about neural network and deep learning methods;\n",
    "<!-- * Learn about bagging, boosting and trees -->\n",
    "<!-- * Support vector machines -->\n",
    "\n",
    "* Learn about basic data analysis;\n",
    "\n",
    "* Be capable of extending the acquired knowledge to other systems and cases;\n",
    "\n",
    "* Have an understanding of central algorithms used in data analysis and machine learning;\n",
    "\n",
    "* Work on numerical projects to illustrate the theory. The projects play a central role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b229c77",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Perspective on Machine Learning\n",
    "\n",
    "1. Rapidly emerging application area\n",
    "\n",
    "2. Experiment AND theory are evolving in many many fields. \n",
    "\n",
    "3. Requires education/retraining for more widespread adoption\n",
    "\n",
    "4. A lot of â€œword-of-mouthâ€ development methods\n",
    "\n",
    "5. And LLMs are playing a big role here\n",
    "\n",
    "Huge amounts of data sets require automation, classical analysis tools often inadequate. \n",
    "High energy physics hit this wall in the 90â€™s.\n",
    "In 2009 single top quark production was determined via [Boosted decision trees, Bayesian\n",
    "Neural Networks, etc.](https://arxiv.org/pdf/0903.0850.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a990a",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Machine Learning Research\n",
    "\n",
    "Where to find recent results:\n",
    "1. Conference proceedings, arXiv and blog posts!\n",
    "\n",
    "2. **NIPS**: [Neural Information Processing Systems](https://papers.nips.cc)\n",
    "\n",
    "3. **ICLR**: [International Conference on Learning Representations](https://openreview.net/group?id=ICLR.cc/2018/Conference#accepted-oral-papers)\n",
    "\n",
    "4. **ICML**: International Conference on Machine Learning\n",
    "\n",
    "5. [Journal of Machine Learning Research](http://www.jmlr.org/papers/v19/) \n",
    "\n",
    "6. [Follow ML on ArXiv](https://arxiv.org/list/cs.LG/recent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2823ead5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Starting your Machine Learning Project\n",
    "\n",
    "1. Identify problem type: classification, regression\n",
    "\n",
    "2. Consider your data carefully\n",
    "\n",
    "3. Choose a simple model that fits 1 and 2\n",
    "\n",
    "4. Consider your data carefully again! Think of data representation more carefully.\n",
    "\n",
    "5. Based on your results, feedback loop to earliest possible point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290963c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Choose a Model and Algorithm\n",
    "\n",
    "* Supervised?\n",
    "\n",
    "* Start with the simplest model that fits your problem\n",
    "\n",
    "* Start with minimal processing of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790e3aa",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Preparing Your Data\n",
    "\n",
    "* Shuffle your data\n",
    "\n",
    "* Mean center your data\n",
    "\n",
    "  * Why?\n",
    "\n",
    "* Normalize the variance\n",
    "\n",
    "  * Why?\n",
    "\n",
    "* **Whitening**\n",
    "\n",
    "  * Decorrelates data\n",
    "\n",
    "  * Can be hit or miss\n",
    "\n",
    " * When to do train/test split?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f079e7f4",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Which activation and weights to choose in neural networks\n",
    "\n",
    "* RELU? ELU? GELU? etc\n",
    "\n",
    "* Sigmoid or Tanh?\n",
    "\n",
    "* Set all weights to 0? Terrible idea\n",
    "\n",
    "* Set all weights to random values? Small random values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb854913",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Optimization Methods and Hyperparameters\n",
    "* Stochastic gradient descent\n",
    "\n",
    " * Stochastic gradient descent + momentum\n",
    "\n",
    "* State-of-the-art approaches:\n",
    "\n",
    "a. RMSProp\n",
    "\n",
    "b. Adam\n",
    "\n",
    "c. and more\n",
    "\n",
    "Which regularization and hyperparameters? $L_1$ or $L_2$, soft\n",
    "classifiers, depths of trees and many other. Need to explore a large\n",
    "set of hyperparameters and regularization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25709f91",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling\n",
    "\n",
    "When do we resample?\n",
    "\n",
    "1. [Bootstrap](https://www.cambridge.org/core/books/bootstrap-methods-and-their-application/ED2FD043579F27952363566DC09CBD6A)\n",
    "\n",
    "2. [Cross-validation](https://www.youtube.com/watch?v=fSytzGwwBVw&ab_channel=StatQuestwithJoshStarmer)\n",
    "\n",
    "3. Jackknife and many other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745738c8",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Other courses on Data science and Machine Learning  at UiO\n",
    "\n",
    "1. [FYS5429 â€“ Advanced machine learning and data analysis for the physical sciences](https://www.uio.no/studier/emner/matnat/fys/FYS5429/index-eng.html)\n",
    "\n",
    "2. [IN3050/IN4050 Introduction to Artificial Intelligence and Machine Learning](https://www.uio.no/studier/emner/matnat/ifi/IN3050/index-eng.html). Introductory course in machine learning and AI\n",
    "\n",
    "3. [STK-INF3000/4000 Selected Topics in Data Science](http://www.uio.no/studier/emner/matnat/math/STK-INF3000/index-eng.html). The course provides insight into selected contemporary relevant topics within Data Science. \n",
    "\n",
    "4. [IN4080 Natural Language Processing](https://www.uio.no/studier/emner/matnat/ifi/IN4080/index.html). Probabilistic and machine learning techniques applied to natural language processing. \n",
    "\n",
    "5. [STK-IN4300 â€“ Statistical learning methods in Data Science](https://www.uio.no/studier/emner/matnat/math/STK-IN4300/index-eng.html). An advanced introduction to statistical and machine learning. For students with a good mathematics and statistics background.\n",
    "\n",
    "6. [IN-STK5000  Responsible Data Science](https://www.uio.no/studier/emner/matnat/ifi/IN-STK5000/index-eng.html). Methods for adaptive collection and processing of data based on machine learning techniques. \n",
    "\n",
    "7. [IN4310 â€“ Machine Learning for Image Analysis](https://www.uio.no/studier/emner/matnat/ifi/IN4310/index.html). An introduction to deep learning with particular emphasis on applications within Image analysis, but useful for other application areas too.\n",
    "\n",
    "8. [IN5310 â€“ Advanced Deep Learning for Image Analysis](https://www.uio.no/studier/emner/matnat/ifi/IN5310/index.html)\n",
    "\n",
    "9. [IN5490 â€“ Advanced Topics in Artificial Intelligence for Intelligent Systems](https://www.uio.no/studier/emner/matnat/ifi/IN5490/index.html)\n",
    "\n",
    "10. [TEK5040 â€“ Deep learning for autonomous systems](https://www.uio.no/studier/emner/matnat/its/TEK5040/). The course addresses advanced algorithms and architectures for deep learning with neural networks. The course provides an introduction to how deep-learning techniques can be used in the construction of key parts of advanced autonomous systems that exist in physical environments and cyber environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8126af",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Additional courses of interest\n",
    "\n",
    "1. [STK4051 Computational Statistics](https://www.uio.no/studier/emner/matnat/math/STK4051/index-eng.html)\n",
    "\n",
    "2. [STK4021 Applied Bayesian Analysis and Numerical Methods](https://www.uio.no/studier/emner/matnat/math/STK4021/index-eng.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06183c0b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## What's the future like?\n",
    "\n",
    "Based on multi-layer nonlinear neural networks, deep learning can\n",
    "learn directly from raw data, automatically extract and abstract\n",
    "features from layer to layer, and then achieve the goal of regression,\n",
    "classification, or ranking. Deep learning has made breakthroughs in\n",
    "computer vision, speech processing and natural language, and reached\n",
    "or even surpassed human level. The success of deep learning is mainly\n",
    "due to the three factors: big data, big model, and big computing.\n",
    "\n",
    "In the past few decades, many different architectures of deep neural\n",
    "networks have been proposed, such as\n",
    "1. Convolutional neural networks, which are mostly used in image and video data processing, and have also been applied to sequential data such as text processing;\n",
    "\n",
    "2. Recurrent neural networks, which can process sequential data of variable length and have been widely used in natural language understanding and speech processing;\n",
    "\n",
    "3. Encoder-decoder framework, which is mostly used for image or sequence generation, such as machine translation, text summarization, and image captioning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce5153",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Types of Machine Learning, a repetition\n",
    "\n",
    "The approaches to machine learning are many, but are often split into two main categories. \n",
    "In *supervised learning* we know the answer to a problem,\n",
    "and let the computer deduce the logic behind it. On the other hand, *unsupervised learning*\n",
    "is a method for finding patterns and relationship in data sets without any prior knowledge of the system.\n",
    "Some authours also operate with a third category, namely *reinforcement learning*. This is a paradigm \n",
    "of learning inspired by behavioural psychology, where learning is achieved by trial-and-error, \n",
    "solely from rewards and punishment.\n",
    "\n",
    "Another way to categorize machine learning tasks is to consider the desired output of a system.\n",
    "Some of the most common tasks are:\n",
    "\n",
    "  * Classification: Outputs are divided into two or more classes. The goal is to   produce a model that assigns inputs into one of these classes. An example is to identify  digits based on pictures of hand-written ones. Classification is typically supervised learning.\n",
    "\n",
    "  * Regression: Finding a functional relationship between an input data set and a reference data set.   The goal is to construct a function that maps input data to continuous output values.\n",
    "\n",
    "  * Clustering: Data are divided into groups with certain common traits, without knowing the different groups beforehand.  It is thus a form of unsupervised learning.\n",
    "\n",
    "  * Other unsupervised learning algortihms like **Boltzmann machines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414bb9b8",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Why Boltzmann machines?\n",
    "\n",
    "What is known as restricted Boltzmann Machines (RMB) have received a lot of attention lately. \n",
    "One of the major reasons is that they can be stacked layer-wise to build deep neural networks that capture complicated statistics.\n",
    "\n",
    "The original RBMs had just one visible layer and a hidden layer, but recently so-called Gaussian-binary RBMs have gained quite some popularity in imaging since they are capable of modeling continuous data that are common to natural images. \n",
    "\n",
    "Furthermore, they have been used to solve complicated [quantum mechanical many-particle problems or classical statistical physics problems like the Ising and Potts classes of models](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.91.045002)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b3690",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Boltzmann Machines\n",
    "\n",
    "Why use a generative model rather than the more well known discriminative deep neural networks (DNN)? \n",
    "\n",
    "* Discriminitave methods have several limitations: They are mainly supervised learning methods, thus requiring labeled data. And there are tasks they cannot accomplish, like drawing new examples from an unknown probability distribution.\n",
    "\n",
    "* A generative model can learn to represent and sample from a probability distribution. The core idea is to learn a parametric model of the probability distribution from which the training data was drawn. As an example\n",
    "\n",
    "a. A model for images could learn to draw new examples of cats and dogs, given a training dataset of images of cats and dogs.\n",
    "\n",
    "b. Generate a sample of an ordered or disordered phase, having been given samples of such phases.\n",
    "\n",
    "c. Model the trial function for [Monte Carlo calculations](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.91.045002)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6bc6a9",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Some similarities and differences from DNNs\n",
    "\n",
    "1. Both use gradient-descent based learning procedures for minimizing cost functions\n",
    "\n",
    "2. Energy based models don't use backpropagation and automatic differentiation for computing gradients, instead turning to Markov Chain Monte Carlo methods.\n",
    "\n",
    "3. DNNs often have several hidden layers. A restricted Boltzmann machine has only one hidden layer, however several RBMs can be stacked to make up Deep Belief Networks, of which they constitute the building blocks.\n",
    "\n",
    "History: The RBM was developed by amongst others [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton), called by some the \"Godfather of Deep Learning\", working with the University of Toronto and Google."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cee93b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Boltzmann machines (BM)\n",
    "\n",
    "A BM is what we would call an undirected probabilistic graphical model\n",
    "with stochastic continuous or discrete units.\n",
    "\n",
    "It is interpreted as a stochastic recurrent neural network where the\n",
    "state of each unit(neurons/nodes) depends on the units it is connected\n",
    "to. The weights in the network represent thus the strength of the\n",
    "interaction between various units/nodes.\n",
    "\n",
    "It turns into a Hopfield network if we choose deterministic rather\n",
    "than stochastic units. In contrast to a Hopfield network, a BM is a\n",
    "so-called generative model. It allows us to generate new samples from\n",
    "the learned distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620c2ac",
   "metadata": {
    "editable": true
   },
   "source": [
    "## A standard BM setup\n",
    "\n",
    "A standard BM network is divided into a set of observable and visible units $\\hat{x}$ and a set of unknown hidden units/nodes $\\hat{h}$.\n",
    "\n",
    "Additionally there can be bias nodes for the hidden and visible layers. These biases are normally set to $1$.\n",
    "\n",
    "BMs are stackable, meaning they cwe can train a BM which serves as input to another BM. We can construct deep networks for learning complex PDFs. The layers can be trained one after another, a feature which makes them popular in deep learning\n",
    "\n",
    "However, they are often hard to train. This leads to the introduction of so-called restricted BMs, or RBMS.\n",
    "Here we take away all lateral connections between nodes in the visible layer as well as connections between nodes in the hidden layer. The network is illustrated in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7c204",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The structure of the RBM network\n",
    "\n",
    "<!-- dom:FIGURE: [figures/RBM.png, width=800 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/RBM.png\" width=\"800\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797f5dd",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The network\n",
    "\n",
    "**The network layers**:\n",
    "1. A function $\\mathbf{x}$ that represents the visible layer, a vector of $M$ elements (nodes). This layer represents both what the RBM might be given as training input, and what we want it to be able to reconstruct. This might for example be given by the pixels of an image or coefficients representing speech, or the coordinates of a quantum mechanical state function.\n",
    "\n",
    "2. The function $\\mathbf{h}$ represents the hidden, or latent, layer. A vector of $N$ elements (nodes). Also called \"feature detectors\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01432b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Goals\n",
    "\n",
    "The goal of the hidden layer is to increase the model's expressive\n",
    "power. We encode complex interactions between visible variables by\n",
    "introducing additional, hidden variables that interact with visible\n",
    "degrees of freedom in a simple manner, yet still reproduce the complex\n",
    "correlations between visible degrees in the data once marginalized\n",
    "over (integrated out).\n",
    "\n",
    "**The network parameters, to be optimized/learned**:\n",
    "1. $\\mathbf{a}$ represents the visible bias, a vector of same length as $\\mathbf{x}$.\n",
    "\n",
    "2. $\\mathbf{b}$ represents the hidden bias, a vector of same lenght as $\\mathbf{h}$.\n",
    "\n",
    "3. $W$ represents the interaction weights, a matrix of size $M\\times N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d4ba60",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Joint distribution\n",
    "\n",
    "The restricted Boltzmann machine is described by a Boltzmann distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0625a2",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tP_{rbm}(\\mathbf{x},\\mathbf{h}) = \\frac{1}{Z} e^{-\\frac{1}{T_0}E(\\mathbf{x},\\mathbf{h})},\n",
    "\\label{_auto1} \\tag{1}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501fcc54",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $Z$ is the normalization constant or partition function, defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf7dcb8",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tZ = \\int \\int e^{-\\frac{1}{T_0}E(\\mathbf{x},\\mathbf{h})} d\\mathbf{x} d\\mathbf{h}.\n",
    "\\label{_auto2} \\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1621d8",
   "metadata": {
    "editable": true
   },
   "source": [
    "It is common to ignore $T_0$ by setting it to one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c16d182",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Network Elements, the energy function\n",
    "\n",
    "The function $E(\\mathbf{x},\\mathbf{h})$ gives the **energy** of a\n",
    "configuration (pair of vectors) $(\\mathbf{x}, \\mathbf{h})$. The lower\n",
    "the energy of a configuration, the higher the probability of it. This\n",
    "function also depends on the parameters $\\mathbf{a}$, $\\mathbf{b}$ and\n",
    "$W$. Thus, when we adjust them during the learning procedure, we are\n",
    "adjusting the energy function to best fit our problem.\n",
    "\n",
    "An expression for the energy function is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca2c91",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E(\\hat{x},\\hat{h}) = -\\sum_{ia}^{NA}b_i^a \\alpha_i^a(x_i)-\\sum_{jd}^{MD}c_j^d \\beta_j^d(h_j)-\\sum_{ijad}^{NAMD}b_i^a \\alpha_i^a(x_i)c_j^d \\beta_j^d(h_j)w_{ij}^{ad}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b98e1",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here $\\beta_j^d(h_j)$ and $\\alpha_i^a(x_j)$ are so-called transfer functions that map a given input value to a desired feature value. The labels $a$ and $d$ denote that there can be multiple transfer functions per variable. The first sum depends only on the visible units. The second on the hidden ones. **Note** that there is no connection between nodes in a layer.\n",
    "\n",
    "The quantities $b$ and $c$ can be interpreted as the visible and hidden biases, respectively.\n",
    "\n",
    "The connection between the nodes in the two layers is given by the weights $w_{ij}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba0760",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Defining different types of RBMs\n",
    "There are different variants of RBMs, and the differences lie in the types of visible and hidden units we choose as well as in the implementation of the energy function $E(\\mathbf{x},\\mathbf{h})$. \n",
    "\n",
    "**Binary-Binary RBM:**\n",
    "\n",
    "RBMs were first developed using binary units in both the visible and hidden layer. The corresponding energy function is defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7425d0",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto3\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tE(\\mathbf{x}, \\mathbf{h}) = - \\sum_i^M x_i a_i- \\sum_j^N b_j h_j - \\sum_{i,j}^{M,N} x_i w_{ij} h_j,\n",
    "\\label{_auto3} \\tag{3}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34a047",
   "metadata": {
    "editable": true
   },
   "source": [
    "where the binary values taken on by the nodes are most commonly 0 and 1.\n",
    "\n",
    "**Gaussian-Binary RBM:**\n",
    "\n",
    "Another varient is the RBM where the visible units are Gaussian while the hidden units remain binary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f2172",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto4\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tE(\\mathbf{x}, \\mathbf{h}) = \\sum_i^M \\frac{(x_i - a_i)^2}{2\\sigma_i^2} - \\sum_j^N b_j h_j - \\sum_{i,j}^{M,N} \\frac{x_i w_{ij} h_j}{\\sigma_i^2}. \n",
    "\\label{_auto4} \\tag{4}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5fb2fd",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More about RBMs\n",
    "1. Useful when we model continuous data (i.e., we wish $\\mathbf{x}$ to be continuous)\n",
    "\n",
    "2. Requires a smaller learning rate, since there's no upper bound to the value a component might take in the reconstruction\n",
    "\n",
    "Other types of units include:\n",
    "1. Softmax and multinomial units\n",
    "\n",
    "2. Gaussian visible and hidden units\n",
    "\n",
    "3. Binomial units\n",
    "\n",
    "4. Rectified linear units\n",
    "\n",
    "To read more, see [Lectures on Boltzmann machines in Physics](https://github.com/CompPhysics/ComputationalPhysics2/blob/gh-pages/doc/pub/notebook2/ipynb/notebook2.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b16cc5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Autoencoders: Overarching view\n",
    "\n",
    "Autoencoders are artificial neural networks capable of learning\n",
    "efficient representations of the input data (these representations are called codings)  without\n",
    "any supervision (i.e., the training set is unlabeled). These codings\n",
    "typically have a much lower dimensionality than the input data, making\n",
    "autoencoders useful for dimensionality reduction. \n",
    "\n",
    "More importantly, autoencoders act as powerful feature detectors, and\n",
    "they can be used for unsupervised pretraining of deep neural networks.\n",
    "\n",
    "Lastly, they are capable of randomly generating new data that looks\n",
    "very similar to the training data; this is called a generative\n",
    "model. For example, you could train an autoencoder on pictures of\n",
    "faces, and it would then be able to generate new faces.  Surprisingly,\n",
    "autoencoders work by simply learning to copy their inputs to their\n",
    "outputs. This may sound like a trivial task, but we will see that\n",
    "constraining the network in various ways can make it rather\n",
    "difficult. For example, you can limit the size of the internal\n",
    "representation, or you can add noise to the inputs and train the\n",
    "network to recover the original inputs. These constraints prevent the\n",
    "autoencoder from trivially copying the inputs directly to the outputs,\n",
    "which forces it to learn efficient ways of representing the data. In\n",
    "short, the codings are byproducts of the autoencoderâ€™s attempt to\n",
    "learn the identity function under some constraints.\n",
    "\n",
    "[Video on autoencoders](https://www.coursera.org/lecture/building-deep-learning-models-with-tensorflow/autoencoders-1U4L3)\n",
    "\n",
    "See also A. Geron's textbook, chapter 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36297c1c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Bayesian Machine Learning\n",
    "\n",
    "This is an important topic if we aim at extracting a probability\n",
    "distribution. This gives us also a confidence interval and error\n",
    "estimates.\n",
    "\n",
    "Bayesian machine learning allows us to encode our prior beliefs about\n",
    "what those models should look like, independent of what the data tells\n",
    "us. This is especially useful when we donâ€™t have a ton of data to\n",
    "confidently learn our model.\n",
    "\n",
    "[Video on Bayesian deep learning](https://www.youtube.com/watch?v=E1qhGw8QxqY&ab_channel=AndrewGordonWilson)\n",
    "\n",
    "See also the [slides here](https://github.com/CompPhysics/MachineLearning/blob/master/doc/Articles/lec03.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ab9cf",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Reinforcement Learning\n",
    "\n",
    "Reinforcement Learning (RL) is one of the most exciting fields of\n",
    "Machine Learning today, and also one of the oldest. It has been around\n",
    "since the 1950s, producing many interesting applications over the\n",
    "years.\n",
    "\n",
    "It studies\n",
    "how agents take actions based on trial and error, so as to maximize\n",
    "some notion of cumulative reward in a dynamic system or\n",
    "environment. Due to its generality, the problem has also been studied\n",
    "in many other disciplines, such as game theory, control theory,\n",
    "operations research, information theory, multi-agent systems, swarm\n",
    "intelligence, statistics, and genetic algorithms.\n",
    "\n",
    "In March 2016, AlphaGo, a computer program that plays the board game\n",
    "Go, beat Lee Sedol in a five-game match. This was the first time a\n",
    "computer Go program had beaten a 9-dan (highest rank) professional\n",
    "without handicaps. AlphaGo is based on deep convolutional neural\n",
    "networks and reinforcement learning. AlphaGoâ€™s victory was a major\n",
    "milestone in artificial intelligence and it has also made\n",
    "reinforcement learning a hot research area in the field of machine\n",
    "learning.\n",
    "\n",
    "[Lecture on Reinforcement Learning](https://www.youtube.com/watch?v=FgzM3zpZ55o&ab_channel=stanfordonline).\n",
    "\n",
    "See also A. Geron's textbook, chapter 16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66304a",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Transfer learning\n",
    "\n",
    "The goal of transfer learning is to transfer the model or knowledge\n",
    "obtained from a source task to the target task, in order to resolve\n",
    "the issues of insufficient training data in the target task. The\n",
    "rationality of doing so lies in that usually the source and target\n",
    "tasks have inter-correlations, and therefore either the features,\n",
    "samples, or models in the source task might provide useful information\n",
    "for us to better solve the target task. Transfer learning is a hot\n",
    "research topic in recent years, with many problems still waiting to be studied.\n",
    "\n",
    "[Lecture on transfer learning](https://www.ias.edu/video/machinelearning/2020/0331-SamoryKpotufe)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed686fb",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Adversarial learning\n",
    "\n",
    "The conventional deep generative model has a potential problem: the\n",
    "model tends to generate extreme instances to maximize the\n",
    "probabilistic likelihood, which will hurt its performance. Adversarial\n",
    "learning utilizes the adversarial behaviors (e.g., generating\n",
    "adversarial instances or training an adversarial model) to enhance the\n",
    "robustness of the model and improve the quality of the generated\n",
    "data. In recent years, one of the most promising unsupervised learning\n",
    "technologies, generative adversarial networks (GAN), has already been\n",
    "successfully applied to image, speech, and text.\n",
    "\n",
    "[Lecture on adversial learning](https://www.youtube.com/watch?v=CIfsB_EYsVI&ab_channel=StanfordUniversitySchoolofEngineering)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46abaf8",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Dual learning\n",
    "\n",
    "Dual learning is a new learning paradigm, the basic idea of which is\n",
    "to use the primal-dual structure between machine learning tasks to\n",
    "obtain effective feedback/regularization, and guide and strengthen the\n",
    "learning process, thus reducing the requirement of large-scale labeled\n",
    "data for deep learning. The idea of dual learning has been applied to\n",
    "many problems in machine learning, including machine translation,\n",
    "image style conversion, question answering and generation, image\n",
    "classification and generation, text classification and generation,\n",
    "image-to-text, and text-to-image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b9eb1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Distributed machine learning\n",
    "\n",
    "Distributed computation will speed up machine learning algorithms,\n",
    "significantly improve their efficiency, and thus enlarge their\n",
    "application. When distributed meets machine learning, more than just\n",
    "implementing the machine learning algorithms in parallel is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226dc6c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Meta learning\n",
    "\n",
    "Meta learning is an emerging research direction in machine\n",
    "learning. Roughly speaking, meta learning concerns learning how to\n",
    "learn, and focuses on the understanding and adaptation of the learning\n",
    "itself, instead of just completing a specific learning task. That is,\n",
    "a meta learner needs to be able to evaluate its own learning methods\n",
    "and adjust its own learning methods according to specific learning\n",
    "tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3712bec4",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The Challenges Facing Machine Learning\n",
    "\n",
    "While there has been much progress in machine learning, there are also challenges.\n",
    "\n",
    "For example, the mainstream machine learning technologies are\n",
    "black-box approaches, making us concerned about their potential\n",
    "risks. To tackle this challenge, we may want to make machine learning\n",
    "more explainable and controllable. As another example, the\n",
    "computational complexity of machine learning algorithms is usually\n",
    "very high and we may want to invent lightweight algorithms or\n",
    "implementations. Furthermore, in many domains such as physics,\n",
    "chemistry, biology, and social sciences, people usually seek elegantly\n",
    "simple equations (e.g., the SchrÃ¶dinger equation) to uncover the\n",
    "underlying laws behind various phenomena. In the field of machine\n",
    "learning, can we reveal simple laws instead of designing more complex\n",
    "models for data fitting? Although there are many challenges, we are\n",
    "still very optimistic about the future of machine learning. As we look\n",
    "forward to the future, here are what we think the research hotspots in\n",
    "the next ten years will be.\n",
    "\n",
    "See the article on [Discovery of Physics From Data: Universal Laws and Discrepancies](https://www.frontiersin.org/articles/10.3389/frai.2020.00025/full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914a5ab",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Explainable machine learning\n",
    "\n",
    "Machine learning, especially deep learning, evolves rapidly. The\n",
    "ability gap between machine and human on many complex cognitive tasks\n",
    "becomes narrower and narrower. However, we are still in the very early\n",
    "stage in terms of explaining why those effective models work and how\n",
    "they work.\n",
    "\n",
    "**What is missing: the gap between correlation and causation**. Standard Machine Learning is based on what e have called a frequentist approach. \n",
    "\n",
    "Most\n",
    "machine learning techniques, especially the statistical ones, depend\n",
    "highly on correlations in data sets to make predictions and analyses. In\n",
    "contrast, rational humans tend to reply on clear and trustworthy\n",
    "causality relations obtained via logical reasoning on real and clear\n",
    "facts. It is one of the core goals of explainable machine learning to\n",
    "transition from solving problems by data correlation to solving\n",
    "problems by logical reasoning.\n",
    "\n",
    "**Bayesian Machine Learning is one of the exciting research directions in this field**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e50346",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Quantum machine learning\n",
    "\n",
    "Quantum machine learning is an emerging interdisciplinary research\n",
    "area at the intersection of quantum computing and machine learning.\n",
    "\n",
    "Quantum computers use effects such as quantum coherence and quantum\n",
    "entanglement to process information, which is fundamentally different\n",
    "from classical computers. Quantum algorithms have surpassed the best\n",
    "classical algorithms in several problems (e.g., searching for an\n",
    "unsorted database, inverting a sparse matrix), which we call quantum\n",
    "acceleration.\n",
    "\n",
    "When quantum computing meets machine learning, it can be a mutually\n",
    "beneficial and reinforcing process, as it allows us to take advantage\n",
    "of quantum computing to improve the performance of classical machine\n",
    "learning algorithms. In addition, we can also use the machine learning\n",
    "algorithms (on classic computers) to analyze and improve quantum\n",
    "computing systems.\n",
    "\n",
    "[Lecture on Quantum ML](https://www.youtube.com/watch?v=Xh9pUu3-WxM&ab_channel=InstituteforPure%26AppliedMathematics%28IPAM%29).\n",
    "\n",
    "[Read interview with Maria Schuld on her work on Quantum Machine Learning](https://physics.aps.org/articles/v13/179?utm_campaign=weekly&utm_medium=email&utm_source=emailalert). See also [her recent textbook](https://www.springer.com/gp/book/9783319964232)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7843a44",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Quantum machine learning algorithms based on linear algebra\n",
    "\n",
    "Many quantum machine learning algorithms are based on variants of\n",
    "quantum algorithms for solving linear equations, which can efficiently\n",
    "solve N-variable linear equations with complexity of O(log2 N) under\n",
    "certain conditions. The quantum matrix inversion algorithm can\n",
    "accelerate many machine learning methods, such as least square linear\n",
    "regression, least square version of support vector machine, Gaussian\n",
    "process, and more. The training of these algorithms can be simplified\n",
    "to solve linear equations. The key bottleneck of this type of quantum\n",
    "machine learning algorithms is data inputâ€”that is, how to initialize\n",
    "the quantum system with the entire data set. Although efficient\n",
    "data-input algorithms exist for certain situations, how to efficiently\n",
    "input data into a quantum system is as yet unknown for most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b86495",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Quantum reinforcement learning\n",
    "\n",
    "In quantum reinforcement learning, a quantum agent interacts with the\n",
    "classical environment to obtain rewards from the environment, so as to\n",
    "adjust and improve its behavioral strategies. In some cases, it\n",
    "achieves quantum acceleration by the quantum processing capabilities\n",
    "of the agent or the possibility of exploring the environment through\n",
    "quantum superposition. Such algorithms have been proposed in\n",
    "superconducting circuits and systems of trapped ions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a69e4",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Quantum deep learning\n",
    "\n",
    "Dedicated quantum information processors, such as quantum annealers\n",
    "and programmable photonic circuits, are well suited for building deep\n",
    "quantum networks. The simplest deep quantum network is the Boltzmann\n",
    "machine. The classical Boltzmann machine consists of bits with tunable\n",
    "interactions and is trained by adjusting the interaction of these bits\n",
    "so that the distribution of its expression conforms to the statistics\n",
    "of the data. To quantize the Boltzmann machine, the neural network can\n",
    "simply be represented as a set of interacting quantum spins that\n",
    "correspond to an adjustable Ising model. Then, by initializing the\n",
    "input neurons in the Boltzmann machine to a fixed state and allowing\n",
    "the system to heat up, we can read out the output qubits to get the\n",
    "result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cdcadf",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Social machine learning\n",
    "\n",
    "Machine learning aims to imitate how humans\n",
    "learn. While we have developed successful machine learning algorithms,\n",
    "until now we have ignored one important fact: humans are social. Each\n",
    "of us is one part of the total society and it is difficult for us to\n",
    "live, learn, and improve ourselves, alone and isolated. Therefore, we\n",
    "should design machines with social properties. Can we let machines\n",
    "evolve by imitating human society so as to achieve more effective,\n",
    "intelligent, interpretable â€œsocial machine learningâ€?\n",
    "\n",
    "And much more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a3258",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The last words?\n",
    "\n",
    "Early computer scientist Alan Kay said, **The best way to predict the\n",
    "future is to create it**. Therefore, all machine learning\n",
    "practitioners, whether scholars or engineers, professors or students,\n",
    "need to work together to advance these important research\n",
    "topics. Together, we will not just predict the future, but create it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd77f5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Best wishes to you all and thanks so much for your heroic efforts this semester\n",
    "\n",
    "<!-- dom:FIGURE: [figures/Nebbdyr2.png, width=500 frac=0.6] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/Nebbdyr2.png\" width=\"500\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
