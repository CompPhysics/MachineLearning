<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week46.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week46-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 46: Decision Trees, Ensemble methods  and Random Forests">
<title>Week 46: Decision Trees, Ensemble methods  and Random Forests</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week46.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week46-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 46', 2, None, 'plan-for-week-46'),
              ('Reading recommendations', 2, None, 'reading-recommendations'),
              ('TensorFlow examples', 2, None, 'tensorflow-examples'),
              ('From NNs and CNNs to recurrent neural networks (RNNs)',
               2,
               None,
               'from-nns-and-cnns-to-recurrent-neural-networks-rnns'),
              ('What is a recurrent NN?', 2, None, 'what-is-a-recurrent-nn'),
              ('Why RNNs?', 2, None, 'why-rnns'),
              ('Feedback connections', 2, None, 'feedback-connections'),
              ('Vanishing gradients', 2, None, 'vanishing-gradients'),
              ('Recurrent neural networks (RNNs): Overarching view',
               2,
               None,
               'recurrent-neural-networks-rnns-overarching-view'),
              ('Sequential data only?', 2, None, 'sequential-data-only'),
              ('Differential equations', 2, None, 'differential-equations'),
              ('A simple regression example using TensorFlow with Keras',
               2,
               None,
               'a-simple-regression-example-using-tensorflow-with-keras'),
              ('Corresponding example using PyTorch',
               2,
               None,
               'corresponding-example-using-pytorch'),
              ('RNNs', 2, None, 'rnns'),
              ('What kinds of behaviour can RNNs exhibit?',
               2,
               None,
               'what-kinds-of-behaviour-can-rnns-exhibit'),
              ('Basic layout,  "Figures from Sebastian Rashcka et al, Machine '
               'learning with Sickit-Learn and '
               'PyTorch":"https://sebastianraschka.com/blog/2022/ml-pytorch-book.html"',
               2,
               None,
               'basic-layout-figures-from-sebastian-rashcka-et-al-machine-learning-with-sickit-learn-and-pytorch-https-sebastianraschka-com-blog-2022-ml-pytorch-book-html'),
              ('Solving differential equations with RNNs',
               2,
               None,
               'solving-differential-equations-with-rnns'),
              ('Two first-order differential equations',
               2,
               None,
               'two-first-order-differential-equations'),
              ('Velocity only', 2, None, 'velocity-only'),
              ('Linking with RNNs', 2, None, 'linking-with-rnns'),
              ('Minor rewrite', 2, None, 'minor-rewrite'),
              ('RNNs in more detail', 2, None, 'rnns-in-more-detail'),
              ('RNNs in more detail, part 2',
               2,
               None,
               'rnns-in-more-detail-part-2'),
              ('RNNs in more detail, part 3',
               2,
               None,
               'rnns-in-more-detail-part-3'),
              ('RNNs in more detail, part 4',
               2,
               None,
               'rnns-in-more-detail-part-4'),
              ('RNNs in more detail, part 5',
               2,
               None,
               'rnns-in-more-detail-part-5'),
              ('RNNs in more detail, part 6',
               2,
               None,
               'rnns-in-more-detail-part-6'),
              ('RNNs in more detail, part 7',
               2,
               None,
               'rnns-in-more-detail-part-7'),
              ('Backpropagation through time',
               2,
               None,
               'backpropagation-through-time'),
              ('The backward pass is linear',
               2,
               None,
               'the-backward-pass-is-linear'),
              ('The problem of exploding or vanishing gradients',
               2,
               None,
               'the-problem-of-exploding-or-vanishing-gradients'),
              ('Mathematical setup', 2, None, 'mathematical-setup'),
              ('Back propagation in time through figures, part 1',
               2,
               None,
               'back-propagation-in-time-through-figures-part-1'),
              ('Back propagation in time, part 2',
               2,
               None,
               'back-propagation-in-time-part-2'),
              ('Back propagation in time, part 3',
               2,
               None,
               'back-propagation-in-time-part-3'),
              ('Back propagation in time, part 4',
               2,
               None,
               'back-propagation-in-time-part-4'),
              ('Back propagation in time in equations',
               2,
               None,
               'back-propagation-in-time-in-equations'),
              ('Chain rule again', 2, None, 'chain-rule-again'),
              ('Gradients of loss functions',
               2,
               None,
               'gradients-of-loss-functions'),
              ('Summary of RNNs', 2, None, 'summary-of-rnns'),
              ('Summary of a  typical RNN',
               2,
               None,
               'summary-of-a-typical-rnn'),
              ('Four effective ways to learn an RNN',
               2,
               None,
               'four-effective-ways-to-learn-an-rnn'),
              ('The mathematics of RNNs, the basic architecture',
               2,
               None,
               'the-mathematics-of-rnns-the-basic-architecture'),
              ('Four effective ways to learn an RNN and preparing for next '
               'week',
               2,
               None,
               'four-effective-ways-to-learn-an-rnn-and-preparing-for-next-week'),
              ('Long Short Term Memory (LSTM)',
               2,
               None,
               'long-short-term-memory-lstm')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week46-bs.html">Week 46: Decision Trees, Ensemble methods  and Random Forests</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week46-bs001.html#plan-for-week-46" style="font-size: 80%;">Plan for week 46</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs002.html#reading-recommendations" style="font-size: 80%;">Reading recommendations</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs003.html#tensorflow-examples" style="font-size: 80%;">TensorFlow examples</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs004.html#from-nns-and-cnns-to-recurrent-neural-networks-rnns" style="font-size: 80%;">From NNs and CNNs to recurrent neural networks (RNNs)</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs005.html#what-is-a-recurrent-nn" style="font-size: 80%;">What is a recurrent NN?</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs006.html#why-rnns" style="font-size: 80%;">Why RNNs?</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs007.html#feedback-connections" style="font-size: 80%;">Feedback connections</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs008.html#vanishing-gradients" style="font-size: 80%;">Vanishing gradients</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs009.html#recurrent-neural-networks-rnns-overarching-view" style="font-size: 80%;">Recurrent neural networks (RNNs): Overarching view</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs010.html#sequential-data-only" style="font-size: 80%;">Sequential data only?</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs011.html#differential-equations" style="font-size: 80%;">Differential equations</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs012.html#a-simple-regression-example-using-tensorflow-with-keras" style="font-size: 80%;">A simple regression example using TensorFlow with Keras</a></li>
     <!-- navigation toc: --> <li><a href="#corresponding-example-using-pytorch" style="font-size: 80%;">Corresponding example using PyTorch</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs014.html#rnns" style="font-size: 80%;">RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs015.html#what-kinds-of-behaviour-can-rnns-exhibit" style="font-size: 80%;">What kinds of behaviour can RNNs exhibit?</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs016.html#basic-layout-figures-from-sebastian-rashcka-et-al-machine-learning-with-sickit-learn-and-pytorch-https-sebastianraschka-com-blog-2022-ml-pytorch-book-html" style="font-size: 80%;">Basic layout,  "Figures from Sebastian Rashcka et al, Machine learning with Sickit-Learn and PyTorch":"https://sebastianraschka.com/blog/2022/ml-pytorch-book.html"</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs017.html#solving-differential-equations-with-rnns" style="font-size: 80%;">Solving differential equations with RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs018.html#two-first-order-differential-equations" style="font-size: 80%;">Two first-order differential equations</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs019.html#velocity-only" style="font-size: 80%;">Velocity only</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs020.html#linking-with-rnns" style="font-size: 80%;">Linking with RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs021.html#minor-rewrite" style="font-size: 80%;">Minor rewrite</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs022.html#rnns-in-more-detail" style="font-size: 80%;">RNNs in more detail</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs023.html#rnns-in-more-detail-part-2" style="font-size: 80%;">RNNs in more detail, part 2</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs024.html#rnns-in-more-detail-part-3" style="font-size: 80%;">RNNs in more detail, part 3</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs025.html#rnns-in-more-detail-part-4" style="font-size: 80%;">RNNs in more detail, part 4</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs026.html#rnns-in-more-detail-part-5" style="font-size: 80%;">RNNs in more detail, part 5</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs027.html#rnns-in-more-detail-part-6" style="font-size: 80%;">RNNs in more detail, part 6</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs028.html#rnns-in-more-detail-part-7" style="font-size: 80%;">RNNs in more detail, part 7</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs029.html#backpropagation-through-time" style="font-size: 80%;">Backpropagation through time</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs030.html#the-backward-pass-is-linear" style="font-size: 80%;">The backward pass is linear</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs031.html#the-problem-of-exploding-or-vanishing-gradients" style="font-size: 80%;">The problem of exploding or vanishing gradients</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs032.html#mathematical-setup" style="font-size: 80%;">Mathematical setup</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs033.html#back-propagation-in-time-through-figures-part-1" style="font-size: 80%;">Back propagation in time through figures, part 1</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs034.html#back-propagation-in-time-part-2" style="font-size: 80%;">Back propagation in time, part 2</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs035.html#back-propagation-in-time-part-3" style="font-size: 80%;">Back propagation in time, part 3</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs036.html#back-propagation-in-time-part-4" style="font-size: 80%;">Back propagation in time, part 4</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs037.html#back-propagation-in-time-in-equations" style="font-size: 80%;">Back propagation in time in equations</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs038.html#chain-rule-again" style="font-size: 80%;">Chain rule again</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs039.html#gradients-of-loss-functions" style="font-size: 80%;">Gradients of loss functions</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs040.html#summary-of-rnns" style="font-size: 80%;">Summary of RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs041.html#summary-of-a-typical-rnn" style="font-size: 80%;">Summary of a  typical RNN</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs042.html#four-effective-ways-to-learn-an-rnn" style="font-size: 80%;">Four effective ways to learn an RNN</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs043.html#the-mathematics-of-rnns-the-basic-architecture" style="font-size: 80%;">The mathematics of RNNs, the basic architecture</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs044.html#four-effective-ways-to-learn-an-rnn-and-preparing-for-next-week" style="font-size: 80%;">Four effective ways to learn an RNN and preparing for next week</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs045.html#long-short-term-memory-lstm" style="font-size: 80%;">Long Short Term Memory (LSTM)</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0013"></a>
<!-- !split -->
<h2 id="corresponding-example-using-pytorch" class="anchor">Corresponding example using PyTorch </h2>

<p>The structure of the code here is as follows</p>
<ol>
<li> Generate a sine function  and splits it into training and validation sets</li>
<li> Create a custom data set for sequence generation</li>
<li> Define an RNN model with one RNN layer and a final plain linear layer</li>
<li> Train the model using the mean-squared error as cost function and the Adam optimizer</li>
<li> Generate predictions using recursive forecasting</li>
<li> Plot the results and training/validation loss curves</li>
</ol>
<p>The model takes sequences of 20 previous values to predict the next
value of the sine function. The recursive prediction uses the model's own
predictions to generate future values, showing how well it maintains
the sine wave pattern over time.
</p>

<p>The final plots show the the predicted values vs. the actual sine wave for the validation period
and the training and validation cost function curves to monitor for overfitting.
</p>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">torch</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">torch.nn</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">nn</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>

<span style="color: #408080; font-style: italic"># Generate synthetic sine wave data</span>
t <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>linspace(<span style="color: #666666">0</span>, <span style="color: #666666">4*</span>np<span style="color: #666666">.</span>pi, <span style="color: #666666">1000</span>)
data <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>sin(t)

<span style="color: #408080; font-style: italic"># Split data into training and validation</span>
train_data <span style="color: #666666">=</span> data[:<span style="color: #666666">800</span>]
val_data <span style="color: #666666">=</span> data[<span style="color: #666666">800</span>:]

<span style="color: #408080; font-style: italic"># Hyperparameters</span>
seq_len <span style="color: #666666">=</span> <span style="color: #666666">20</span>
batch_size <span style="color: #666666">=</span> <span style="color: #666666">32</span>
hidden_size <span style="color: #666666">=</span> <span style="color: #666666">64</span>
num_epochs <span style="color: #666666">=</span> <span style="color: #666666">100</span>
learning_rate <span style="color: #666666">=</span> <span style="color: #666666">0.001</span>

<span style="color: #408080; font-style: italic"># Create dataset and dataloaders</span>
<span style="color: #008000; font-weight: bold">class</span> <span style="color: #0000FF; font-weight: bold">SineDataset</span>(torch<span style="color: #666666">.</span>utils<span style="color: #666666">.</span>data<span style="color: #666666">.</span>Dataset):
   <span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">__init__</span>(<span style="color: #008000">self</span>, data, seq_len):
       <span style="color: #008000">self</span><span style="color: #666666">.</span>data <span style="color: #666666">=</span> data
       <span style="color: #008000">self</span><span style="color: #666666">.</span>seq_len <span style="color: #666666">=</span> seq_len

   <span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">__len__</span>(<span style="color: #008000">self</span>):
       <span style="color: #008000; font-weight: bold">return</span> <span style="color: #008000">len</span>(<span style="color: #008000">self</span><span style="color: #666666">.</span>data) <span style="color: #666666">-</span> <span style="color: #008000">self</span><span style="color: #666666">.</span>seq_len

   <span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">__getitem__</span>(<span style="color: #008000">self</span>, idx):
       x <span style="color: #666666">=</span> <span style="color: #008000">self</span><span style="color: #666666">.</span>data[idx:idx<span style="color: #666666">+</span><span style="color: #008000">self</span><span style="color: #666666">.</span>seq_len]
       y <span style="color: #666666">=</span> <span style="color: #008000">self</span><span style="color: #666666">.</span>data[idx<span style="color: #666666">+</span><span style="color: #008000">self</span><span style="color: #666666">.</span>seq_len]
       <span style="color: #008000; font-weight: bold">return</span> x<span style="color: #666666">.</span>unsqueeze(<span style="color: #666666">-1</span>), y  <span style="color: #408080; font-style: italic"># Add feature dimension</span>

train_dataset <span style="color: #666666">=</span> SineDataset(train_data, seq_len)
val_dataset <span style="color: #666666">=</span> SineDataset(val_data, seq_len)

train_loader <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>utils<span style="color: #666666">.</span>data<span style="color: #666666">.</span>DataLoader(train_dataset, batch_size<span style="color: #666666">=</span>batch_size, shuffle<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>)
val_loader <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>utils<span style="color: #666666">.</span>data<span style="color: #666666">.</span>DataLoader(val_dataset, batch_size<span style="color: #666666">=</span>batch_size, shuffle<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">False</span>)

<span style="color: #408080; font-style: italic"># Define RNN model</span>
<span style="color: #008000; font-weight: bold">class</span> <span style="color: #0000FF; font-weight: bold">RNNModel</span>(nn<span style="color: #666666">.</span>Module):
   <span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">__init__</span>(<span style="color: #008000">self</span>, input_size, hidden_size, output_size):
       <span style="color: #008000">super</span>(RNNModel, <span style="color: #008000">self</span>)<span style="color: #666666">.</span><span style="color: #0000FF">__init__</span>()
       <span style="color: #008000">self</span><span style="color: #666666">.</span>rnn <span style="color: #666666">=</span> nn<span style="color: #666666">.</span>RNN(input_size, hidden_size, batch_first<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>)
       <span style="color: #008000">self</span><span style="color: #666666">.</span>fc <span style="color: #666666">=</span> nn<span style="color: #666666">.</span>Linear(hidden_size, output_size)

   <span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">forward</span>(<span style="color: #008000">self</span>, x):
       out, _ <span style="color: #666666">=</span> <span style="color: #008000">self</span><span style="color: #666666">.</span>rnn(x)  <span style="color: #408080; font-style: italic"># out: (batch_size, seq_len, hidden_size)</span>
       out <span style="color: #666666">=</span> out[:, <span style="color: #666666">-1</span>, :]   <span style="color: #408080; font-style: italic"># Take last time step output</span>
       out <span style="color: #666666">=</span> <span style="color: #008000">self</span><span style="color: #666666">.</span>fc(out)
       <span style="color: #008000; font-weight: bold">return</span> out

model <span style="color: #666666">=</span> RNNModel(input_size<span style="color: #666666">=1</span>, hidden_size<span style="color: #666666">=</span>hidden_size, output_size<span style="color: #666666">=1</span>)
criterion <span style="color: #666666">=</span> nn<span style="color: #666666">.</span>MSELoss()
optimizer <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>optim<span style="color: #666666">.</span>Adam(model<span style="color: #666666">.</span>parameters(), lr<span style="color: #666666">=</span>learning_rate)

<span style="color: #408080; font-style: italic"># Training loop</span>
train_losses <span style="color: #666666">=</span> []
val_losses <span style="color: #666666">=</span> []

<span style="color: #008000; font-weight: bold">for</span> epoch <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(num_epochs):
   model<span style="color: #666666">.</span>train()
   epoch_train_loss <span style="color: #666666">=</span> <span style="color: #666666">0</span>
   <span style="color: #008000; font-weight: bold">for</span> x_batch, y_batch <span style="color: #AA22FF; font-weight: bold">in</span> train_loader:
       optimizer<span style="color: #666666">.</span>zero_grad()
       y_pred <span style="color: #666666">=</span> model(x_batch)
       loss <span style="color: #666666">=</span> criterion(y_pred, y_batch<span style="color: #666666">.</span>unsqueeze(<span style="color: #666666">-1</span>))
       loss<span style="color: #666666">.</span>backward()
       optimizer<span style="color: #666666">.</span>step()
       epoch_train_loss <span style="color: #666666">+=</span> loss<span style="color: #666666">.</span>item()

   <span style="color: #408080; font-style: italic"># Validation</span>
   model<span style="color: #666666">.</span>eval()
   epoch_val_loss <span style="color: #666666">=</span> <span style="color: #666666">0</span>
   <span style="color: #008000; font-weight: bold">with</span> torch<span style="color: #666666">.</span>no_grad():
       <span style="color: #008000; font-weight: bold">for</span> x_val, y_val <span style="color: #AA22FF; font-weight: bold">in</span> val_loader:
           y_pred_val <span style="color: #666666">=</span> model(x_val)
           val_loss <span style="color: #666666">=</span> criterion(y_pred_val, y_val<span style="color: #666666">.</span>unsqueeze(<span style="color: #666666">-1</span>))
           epoch_val_loss <span style="color: #666666">+=</span> val_loss<span style="color: #666666">.</span>item()

   <span style="color: #408080; font-style: italic"># Calculate average losses</span>
   train_loss <span style="color: #666666">=</span> epoch_train_loss <span style="color: #666666">/</span> <span style="color: #008000">len</span>(train_loader)
   val_loss <span style="color: #666666">=</span> epoch_val_loss <span style="color: #666666">/</span> <span style="color: #008000">len</span>(val_loader)
   train_losses<span style="color: #666666">.</span>append(train_loss)
   val_losses<span style="color: #666666">.</span>append(val_loss)

   <span style="color: #008000">print</span>(<span style="color: #BA2121">f&#39;Epoch </span><span style="color: #BB6688; font-weight: bold">{</span>epoch<span style="color: #666666">+1</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">/</span><span style="color: #BB6688; font-weight: bold">{</span>num_epochs<span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">, Train Loss: </span><span style="color: #BB6688; font-weight: bold">{</span>train_loss<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.4f</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">, Val Loss: </span><span style="color: #BB6688; font-weight: bold">{</span>val_loss<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.4f</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>)

<span style="color: #408080; font-style: italic"># Generate predictions</span>
model<span style="color: #666666">.</span>eval()
initial_sequence <span style="color: #666666">=</span> train_data[<span style="color: #666666">-</span>seq_len:]<span style="color: #666666">.</span>reshape(<span style="color: #666666">1</span>, seq_len, <span style="color: #666666">1</span>)
predictions <span style="color: #666666">=</span> []
current_sequence <span style="color: #666666">=</span> initial_sequence<span style="color: #666666">.</span>clone()

<span style="color: #008000; font-weight: bold">with</span> torch<span style="color: #666666">.</span>no_grad():
   <span style="color: #008000; font-weight: bold">for</span> _ <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #008000">len</span>(val_data)):
       pred <span style="color: #666666">=</span> model(current_sequence)
       predictions<span style="color: #666666">.</span>append(pred<span style="color: #666666">.</span>item())
       <span style="color: #408080; font-style: italic"># Update sequence by removing first element and adding new prediction</span>
       current_sequence <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>cat([current_sequence[:, <span style="color: #666666">1</span>:, :], pred<span style="color: #666666">.</span>unsqueeze(<span style="color: #666666">1</span>)], dim<span style="color: #666666">=1</span>)

<span style="color: #408080; font-style: italic"># Plot results</span>
plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">12</span>, <span style="color: #666666">6</span>))
plt<span style="color: #666666">.</span>plot(t[<span style="color: #666666">800</span>:]<span style="color: #666666">.</span>numpy(), val_data<span style="color: #666666">.</span>numpy(), label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;True values&#39;</span>)
plt<span style="color: #666666">.</span>plot(t[<span style="color: #666666">800</span>:]<span style="color: #666666">.</span>numpy(), predictions, label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Predictions&#39;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&#39;Sine Wave Prediction&#39;</span>)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;Time&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;Value&#39;</span>)
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()

<span style="color: #408080; font-style: italic"># Plot training and validation loss</span>
plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">10</span>, <span style="color: #666666">5</span>))
plt<span style="color: #666666">.</span>plot(train_losses, label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Training Loss&#39;</span>)
plt<span style="color: #666666">.</span>plot(val_losses, label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Validation Loss&#39;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&#39;Training and Validation Loss&#39;</span>)
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;Epoch&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;Loss&#39;</span>)
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week46-bs012.html">&laquo;</a></li>
  <li><a href="._week46-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week46-bs005.html">6</a></li>
  <li><a href="._week46-bs006.html">7</a></li>
  <li><a href="._week46-bs007.html">8</a></li>
  <li><a href="._week46-bs008.html">9</a></li>
  <li><a href="._week46-bs009.html">10</a></li>
  <li><a href="._week46-bs010.html">11</a></li>
  <li><a href="._week46-bs011.html">12</a></li>
  <li><a href="._week46-bs012.html">13</a></li>
  <li class="active"><a href="._week46-bs013.html">14</a></li>
  <li><a href="._week46-bs014.html">15</a></li>
  <li><a href="._week46-bs015.html">16</a></li>
  <li><a href="._week46-bs016.html">17</a></li>
  <li><a href="._week46-bs017.html">18</a></li>
  <li><a href="._week46-bs018.html">19</a></li>
  <li><a href="._week46-bs019.html">20</a></li>
  <li><a href="._week46-bs020.html">21</a></li>
  <li><a href="._week46-bs021.html">22</a></li>
  <li><a href="._week46-bs022.html">23</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week46-bs045.html">46</a></li>
  <li><a href="._week46-bs014.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

