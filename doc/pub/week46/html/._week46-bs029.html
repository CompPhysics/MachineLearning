<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week46.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week46-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 46: Decision Trees, Ensemble methods  and Random Forests">
<title>Week 46: Decision Trees, Ensemble methods  and Random Forests</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week46.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week46-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 46', 2, None, 'plan-for-week-46'),
              ('Reading recommendations', 2, None, 'reading-recommendations'),
              ('TensorFlow examples', 2, None, 'tensorflow-examples'),
              ('From NNs and CNNs to recurrent neural networks (RNNs)',
               2,
               None,
               'from-nns-and-cnns-to-recurrent-neural-networks-rnns'),
              ('What is a recurrent NN?', 2, None, 'what-is-a-recurrent-nn'),
              ('Why RNNs?', 2, None, 'why-rnns'),
              ('Feedback connections', 2, None, 'feedback-connections'),
              ('Vanishing gradients', 2, None, 'vanishing-gradients'),
              ('Recurrent neural networks (RNNs): Overarching view',
               2,
               None,
               'recurrent-neural-networks-rnns-overarching-view'),
              ('Sequential data only?', 2, None, 'sequential-data-only'),
              ('Differential equations', 2, None, 'differential-equations'),
              ('A simple regression example using TensorFlow with Keras',
               2,
               None,
               'a-simple-regression-example-using-tensorflow-with-keras'),
              ('Corresponding example using PyTorch',
               2,
               None,
               'corresponding-example-using-pytorch'),
              ('RNNs', 2, None, 'rnns'),
              ('What kinds of behaviour can RNNs exhibit?',
               2,
               None,
               'what-kinds-of-behaviour-can-rnns-exhibit'),
              ('Basic layout,  "Figures from Sebastian Rashcka et al, Machine '
               'learning with Sickit-Learn and '
               'PyTorch":"https://sebastianraschka.com/blog/2022/ml-pytorch-book.html"',
               2,
               None,
               'basic-layout-figures-from-sebastian-rashcka-et-al-machine-learning-with-sickit-learn-and-pytorch-https-sebastianraschka-com-blog-2022-ml-pytorch-book-html'),
              ('Solving differential equations with RNNs',
               2,
               None,
               'solving-differential-equations-with-rnns'),
              ('Two first-order differential equations',
               2,
               None,
               'two-first-order-differential-equations'),
              ('Velocity only', 2, None, 'velocity-only'),
              ('Linking with RNNs', 2, None, 'linking-with-rnns'),
              ('Minor rewrite', 2, None, 'minor-rewrite'),
              ('RNNs in more detail', 2, None, 'rnns-in-more-detail'),
              ('RNNs in more detail, part 2',
               2,
               None,
               'rnns-in-more-detail-part-2'),
              ('RNNs in more detail, part 3',
               2,
               None,
               'rnns-in-more-detail-part-3'),
              ('RNNs in more detail, part 4',
               2,
               None,
               'rnns-in-more-detail-part-4'),
              ('RNNs in more detail, part 5',
               2,
               None,
               'rnns-in-more-detail-part-5'),
              ('RNNs in more detail, part 6',
               2,
               None,
               'rnns-in-more-detail-part-6'),
              ('RNNs in more detail, part 7',
               2,
               None,
               'rnns-in-more-detail-part-7'),
              ('Backpropagation through time',
               2,
               None,
               'backpropagation-through-time'),
              ('The backward pass is linear',
               2,
               None,
               'the-backward-pass-is-linear'),
              ('The problem of exploding or vanishing gradients',
               2,
               None,
               'the-problem-of-exploding-or-vanishing-gradients'),
              ('Mathematical setup', 2, None, 'mathematical-setup'),
              ('Back propagation in time through figures, part 1',
               2,
               None,
               'back-propagation-in-time-through-figures-part-1'),
              ('Back propagation in time, part 2',
               2,
               None,
               'back-propagation-in-time-part-2'),
              ('Back propagation in time, part 3',
               2,
               None,
               'back-propagation-in-time-part-3'),
              ('Back propagation in time, part 4',
               2,
               None,
               'back-propagation-in-time-part-4'),
              ('Back propagation in time in equations',
               2,
               None,
               'back-propagation-in-time-in-equations'),
              ('Chain rule again', 2, None, 'chain-rule-again'),
              ('Gradients of loss functions',
               2,
               None,
               'gradients-of-loss-functions'),
              ('Summary of RNNs', 2, None, 'summary-of-rnns'),
              ('Summary of a  typical RNN',
               2,
               None,
               'summary-of-a-typical-rnn'),
              ('Four effective ways to learn an RNN',
               2,
               None,
               'four-effective-ways-to-learn-an-rnn'),
              ('The mathematics of RNNs, the basic architecture',
               2,
               None,
               'the-mathematics-of-rnns-the-basic-architecture'),
              ('Gating mechanism: Long Short Term Memory (LSTM)',
               2,
               None,
               'gating-mechanism-long-short-term-memory-lstm'),
              ('Implementing a memory cell in a neural network',
               2,
               None,
               'implementing-a-memory-cell-in-a-neural-network'),
              ('LSTM details', 2, None, 'lstm-details'),
              ('Basic layout (All figures from Raschka *et al.,*)',
               2,
               None,
               'basic-layout-all-figures-from-raschka-et-al'),
              ('LSTM details', 2, None, 'lstm-details'),
              ('Comparing with a standard  RNN',
               2,
               None,
               'comparing-with-a-standard-rnn'),
              ('LSTM details I', 2, None, 'lstm-details-i'),
              ('LSTM details II', 2, None, 'lstm-details-ii'),
              ('LSTM details III', 2, None, 'lstm-details-iii'),
              ('Forget gate', 2, None, 'forget-gate'),
              ('The forget gate', 2, None, 'the-forget-gate'),
              ('Basic layout', 2, None, 'basic-layout'),
              ('Input gate', 2, None, 'input-gate'),
              ('Short summary', 2, None, 'short-summary'),
              ('Forget and input', 2, None, 'forget-and-input'),
              ('Basic layout', 2, None, 'basic-layout'),
              ('Output gate', 2, None, 'output-gate'),
              ('Summary of LSTM', 2, None, 'summary-of-lstm'),
              ('LSTM implementation using TensorFlow',
               2,
               None,
               'lstm-implementation-using-tensorflow'),
              ('And the corresponding one with PyTorch',
               2,
               None,
               'and-the-corresponding-one-with-pytorch')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week46-bs.html">Week 46: Decision Trees, Ensemble methods  and Random Forests</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week46-bs001.html#plan-for-week-46" style="font-size: 80%;">Plan for week 46</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs002.html#reading-recommendations" style="font-size: 80%;">Reading recommendations</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs003.html#tensorflow-examples" style="font-size: 80%;">TensorFlow examples</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs004.html#from-nns-and-cnns-to-recurrent-neural-networks-rnns" style="font-size: 80%;">From NNs and CNNs to recurrent neural networks (RNNs)</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs005.html#what-is-a-recurrent-nn" style="font-size: 80%;">What is a recurrent NN?</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs006.html#why-rnns" style="font-size: 80%;">Why RNNs?</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs007.html#feedback-connections" style="font-size: 80%;">Feedback connections</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs008.html#vanishing-gradients" style="font-size: 80%;">Vanishing gradients</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs009.html#recurrent-neural-networks-rnns-overarching-view" style="font-size: 80%;">Recurrent neural networks (RNNs): Overarching view</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs010.html#sequential-data-only" style="font-size: 80%;">Sequential data only?</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs011.html#differential-equations" style="font-size: 80%;">Differential equations</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs012.html#a-simple-regression-example-using-tensorflow-with-keras" style="font-size: 80%;">A simple regression example using TensorFlow with Keras</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs013.html#corresponding-example-using-pytorch" style="font-size: 80%;">Corresponding example using PyTorch</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs014.html#rnns" style="font-size: 80%;">RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs015.html#what-kinds-of-behaviour-can-rnns-exhibit" style="font-size: 80%;">What kinds of behaviour can RNNs exhibit?</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs016.html#basic-layout-figures-from-sebastian-rashcka-et-al-machine-learning-with-sickit-learn-and-pytorch-https-sebastianraschka-com-blog-2022-ml-pytorch-book-html" style="font-size: 80%;">Basic layout,  "Figures from Sebastian Rashcka et al, Machine learning with Sickit-Learn and PyTorch":"https://sebastianraschka.com/blog/2022/ml-pytorch-book.html"</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs017.html#solving-differential-equations-with-rnns" style="font-size: 80%;">Solving differential equations with RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs018.html#two-first-order-differential-equations" style="font-size: 80%;">Two first-order differential equations</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs019.html#velocity-only" style="font-size: 80%;">Velocity only</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs020.html#linking-with-rnns" style="font-size: 80%;">Linking with RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs021.html#minor-rewrite" style="font-size: 80%;">Minor rewrite</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs022.html#rnns-in-more-detail" style="font-size: 80%;">RNNs in more detail</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs023.html#rnns-in-more-detail-part-2" style="font-size: 80%;">RNNs in more detail, part 2</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs024.html#rnns-in-more-detail-part-3" style="font-size: 80%;">RNNs in more detail, part 3</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs025.html#rnns-in-more-detail-part-4" style="font-size: 80%;">RNNs in more detail, part 4</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs026.html#rnns-in-more-detail-part-5" style="font-size: 80%;">RNNs in more detail, part 5</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs027.html#rnns-in-more-detail-part-6" style="font-size: 80%;">RNNs in more detail, part 6</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs028.html#rnns-in-more-detail-part-7" style="font-size: 80%;">RNNs in more detail, part 7</a></li>
     <!-- navigation toc: --> <li><a href="#backpropagation-through-time" style="font-size: 80%;">Backpropagation through time</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs030.html#the-backward-pass-is-linear" style="font-size: 80%;">The backward pass is linear</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs031.html#the-problem-of-exploding-or-vanishing-gradients" style="font-size: 80%;">The problem of exploding or vanishing gradients</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs032.html#mathematical-setup" style="font-size: 80%;">Mathematical setup</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs033.html#back-propagation-in-time-through-figures-part-1" style="font-size: 80%;">Back propagation in time through figures, part 1</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs034.html#back-propagation-in-time-part-2" style="font-size: 80%;">Back propagation in time, part 2</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs035.html#back-propagation-in-time-part-3" style="font-size: 80%;">Back propagation in time, part 3</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs036.html#back-propagation-in-time-part-4" style="font-size: 80%;">Back propagation in time, part 4</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs037.html#back-propagation-in-time-in-equations" style="font-size: 80%;">Back propagation in time in equations</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs038.html#chain-rule-again" style="font-size: 80%;">Chain rule again</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs039.html#gradients-of-loss-functions" style="font-size: 80%;">Gradients of loss functions</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs040.html#summary-of-rnns" style="font-size: 80%;">Summary of RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs041.html#summary-of-a-typical-rnn" style="font-size: 80%;">Summary of a  typical RNN</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs042.html#four-effective-ways-to-learn-an-rnn" style="font-size: 80%;">Four effective ways to learn an RNN</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs043.html#the-mathematics-of-rnns-the-basic-architecture" style="font-size: 80%;">The mathematics of RNNs, the basic architecture</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs044.html#gating-mechanism-long-short-term-memory-lstm" style="font-size: 80%;">Gating mechanism: Long Short Term Memory (LSTM)</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs045.html#implementing-a-memory-cell-in-a-neural-network" style="font-size: 80%;">Implementing a memory cell in a neural network</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs048.html#lstm-details" style="font-size: 80%;">LSTM details</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs047.html#basic-layout-all-figures-from-raschka-et-al" style="font-size: 80%;">Basic layout (All figures from Raschka <em>et al.,</em>)</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs048.html#lstm-details" style="font-size: 80%;">LSTM details</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs049.html#comparing-with-a-standard-rnn" style="font-size: 80%;">Comparing with a standard  RNN</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs050.html#lstm-details-i" style="font-size: 80%;">LSTM details I</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs051.html#lstm-details-ii" style="font-size: 80%;">LSTM details II</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs052.html#lstm-details-iii" style="font-size: 80%;">LSTM details III</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs053.html#forget-gate" style="font-size: 80%;">Forget gate</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs054.html#the-forget-gate" style="font-size: 80%;">The forget gate</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs059.html#basic-layout" style="font-size: 80%;">Basic layout</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs056.html#input-gate" style="font-size: 80%;">Input gate</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs057.html#short-summary" style="font-size: 80%;">Short summary</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs058.html#forget-and-input" style="font-size: 80%;">Forget and input</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs059.html#basic-layout" style="font-size: 80%;">Basic layout</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs060.html#output-gate" style="font-size: 80%;">Output gate</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs061.html#summary-of-lstm" style="font-size: 80%;">Summary of LSTM</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs062.html#lstm-implementation-using-tensorflow" style="font-size: 80%;">LSTM implementation using TensorFlow</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs063.html#and-the-corresponding-one-with-pytorch" style="font-size: 80%;">And the corresponding one with PyTorch</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0029"></a>
<!-- !split -->
<h2 id="backpropagation-through-time" class="anchor">Backpropagation through time </h2>

<div class="panel panel-default">
<div class="panel-body">
<!-- subsequent paragraphs come in larger fonts, so start with a paragraph -->
<p>We can think of the recurrent net as a layered, feed-forward
net with shared weights and then train the feed-forward net
with weight constraints.
</p>
</div>
</div>


<p>We can also think of this training algorithm in the time domain:</p>
<ol>
<li> The forward pass builds up a stack of the activities of all the units at each time step.</li>
<li> The backward pass peels activities off the stack to compute the error derivatives at each time step.</li>
<li> After the backward pass we add together the derivatives at all the different times for each weight.</li> 
</ol>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week46-bs028.html">&laquo;</a></li>
  <li><a href="._week46-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week46-bs021.html">22</a></li>
  <li><a href="._week46-bs022.html">23</a></li>
  <li><a href="._week46-bs023.html">24</a></li>
  <li><a href="._week46-bs024.html">25</a></li>
  <li><a href="._week46-bs025.html">26</a></li>
  <li><a href="._week46-bs026.html">27</a></li>
  <li><a href="._week46-bs027.html">28</a></li>
  <li><a href="._week46-bs028.html">29</a></li>
  <li class="active"><a href="._week46-bs029.html">30</a></li>
  <li><a href="._week46-bs030.html">31</a></li>
  <li><a href="._week46-bs031.html">32</a></li>
  <li><a href="._week46-bs032.html">33</a></li>
  <li><a href="._week46-bs033.html">34</a></li>
  <li><a href="._week46-bs034.html">35</a></li>
  <li><a href="._week46-bs035.html">36</a></li>
  <li><a href="._week46-bs036.html">37</a></li>
  <li><a href="._week46-bs037.html">38</a></li>
  <li><a href="._week46-bs038.html">39</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week46-bs063.html">64</a></li>
  <li><a href="._week46-bs030.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

