<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week38.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week38-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week38: Logistic Regression and Optimization">
<title>Week38: Logistic Regression and Optimization</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week38.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week38-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plans for week 38', 2, None, 'plans-for-week-38'),
              ('Material from last week and relevant for the first project',
               2,
               None,
               'material-from-last-week-and-relevant-for-the-first-project'),
              ('Various steps in cross-validation',
               2,
               None,
               'various-steps-in-cross-validation'),
              ('How to set up the cross-validation for Ridge and/or Lasso',
               2,
               None,
               'how-to-set-up-the-cross-validation-for-ridge-and-or-lasso'),
              ('Cross-validation in brief',
               2,
               None,
               'cross-validation-in-brief'),
              ('Code Example for Cross-validation and $k$-fold '
               'Cross-validation',
               2,
               None,
               'code-example-for-cross-validation-and-k-fold-cross-validation'),
              ('Material for lecture Thursday September 21',
               2,
               None,
               'material-for-lecture-thursday-september-21'),
              ('Logistic Regression', 2, None, 'logistic-regression'),
              ('Classification problems', 2, None, 'classification-problems'),
              ('Optimization and Deep learning',
               2,
               None,
               'optimization-and-deep-learning'),
              ('Basics', 2, None, 'basics'),
              ('Linear classifier', 2, None, 'linear-classifier'),
              ('Some selected properties', 2, None, 'some-selected-properties'),
              ('Simple example', 2, None, 'simple-example'),
              ('Plotting the mean value for each group',
               2,
               None,
               'plotting-the-mean-value-for-each-group'),
              ('The logistic function', 2, None, 'the-logistic-function'),
              ('Examples of likelihood functions used in logistic regression '
               'and nueral networks',
               2,
               None,
               'examples-of-likelihood-functions-used-in-logistic-regression-and-nueral-networks'),
              ('Two parameters', 2, None, 'two-parameters'),
              ('Maximum likelihood', 2, None, 'maximum-likelihood'),
              ('The cost function rewritten',
               2,
               None,
               'the-cost-function-rewritten'),
              ('Minimizing the cross entropy',
               2,
               None,
               'minimizing-the-cross-entropy'),
              ('A more compact expression',
               2,
               None,
               'a-more-compact-expression'),
              ('Extending to more predictors',
               2,
               None,
               'extending-to-more-predictors'),
              ('Including more classes', 2, None, 'including-more-classes'),
              ('More classes', 2, None, 'more-classes'),
              ('Friday September 23', 2, None, 'friday-september-23'),
              ('Searching for Optimal Regularization Parameters $\\lambda$',
               2,
               None,
               'searching-for-optimal-regularization-parameters-lambda'),
              ('Grid Search', 2, None, 'grid-search'),
              ('Randomized Grid Search', 2, None, 'randomized-grid-search'),
              ('Wisconsin Cancer Data', 2, None, 'wisconsin-cancer-data'),
              ('Using the correlation matrix',
               2,
               None,
               'using-the-correlation-matrix'),
              ('Discussing the correlation data',
               2,
               None,
               'discussing-the-correlation-data'),
              ('Other measures in classification studies: Cancer Data  again',
               2,
               None,
               'other-measures-in-classification-studies-cancer-data-again'),
              ('Optimization, the central part of any Machine Learning '
               'algortithm',
               2,
               None,
               'optimization-the-central-part-of-any-machine-learning-algortithm'),
              ('Revisiting our Logistic Regression case',
               2,
               None,
               'revisiting-our-logistic-regression-case'),
              ('The equations to solve', 2, None, 'the-equations-to-solve'),
              ("Solving using Newton-Raphson's method",
               2,
               None,
               'solving-using-newton-raphson-s-method'),
              ("Brief reminder on Newton-Raphson's method",
               2,
               None,
               'brief-reminder-on-newton-raphson-s-method'),
              ('The equations', 2, None, 'the-equations'),
              ('Simple geometric interpretation',
               2,
               None,
               'simple-geometric-interpretation'),
              ('Extending to more than one variable',
               2,
               None,
               'extending-to-more-than-one-variable'),
              ('Steepest descent', 2, None, 'steepest-descent'),
              ('More on Steepest descent', 2, None, 'more-on-steepest-descent'),
              ('The ideal', 2, None, 'the-ideal'),
              ('The sensitiveness of the gradient descent',
               2,
               None,
               'the-sensitiveness-of-the-gradient-descent'),
              ('Convex functions', 2, None, 'convex-functions'),
              ('Convex function', 2, None, 'convex-function'),
              ('Conditions on convex functions',
               2,
               None,
               'conditions-on-convex-functions'),
              ('More on convex functions', 2, None, 'more-on-convex-functions'),
              ('Some simple problems', 2, None, 'some-simple-problems'),
              ('Revisiting our first homework',
               2,
               None,
               'revisiting-our-first-homework'),
              ('Gradient descent example', 2, None, 'gradient-descent-example'),
              ('The derivative of the cost/loss function',
               2,
               None,
               'the-derivative-of-the-cost-loss-function'),
              ('The Hessian matrix', 2, None, 'the-hessian-matrix'),
              ('Simple program', 2, None, 'simple-program'),
              ('Gradient Descent Example', 2, None, 'gradient-descent-example'),
              ('And a corresponding example using _scikit-learn_',
               2,
               None,
               'and-a-corresponding-example-using-scikit-learn'),
              ('Gradient descent and Ridge',
               2,
               None,
               'gradient-descent-and-ridge'),
              ('The Hessian matrix for Ridge Regression',
               2,
               None,
               'the-hessian-matrix-for-ridge-regression'),
              ('Program example for gradient descent with Ridge Regression',
               2,
               None,
               'program-example-for-gradient-descent-with-ridge-regression'),
              ('Using gradient descent methods, limitations',
               2,
               None,
               'using-gradient-descent-methods-limitations'),
              ('Challenge yourself the coming weekend',
               2,
               None,
               'challenge-yourself-the-coming-weekend')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week38-bs.html">Week38: Logistic Regression and Optimization</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week38-bs001.html#plans-for-week-38" style="font-size: 80%;">Plans for week 38</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs002.html#material-from-last-week-and-relevant-for-the-first-project" style="font-size: 80%;">Material from last week and relevant for the first project</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs003.html#various-steps-in-cross-validation" style="font-size: 80%;">Various steps in cross-validation</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs004.html#how-to-set-up-the-cross-validation-for-ridge-and-or-lasso" style="font-size: 80%;">How to set up the cross-validation for Ridge and/or Lasso</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs005.html#cross-validation-in-brief" style="font-size: 80%;">Cross-validation in brief</a></li>
     <!-- navigation toc: --> <li><a href="#code-example-for-cross-validation-and-k-fold-cross-validation" style="font-size: 80%;">Code Example for Cross-validation and \( k \)-fold Cross-validation</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs007.html#material-for-lecture-thursday-september-21" style="font-size: 80%;">Material for lecture Thursday September 21</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs008.html#logistic-regression" style="font-size: 80%;">Logistic Regression</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs009.html#classification-problems" style="font-size: 80%;">Classification problems</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs010.html#optimization-and-deep-learning" style="font-size: 80%;">Optimization and Deep learning</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs011.html#basics" style="font-size: 80%;">Basics</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs012.html#linear-classifier" style="font-size: 80%;">Linear classifier</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs013.html#some-selected-properties" style="font-size: 80%;">Some selected properties</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs014.html#simple-example" style="font-size: 80%;">Simple example</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs015.html#plotting-the-mean-value-for-each-group" style="font-size: 80%;">Plotting the mean value for each group</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs016.html#the-logistic-function" style="font-size: 80%;">The logistic function</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs017.html#examples-of-likelihood-functions-used-in-logistic-regression-and-nueral-networks" style="font-size: 80%;">Examples of likelihood functions used in logistic regression and nueral networks</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs018.html#two-parameters" style="font-size: 80%;">Two parameters</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs019.html#maximum-likelihood" style="font-size: 80%;">Maximum likelihood</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs020.html#the-cost-function-rewritten" style="font-size: 80%;">The cost function rewritten</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs021.html#minimizing-the-cross-entropy" style="font-size: 80%;">Minimizing the cross entropy</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs022.html#a-more-compact-expression" style="font-size: 80%;">A more compact expression</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs023.html#extending-to-more-predictors" style="font-size: 80%;">Extending to more predictors</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs024.html#including-more-classes" style="font-size: 80%;">Including more classes</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs025.html#more-classes" style="font-size: 80%;">More classes</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs026.html#friday-september-23" style="font-size: 80%;">Friday September 23</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs027.html#searching-for-optimal-regularization-parameters-lambda" style="font-size: 80%;">Searching for Optimal Regularization Parameters \( \lambda \)</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs028.html#grid-search" style="font-size: 80%;">Grid Search</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs029.html#randomized-grid-search" style="font-size: 80%;">Randomized Grid Search</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs030.html#wisconsin-cancer-data" style="font-size: 80%;">Wisconsin Cancer Data</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs031.html#using-the-correlation-matrix" style="font-size: 80%;">Using the correlation matrix</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs032.html#discussing-the-correlation-data" style="font-size: 80%;">Discussing the correlation data</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs033.html#other-measures-in-classification-studies-cancer-data-again" style="font-size: 80%;">Other measures in classification studies: Cancer Data  again</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs034.html#optimization-the-central-part-of-any-machine-learning-algortithm" style="font-size: 80%;">Optimization, the central part of any Machine Learning algortithm</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs035.html#revisiting-our-logistic-regression-case" style="font-size: 80%;">Revisiting our Logistic Regression case</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs036.html#the-equations-to-solve" style="font-size: 80%;">The equations to solve</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs037.html#solving-using-newton-raphson-s-method" style="font-size: 80%;">Solving using Newton-Raphson's method</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs038.html#brief-reminder-on-newton-raphson-s-method" style="font-size: 80%;">Brief reminder on Newton-Raphson's method</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs039.html#the-equations" style="font-size: 80%;">The equations</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs040.html#simple-geometric-interpretation" style="font-size: 80%;">Simple geometric interpretation</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs041.html#extending-to-more-than-one-variable" style="font-size: 80%;">Extending to more than one variable</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs042.html#steepest-descent" style="font-size: 80%;">Steepest descent</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs043.html#more-on-steepest-descent" style="font-size: 80%;">More on Steepest descent</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs044.html#the-ideal" style="font-size: 80%;">The ideal</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs045.html#the-sensitiveness-of-the-gradient-descent" style="font-size: 80%;">The sensitiveness of the gradient descent</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs046.html#convex-functions" style="font-size: 80%;">Convex functions</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs047.html#convex-function" style="font-size: 80%;">Convex function</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs048.html#conditions-on-convex-functions" style="font-size: 80%;">Conditions on convex functions</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs049.html#more-on-convex-functions" style="font-size: 80%;">More on convex functions</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs050.html#some-simple-problems" style="font-size: 80%;">Some simple problems</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs051.html#revisiting-our-first-homework" style="font-size: 80%;">Revisiting our first homework</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs056.html#gradient-descent-example" style="font-size: 80%;">Gradient descent example</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs053.html#the-derivative-of-the-cost-loss-function" style="font-size: 80%;">The derivative of the cost/loss function</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs054.html#the-hessian-matrix" style="font-size: 80%;">The Hessian matrix</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs055.html#simple-program" style="font-size: 80%;">Simple program</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs056.html#gradient-descent-example" style="font-size: 80%;">Gradient Descent Example</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs057.html#and-a-corresponding-example-using-scikit-learn" style="font-size: 80%;">And a corresponding example using <b>scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs058.html#gradient-descent-and-ridge" style="font-size: 80%;">Gradient descent and Ridge</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs059.html#the-hessian-matrix-for-ridge-regression" style="font-size: 80%;">The Hessian matrix for Ridge Regression</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs060.html#program-example-for-gradient-descent-with-ridge-regression" style="font-size: 80%;">Program example for gradient descent with Ridge Regression</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs061.html#using-gradient-descent-methods-limitations" style="font-size: 80%;">Using gradient descent methods, limitations</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs062.html#challenge-yourself-the-coming-weekend" style="font-size: 80%;">Challenge yourself the coming weekend</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0006"></a>
<!-- !split -->
<h2 id="code-example-for-cross-validation-and-k-fold-cross-validation" class="anchor">Code Example for Cross-validation and \( k \)-fold Cross-validation </h2>

<p>The code here uses Ridge regression with cross-validation (CV)  resampling and \( k \)-fold CV in order to fit a specific polynomial. </p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.model_selection</span> <span style="color: #008000; font-weight: bold">import</span> KFold
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.linear_model</span> <span style="color: #008000; font-weight: bold">import</span> Ridge
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.model_selection</span> <span style="color: #008000; font-weight: bold">import</span> cross_val_score
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.preprocessing</span> <span style="color: #008000; font-weight: bold">import</span> PolynomialFeatures

<span style="color: #408080; font-style: italic"># A seed just to ensure that the random numbers are the same for every run.</span>
<span style="color: #408080; font-style: italic"># Useful for eventual debugging.</span>
np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>seed(<span style="color: #666666">3155</span>)

<span style="color: #408080; font-style: italic"># Generate the data.</span>
nsamples <span style="color: #666666">=</span> <span style="color: #666666">100</span>
x <span style="color: #666666">=</span> np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>randn(nsamples)
y <span style="color: #666666">=</span> <span style="color: #666666">3*</span>x<span style="color: #666666">**2</span> <span style="color: #666666">+</span> np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>randn(nsamples)

<span style="color: #408080; font-style: italic">## Cross-validation on Ridge regression using KFold only</span>

<span style="color: #408080; font-style: italic"># Decide degree on polynomial to fit</span>
poly <span style="color: #666666">=</span> PolynomialFeatures(degree <span style="color: #666666">=</span> <span style="color: #666666">6</span>)

<span style="color: #408080; font-style: italic"># Decide which values of lambda to use</span>
nlambdas <span style="color: #666666">=</span> <span style="color: #666666">500</span>
lambdas <span style="color: #666666">=</span> np<span style="color: #666666">.</span>logspace(<span style="color: #666666">-3</span>, <span style="color: #666666">5</span>, nlambdas)

<span style="color: #408080; font-style: italic"># Initialize a KFold instance</span>
k <span style="color: #666666">=</span> <span style="color: #666666">5</span>
kfold <span style="color: #666666">=</span> KFold(n_splits <span style="color: #666666">=</span> k)

<span style="color: #408080; font-style: italic"># Perform the cross-validation to estimate MSE</span>
scores_KFold <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((nlambdas, k))

i <span style="color: #666666">=</span> <span style="color: #666666">0</span>
<span style="color: #008000; font-weight: bold">for</span> lmb <span style="color: #AA22FF; font-weight: bold">in</span> lambdas:
    ridge <span style="color: #666666">=</span> Ridge(alpha <span style="color: #666666">=</span> lmb)
    j <span style="color: #666666">=</span> <span style="color: #666666">0</span>
    <span style="color: #008000; font-weight: bold">for</span> train_inds, test_inds <span style="color: #AA22FF; font-weight: bold">in</span> kfold<span style="color: #666666">.</span>split(x):
        xtrain <span style="color: #666666">=</span> x[train_inds]
        ytrain <span style="color: #666666">=</span> y[train_inds]

        xtest <span style="color: #666666">=</span> x[test_inds]
        ytest <span style="color: #666666">=</span> y[test_inds]

        Xtrain <span style="color: #666666">=</span> poly<span style="color: #666666">.</span>fit_transform(xtrain[:, np<span style="color: #666666">.</span>newaxis])
        ridge<span style="color: #666666">.</span>fit(Xtrain, ytrain[:, np<span style="color: #666666">.</span>newaxis])

        Xtest <span style="color: #666666">=</span> poly<span style="color: #666666">.</span>fit_transform(xtest[:, np<span style="color: #666666">.</span>newaxis])
        ypred <span style="color: #666666">=</span> ridge<span style="color: #666666">.</span>predict(Xtest)

        scores_KFold[i,j] <span style="color: #666666">=</span> np<span style="color: #666666">.</span>sum((ypred <span style="color: #666666">-</span> ytest[:, np<span style="color: #666666">.</span>newaxis])<span style="color: #666666">**2</span>)<span style="color: #666666">/</span>np<span style="color: #666666">.</span>size(ypred)

        j <span style="color: #666666">+=</span> <span style="color: #666666">1</span>
    i <span style="color: #666666">+=</span> <span style="color: #666666">1</span>


estimated_mse_KFold <span style="color: #666666">=</span> np<span style="color: #666666">.</span>mean(scores_KFold, axis <span style="color: #666666">=</span> <span style="color: #666666">1</span>)

<span style="color: #408080; font-style: italic">## Cross-validation using cross_val_score from sklearn along with KFold</span>

<span style="color: #408080; font-style: italic"># kfold is an instance initialized above as:</span>
<span style="color: #408080; font-style: italic"># kfold = KFold(n_splits = k)</span>

estimated_mse_sklearn <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros(nlambdas)
i <span style="color: #666666">=</span> <span style="color: #666666">0</span>
<span style="color: #008000; font-weight: bold">for</span> lmb <span style="color: #AA22FF; font-weight: bold">in</span> lambdas:
    ridge <span style="color: #666666">=</span> Ridge(alpha <span style="color: #666666">=</span> lmb)

    X <span style="color: #666666">=</span> poly<span style="color: #666666">.</span>fit_transform(x[:, np<span style="color: #666666">.</span>newaxis])
    estimated_mse_folds <span style="color: #666666">=</span> cross_val_score(ridge, X, y[:, np<span style="color: #666666">.</span>newaxis], scoring<span style="color: #666666">=</span><span style="color: #BA2121">&#39;neg_mean_squared_error&#39;</span>, cv<span style="color: #666666">=</span>kfold)

    <span style="color: #408080; font-style: italic"># cross_val_score return an array containing the estimated negative mse for every fold.</span>
    <span style="color: #408080; font-style: italic"># we have to the the mean of every array in order to get an estimate of the mse of the model</span>
    estimated_mse_sklearn[i] <span style="color: #666666">=</span> np<span style="color: #666666">.</span>mean(<span style="color: #666666">-</span>estimated_mse_folds)

    i <span style="color: #666666">+=</span> <span style="color: #666666">1</span>

<span style="color: #408080; font-style: italic">## Plot and compare the slightly different ways to perform cross-validation</span>

plt<span style="color: #666666">.</span>figure()

plt<span style="color: #666666">.</span>plot(np<span style="color: #666666">.</span>log10(lambdas), estimated_mse_sklearn, label <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;cross_val_score&#39;</span>)
plt<span style="color: #666666">.</span>plot(np<span style="color: #666666">.</span>log10(lambdas), estimated_mse_KFold, <span style="color: #BA2121">&#39;r--&#39;</span>, label <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;KFold&#39;</span>)

plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;log10(lambda)&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;mse&#39;</span>)

plt<span style="color: #666666">.</span>legend()

plt<span style="color: #666666">.</span>show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week38-bs005.html">&laquo;</a></li>
  <li><a href="._week38-bs000.html">1</a></li>
  <li><a href="._week38-bs001.html">2</a></li>
  <li><a href="._week38-bs002.html">3</a></li>
  <li><a href="._week38-bs003.html">4</a></li>
  <li><a href="._week38-bs004.html">5</a></li>
  <li><a href="._week38-bs005.html">6</a></li>
  <li class="active"><a href="._week38-bs006.html">7</a></li>
  <li><a href="._week38-bs007.html">8</a></li>
  <li><a href="._week38-bs008.html">9</a></li>
  <li><a href="._week38-bs009.html">10</a></li>
  <li><a href="._week38-bs010.html">11</a></li>
  <li><a href="._week38-bs011.html">12</a></li>
  <li><a href="._week38-bs012.html">13</a></li>
  <li><a href="._week38-bs013.html">14</a></li>
  <li><a href="._week38-bs014.html">15</a></li>
  <li><a href="._week38-bs015.html">16</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week38-bs062.html">63</a></li>
  <li><a href="._week38-bs007.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

