<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week40.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week40-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 40: Gradient descent methods (continued) and start Neural networks">
<title>Week 40: Gradient descent methods (continued) and start Neural networks</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week40.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week40-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Lecture Monday September 30, 2024',
               2,
               None,
               'lecture-monday-september-30-2024'),
              ('Suggested readings and videos',
               2,
               None,
               'suggested-readings-and-videos'),
              ('Lab sessions Tuesday and Wednesday',
               2,
               None,
               'lab-sessions-tuesday-and-wednesday'),
              ('Automatic differentiation',
               2,
               None,
               'automatic-differentiation'),
              ('Using autograd', 2, None, 'using-autograd'),
              ('Autograd with more complicated functions',
               2,
               None,
               'autograd-with-more-complicated-functions'),
              ('More complicated functions using the elements of their '
               'arguments directly',
               2,
               None,
               'more-complicated-functions-using-the-elements-of-their-arguments-directly'),
              ('Functions using mathematical functions from Numpy',
               2,
               None,
               'functions-using-mathematical-functions-from-numpy'),
              ('More autograd', 2, None, 'more-autograd'),
              ('And  with loops', 2, None, 'and-with-loops'),
              ('Using recursion', 2, None, 'using-recursion'),
              ('Using Autograd with OLS', 2, None, 'using-autograd-with-ols'),
              ('Same code but now with momentum gradient descent',
               2,
               None,
               'same-code-but-now-with-momentum-gradient-descent'),
              ('Including Stochastic Gradient Descent with Autograd',
               2,
               None,
               'including-stochastic-gradient-descent-with-autograd'),
              ('Same code but now with momentum gradient descent',
               2,
               None,
               'same-code-but-now-with-momentum-gradient-descent'),
              ('Similar (second order function now) problem but now with '
               'AdaGrad',
               2,
               None,
               'similar-second-order-function-now-problem-but-now-with-adagrad'),
              ('RMSprop for adaptive learning rate with Stochastic Gradient '
               'Descent',
               2,
               None,
               'rmsprop-for-adaptive-learning-rate-with-stochastic-gradient-descent'),
              ('And finally "ADAM":"https://arxiv.org/pdf/1412.6980.pdf"',
               2,
               None,
               'and-finally-adam-https-arxiv-org-pdf-1412-6980-pdf'),
              ('And Logistic Regression', 2, None, 'and-logistic-regression'),
              ('Introducing "JAX":"https://jax.readthedocs.io/en/latest/"',
               2,
               None,
               'introducing-jax-https-jax-readthedocs-io-en-latest'),
              ('Getting started with Jax, note the way we import numpy',
               3,
               None,
               'getting-started-with-jax-note-the-way-we-import-numpy'),
              ('A warm-up example', 3, None, 'a-warm-up-example'),
              ('A more advanced example', 3, None, 'a-more-advanced-example'),
              ('Introduction to Neural networks',
               2,
               None,
               'introduction-to-neural-networks'),
              ('Artificial neurons', 2, None, 'artificial-neurons'),
              ('Neural network types', 2, None, 'neural-network-types'),
              ('Feed-forward neural networks',
               2,
               None,
               'feed-forward-neural-networks'),
              ('Convolutional Neural Network',
               2,
               None,
               'convolutional-neural-network'),
              ('Recurrent neural networks',
               2,
               None,
               'recurrent-neural-networks'),
              ('Other types of networks', 2, None, 'other-types-of-networks'),
              ('Multilayer perceptrons', 2, None, 'multilayer-perceptrons'),
              ('Why multilayer perceptrons?',
               2,
               None,
               'why-multilayer-perceptrons'),
              ('Illustration of a single perceptron model and a '
               'multi-perceptron model',
               2,
               None,
               'illustration-of-a-single-perceptron-model-and-a-multi-perceptron-model'),
              ('Examples of XOR, OR and AND gates',
               2,
               None,
               'examples-of-xor-or-and-and-gates'),
              ('Does Logistic Regression do a better Job?',
               2,
               None,
               'does-logistic-regression-do-a-better-job'),
              ('Adding Neural Networks', 2, None, 'adding-neural-networks'),
              ('Mathematical model', 2, None, 'mathematical-model'),
              ('Mathematical model', 2, None, 'mathematical-model'),
              ('Mathematical model', 2, None, 'mathematical-model'),
              ('Mathematical model', 2, None, 'mathematical-model'),
              ('Mathematical model', 2, None, 'mathematical-model'),
              ('Matrix-vector notation', 3, None, 'matrix-vector-notation'),
              ('Matrix-vector notation  and activation',
               3,
               None,
               'matrix-vector-notation-and-activation'),
              ('Activation functions', 3, None, 'activation-functions'),
              ('Activation functions, Logistic and Hyperbolic ones',
               3,
               None,
               'activation-functions-logistic-and-hyperbolic-ones'),
              ('Relevance', 3, None, 'relevance')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week40-bs.html">Week 40: Gradient descent methods (continued) and start Neural networks</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week40-bs001.html#lecture-monday-september-30-2024" style="font-size: 80%;"><b>Lecture Monday September 30, 2024</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs002.html#suggested-readings-and-videos" style="font-size: 80%;"><b>Suggested readings and videos</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs003.html#lab-sessions-tuesday-and-wednesday" style="font-size: 80%;"><b>Lab sessions Tuesday and Wednesday</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs004.html#automatic-differentiation" style="font-size: 80%;"><b>Automatic differentiation</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs005.html#using-autograd" style="font-size: 80%;"><b>Using autograd</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs006.html#autograd-with-more-complicated-functions" style="font-size: 80%;"><b>Autograd with more complicated functions</b></a></li>
     <!-- navigation toc: --> <li><a href="#more-complicated-functions-using-the-elements-of-their-arguments-directly" style="font-size: 80%;"><b>More complicated functions using the elements of their arguments directly</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs008.html#functions-using-mathematical-functions-from-numpy" style="font-size: 80%;"><b>Functions using mathematical functions from Numpy</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs009.html#more-autograd" style="font-size: 80%;"><b>More autograd</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs010.html#and-with-loops" style="font-size: 80%;"><b>And  with loops</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs011.html#using-recursion" style="font-size: 80%;"><b>Using recursion</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs012.html#using-autograd-with-ols" style="font-size: 80%;"><b>Using Autograd with OLS</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs015.html#same-code-but-now-with-momentum-gradient-descent" style="font-size: 80%;"><b>Same code but now with momentum gradient descent</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs014.html#including-stochastic-gradient-descent-with-autograd" style="font-size: 80%;"><b>Including Stochastic Gradient Descent with Autograd</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs015.html#same-code-but-now-with-momentum-gradient-descent" style="font-size: 80%;"><b>Same code but now with momentum gradient descent</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs016.html#similar-second-order-function-now-problem-but-now-with-adagrad" style="font-size: 80%;"><b>Similar (second order function now) problem but now with AdaGrad</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs017.html#rmsprop-for-adaptive-learning-rate-with-stochastic-gradient-descent" style="font-size: 80%;"><b>RMSprop for adaptive learning rate with Stochastic Gradient Descent</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs018.html#and-finally-adam-https-arxiv-org-pdf-1412-6980-pdf" style="font-size: 80%;"><b>And finally "ADAM":"https://arxiv.org/pdf/1412.6980.pdf"</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs019.html#and-logistic-regression" style="font-size: 80%;"><b>And Logistic Regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs019.html#introducing-jax-https-jax-readthedocs-io-en-latest" style="font-size: 80%;"><b>Introducing "JAX":"https://jax.readthedocs.io/en/latest/"</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs019.html#getting-started-with-jax-note-the-way-we-import-numpy" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Getting started with Jax, note the way we import numpy</a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs019.html#a-warm-up-example" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;A warm-up example</a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs019.html#a-more-advanced-example" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;A more advanced example</a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs020.html#introduction-to-neural-networks" style="font-size: 80%;"><b>Introduction to Neural networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs021.html#artificial-neurons" style="font-size: 80%;"><b>Artificial neurons</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs022.html#neural-network-types" style="font-size: 80%;"><b>Neural network types</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs023.html#feed-forward-neural-networks" style="font-size: 80%;"><b>Feed-forward neural networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs024.html#convolutional-neural-network" style="font-size: 80%;"><b>Convolutional Neural Network</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs025.html#recurrent-neural-networks" style="font-size: 80%;"><b>Recurrent neural networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs026.html#other-types-of-networks" style="font-size: 80%;"><b>Other types of networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs027.html#multilayer-perceptrons" style="font-size: 80%;"><b>Multilayer perceptrons</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs028.html#why-multilayer-perceptrons" style="font-size: 80%;"><b>Why multilayer perceptrons?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs029.html#illustration-of-a-single-perceptron-model-and-a-multi-perceptron-model" style="font-size: 80%;"><b>Illustration of a single perceptron model and a multi-perceptron model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs030.html#examples-of-xor-or-and-and-gates" style="font-size: 80%;"><b>Examples of XOR, OR and AND gates</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs031.html#does-logistic-regression-do-a-better-job" style="font-size: 80%;"><b>Does Logistic Regression do a better Job?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs032.html#adding-neural-networks" style="font-size: 80%;"><b>Adding Neural Networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs037.html#mathematical-model" style="font-size: 80%;"><b>Mathematical model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs037.html#mathematical-model" style="font-size: 80%;"><b>Mathematical model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs037.html#mathematical-model" style="font-size: 80%;"><b>Mathematical model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs037.html#mathematical-model" style="font-size: 80%;"><b>Mathematical model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs037.html#mathematical-model" style="font-size: 80%;"><b>Mathematical model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs038.html#matrix-vector-notation" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Matrix-vector notation</a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs039.html#matrix-vector-notation-and-activation" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Matrix-vector notation  and activation</a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs040.html#activation-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Activation functions</a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs041.html#activation-functions-logistic-and-hyperbolic-ones" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Activation functions, Logistic and Hyperbolic ones</a></li>
     <!-- navigation toc: --> <li><a href="._week40-bs042.html#relevance" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Relevance</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0007"></a>
<!-- !split -->
<h2 id="more-complicated-functions-using-the-elements-of-their-arguments-directly" class="anchor">More complicated functions using the elements of their arguments directly </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">autograd.numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">autograd</span> <span style="color: #008000; font-weight: bold">import</span> grad
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">f3</span>(x): <span style="color: #408080; font-style: italic"># Assumes x is an array of length 5 or higher</span>
    <span style="color: #008000; font-weight: bold">return</span> <span style="color: #666666">2*</span>x[<span style="color: #666666">0</span>] <span style="color: #666666">+</span> <span style="color: #666666">3*</span>x[<span style="color: #666666">1</span>] <span style="color: #666666">+</span> <span style="color: #666666">5*</span>x[<span style="color: #666666">2</span>] <span style="color: #666666">+</span> <span style="color: #666666">7*</span>x[<span style="color: #666666">3</span>] <span style="color: #666666">+</span> <span style="color: #666666">11*</span>x[<span style="color: #666666">4</span>]<span style="color: #666666">**2</span>

f3_grad <span style="color: #666666">=</span> grad(f3)

x <span style="color: #666666">=</span> np<span style="color: #666666">.</span>linspace(<span style="color: #666666">0</span>,<span style="color: #666666">4</span>,<span style="color: #666666">5</span>)

<span style="color: #408080; font-style: italic"># Print the computed gradient:</span>
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;The computed gradient of f3 is: &quot;</span>, f3_grad(x))

<span style="color: #408080; font-style: italic"># The analytical gradient is: (2, 3, 5, 7, 22*x[4])</span>
f3_grad_analytical <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array([<span style="color: #666666">2</span>, <span style="color: #666666">3</span>, <span style="color: #666666">5</span>, <span style="color: #666666">7</span>, <span style="color: #666666">22*</span>x[<span style="color: #666666">4</span>]])

<span style="color: #408080; font-style: italic"># Print the analytical gradient:</span>
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;The analytical gradient of f3 is: &quot;</span>, f3_grad_analytical)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>Note that in this case, when sending an array as input argument, the
output from Autograd is another array. This is the true gradient of
the function, as opposed to the function in the previous example. By
using arrays to represent the variables, the output from Autograd
might be easier to work with, as the output is closer to what one
could expect form a gradient-evaluting function.
</p>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week40-bs006.html">&laquo;</a></li>
  <li><a href="._week40-bs000.html">1</a></li>
  <li><a href="._week40-bs001.html">2</a></li>
  <li><a href="._week40-bs002.html">3</a></li>
  <li><a href="._week40-bs003.html">4</a></li>
  <li><a href="._week40-bs004.html">5</a></li>
  <li><a href="._week40-bs005.html">6</a></li>
  <li><a href="._week40-bs006.html">7</a></li>
  <li class="active"><a href="._week40-bs007.html">8</a></li>
  <li><a href="._week40-bs008.html">9</a></li>
  <li><a href="._week40-bs009.html">10</a></li>
  <li><a href="._week40-bs010.html">11</a></li>
  <li><a href="._week40-bs011.html">12</a></li>
  <li><a href="._week40-bs012.html">13</a></li>
  <li><a href="._week40-bs013.html">14</a></li>
  <li><a href="._week40-bs014.html">15</a></li>
  <li><a href="._week40-bs015.html">16</a></li>
  <li><a href="._week40-bs016.html">17</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week40-bs042.html">43</a></li>
  <li><a href="._week40-bs008.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

