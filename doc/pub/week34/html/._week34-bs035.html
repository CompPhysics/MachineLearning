<!--
Automatically generated HTML file from DocOnce source
(https://github.com/doconce/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 34: Introduction to the course, Logistics and Practicalities">

<title>Week 34: Introduction to the course, Logistics and Practicalities</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Overview of first week', 2, None, 'overview-of-first-week'),
              ('Reading Recommendations', 2, None, 'reading-recommendations'),
              ('Thursday August 26', 2, None, 'thursday-august-26'),
              ('Lectures and ComputerLab', 2, None, 'lectures-and-computerlab'),
              ('Announcement', 2, None, 'announcement'),
              ('Communication channels', 2, None, 'communication-channels'),
              ('Course Format', 2, None, 'course-format'),
              ('Teachers', 2, None, 'teachers'),
              ('Deadlines for projects (tentative)',
               2,
               None,
               'deadlines-for-projects-tentative'),
              ('Recommended textbooks', 2, None, 'recommended-textbooks'),
              ('Prerequisites', 2, None, 'prerequisites'),
              ('Learning outcomes', 2, None, 'learning-outcomes'),
              ('Topics covered in this course: Statistical analysis and '
               'optimization of data',
               2,
               None,
               'topics-covered-in-this-course-statistical-analysis-and-optimization-of-data'),
              ('Topics covered in this course: Machine Learning',
               2,
               None,
               'topics-covered-in-this-course-machine-learning'),
              ('Extremely useful tools, strongly recommended',
               2,
               None,
               'extremely-useful-tools-strongly-recommended'),
              ('Other courses on Data science and Machine Learning  at UiO',
               2,
               None,
               'other-courses-on-data-science-and-machine-learning-at-uio'),
              ('Introduction', 2, None, 'introduction'),
              ('What is Machine Learning?',
               2,
               None,
               'what-is-machine-learning'),
              ('Types of Machine Learning',
               2,
               None,
               'types-of-machine-learning'),
              ('Essential elements of ML', 2, None, 'essential-elements-of-ml'),
              ('An optimization/minimization problem',
               2,
               None,
               'an-optimization-minimization-problem'),
              ('A Frequentist approach to data analysis',
               2,
               None,
               'a-frequentist-approach-to-data-analysis'),
              ('What is a good model?', 2, None, 'what-is-a-good-model'),
              ('What is a good model? Can we define it?',
               2,
               None,
               'what-is-a-good-model-can-we-define-it'),
              ('Software and needed installations',
               2,
               None,
               'software-and-needed-installations'),
              ('Python installers', 2, None, 'python-installers'),
              ('Useful Python libraries', 2, None, 'useful-python-libraries'),
              ('Installing R, C++, cython or Julia',
               2,
               None,
               'installing-r-c-cython-or-julia'),
              ('Installing R, C++, cython, Numba etc',
               2,
               None,
               'installing-r-c-cython-numba-etc'),
              ('Numpy examples and Important Matrix and vector handling '
               'packages',
               2,
               None,
               'numpy-examples-and-important-matrix-and-vector-handling-packages'),
              ('Basic Matrix Features', 2, None, 'basic-matrix-features'),
              ('Some famous Matrices', 3, None, 'some-famous-matrices'),
              ('More Basic Matrix Features',
               3,
               None,
               'more-basic-matrix-features'),
              ('Numpy and arrays', 2, None, 'numpy-and-arrays'),
              ('Matrices in Python', 2, None, 'matrices-in-python'),
              ('Meet the Pandas', 2, None, 'meet-the-pandas'),
              ('Friday August 27', 2, None, 'friday-august-27'),
              ('Simple linear regression model using _scikit-learn_',
               3,
               None,
               'simple-linear-regression-model-using-_scikit-learn_'),
              ('To our real data: nuclear binding energies. Brief reminder on '
               'masses and binding energies',
               3,
               None,
               'to-our-real-data-nuclear-binding-energies-brief-reminder-on-masses-and-binding-energies'),
              ('Organizing our data', 3, None, 'organizing-our-data'),
              ('Seeing the wood for the trees',
               3,
               None,
               'seeing-the-wood-for-the-trees'),
              ('And what about using neural networks?',
               3,
               None,
               'and-what-about-using-neural-networks'),
              ('A first summary', 2, None, 'a-first-summary'),
              ('Why Linear Regression (aka Ordinary Least Squares and family)',
               2,
               None,
               'why-linear-regression-aka-ordinary-least-squares-and-family'),
              ('Regression analysis, overarching aims',
               2,
               None,
               'regression-analysis-overarching-aims'),
              ('Regression analysis, overarching aims II',
               2,
               None,
               'regression-analysis-overarching-aims-ii'),
              ('Examples', 2, None, 'examples'),
              ('General linear models', 2, None, 'general-linear-models'),
              ('Rewriting the fitting procedure as a linear algebra problem',
               2,
               None,
               'rewriting-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Rewriting the fitting procedure as a linear algebra problem, '
               'more details',
               2,
               None,
               'rewriting-the-fitting-procedure-as-a-linear-algebra-problem-more-details'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               'generalizing-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               'generalizing-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Optimizing our parameters',
               2,
               None,
               'optimizing-our-parameters'),
              ('Our model for the nuclear binding energies',
               2,
               None,
               'our-model-for-the-nuclear-binding-energies'),
              ('Optimizing our parameters, more details',
               2,
               None,
               'optimizing-our-parameters-more-details'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Some useful matrix and vector expressions',
               2,
               None,
               'some-useful-matrix-and-vector-expressions'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Own code for Ordinary Least Squares',
               2,
               None,
               'own-code-for-ordinary-least-squares'),
              ('Adding error analysis and training set up',
               2,
               None,
               'adding-error-analysis-and-training-set-up'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('Fitting an Equation of State for Dense Nuclear Matter',
               2,
               None,
               'fitting-an-equation-of-state-for-dense-nuclear-matter'),
              ('The code', 2, None, 'the-code'),
              ('Splitting our Data in Training and Test data',
               2,
               None,
               'splitting-our-data-in-training-and-test-data'),
              ('Exercises for week 35', 2, None, 'exercises-for-week-35'),
              ('Exercise 1: Setting up various Python environments',
               2,
               None,
               'exercise-1-setting-up-various-python-environments'),
              ('Exercise 2: making your own data and exploring scikit-learn',
               2,
               None,
               'exercise-2-making-your-own-data-and-exploring-scikit-learn'),
              ('Exercise 3: Normalizing our data',
               2,
               None,
               'exercise-3-normalizing-our-data')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week34-bs.html">Week 34: Introduction to the course, Logistics and Practicalities</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week34-bs001.html#overview-of-first-week" style="font-size: 80%;"><b>Overview of first week</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs002.html#reading-recommendations" style="font-size: 80%;"><b>Reading Recommendations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs003.html#thursday-august-26" style="font-size: 80%;"><b>Thursday August 26</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs004.html#lectures-and-computerlab" style="font-size: 80%;"><b>Lectures and ComputerLab</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs005.html#announcement" style="font-size: 80%;"><b>Announcement</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs006.html#communication-channels" style="font-size: 80%;"><b>Communication channels</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs007.html#course-format" style="font-size: 80%;"><b>Course Format</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs008.html#teachers" style="font-size: 80%;"><b>Teachers</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs009.html#deadlines-for-projects-tentative" style="font-size: 80%;"><b>Deadlines for projects (tentative)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs010.html#recommended-textbooks" style="font-size: 80%;"><b>Recommended textbooks</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs011.html#prerequisites" style="font-size: 80%;"><b>Prerequisites</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs012.html#learning-outcomes" style="font-size: 80%;"><b>Learning outcomes</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs013.html#topics-covered-in-this-course-statistical-analysis-and-optimization-of-data" style="font-size: 80%;"><b>Topics covered in this course: Statistical analysis and optimization of data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs014.html#topics-covered-in-this-course-machine-learning" style="font-size: 80%;"><b>Topics covered in this course: Machine Learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs015.html#extremely-useful-tools-strongly-recommended" style="font-size: 80%;"><b>Extremely useful tools, strongly recommended</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs016.html#other-courses-on-data-science-and-machine-learning-at-uio" style="font-size: 80%;"><b>Other courses on Data science and Machine Learning  at UiO</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs017.html#introduction" style="font-size: 80%;"><b>Introduction</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs018.html#what-is-machine-learning" style="font-size: 80%;"><b>What is Machine Learning?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs019.html#types-of-machine-learning" style="font-size: 80%;"><b>Types of Machine Learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs020.html#essential-elements-of-ml" style="font-size: 80%;"><b>Essential elements of ML</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs021.html#an-optimization-minimization-problem" style="font-size: 80%;"><b>An optimization/minimization problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs022.html#a-frequentist-approach-to-data-analysis" style="font-size: 80%;"><b>A Frequentist approach to data analysis</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs023.html#what-is-a-good-model" style="font-size: 80%;"><b>What is a good model?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs024.html#what-is-a-good-model-can-we-define-it" style="font-size: 80%;"><b>What is a good model? Can we define it?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs025.html#software-and-needed-installations" style="font-size: 80%;"><b>Software and needed installations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs026.html#python-installers" style="font-size: 80%;"><b>Python installers</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs027.html#useful-python-libraries" style="font-size: 80%;"><b>Useful Python libraries</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs028.html#installing-r-c-cython-or-julia" style="font-size: 80%;"><b>Installing R, C++, cython or Julia</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs029.html#installing-r-c-cython-numba-etc" style="font-size: 80%;"><b>Installing R, C++, cython, Numba etc</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs030.html#numpy-examples-and-important-matrix-and-vector-handling-packages" style="font-size: 80%;"><b>Numpy examples and Important Matrix and vector handling packages</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs031.html#basic-matrix-features" style="font-size: 80%;"><b>Basic Matrix Features</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs032.html#some-famous-matrices" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Some famous Matrices</a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs033.html#more-basic-matrix-features" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;More Basic Matrix Features</a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs034.html#numpy-and-arrays" style="font-size: 80%;"><b>Numpy and arrays</b></a></li>
     <!-- navigation toc: --> <li><a href="#matrices-in-python" style="font-size: 80%;"><b>Matrices in Python</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs036.html#meet-the-pandas" style="font-size: 80%;"><b>Meet the Pandas</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs037.html#friday-august-27" style="font-size: 80%;"><b>Friday August 27</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs038.html#simple-linear-regression-model-using-_scikit-learn_" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Simple linear regression model using <b>scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs038.html#to-our-real-data-nuclear-binding-energies-brief-reminder-on-masses-and-binding-energies" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;To our real data: nuclear binding energies. Brief reminder on masses and binding energies</a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs038.html#organizing-our-data" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Organizing our data</a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs038.html#seeing-the-wood-for-the-trees" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Seeing the wood for the trees</a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs038.html#and-what-about-using-neural-networks" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;And what about using neural networks?</a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs038.html#a-first-summary" style="font-size: 80%;"><b>A first summary</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs039.html#why-linear-regression-aka-ordinary-least-squares-and-family" style="font-size: 80%;"><b>Why Linear Regression (aka Ordinary Least Squares and family)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs040.html#regression-analysis-overarching-aims" style="font-size: 80%;"><b>Regression analysis, overarching aims</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs041.html#regression-analysis-overarching-aims-ii" style="font-size: 80%;"><b>Regression analysis, overarching aims II</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs042.html#examples" style="font-size: 80%;"><b>Examples</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs043.html#general-linear-models" style="font-size: 80%;"><b>General linear models</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs044.html#rewriting-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;"><b>Rewriting the fitting procedure as a linear algebra problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs045.html#rewriting-the-fitting-procedure-as-a-linear-algebra-problem-more-details" style="font-size: 80%;"><b>Rewriting the fitting procedure as a linear algebra problem, more details</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs047.html#generalizing-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;"><b>Generalizing the fitting procedure as a linear algebra problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs047.html#generalizing-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;"><b>Generalizing the fitting procedure as a linear algebra problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs048.html#optimizing-our-parameters" style="font-size: 80%;"><b>Optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs049.html#our-model-for-the-nuclear-binding-energies" style="font-size: 80%;"><b>Our model for the nuclear binding energies</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs050.html#optimizing-our-parameters-more-details" style="font-size: 80%;"><b>Optimizing our parameters, more details</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs054.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;"><b>Interpretations and optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs054.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;"><b>Interpretations and optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs053.html#some-useful-matrix-and-vector-expressions" style="font-size: 80%;"><b>Some useful matrix and vector expressions</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs054.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;"><b>Interpretations and optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs055.html#own-code-for-ordinary-least-squares" style="font-size: 80%;"><b>Own code for Ordinary Least Squares</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs056.html#adding-error-analysis-and-training-set-up" style="font-size: 80%;"><b>Adding error analysis and training set up</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs062.html#the-chi-2-function" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs062.html#the-chi-2-function" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs062.html#the-chi-2-function" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs062.html#the-chi-2-function" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs062.html#the-chi-2-function" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs062.html#the-chi-2-function" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs063.html#fitting-an-equation-of-state-for-dense-nuclear-matter" style="font-size: 80%;"><b>Fitting an Equation of State for Dense Nuclear Matter</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs064.html#the-code" style="font-size: 80%;"><b>The code</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs065.html#splitting-our-data-in-training-and-test-data" style="font-size: 80%;"><b>Splitting our Data in Training and Test data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs066.html#exercises-for-week-35" style="font-size: 80%;"><b>Exercises for week 35</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs066.html#exercise-1-setting-up-various-python-environments" style="font-size: 80%;"><b>Exercise 1: Setting up various Python environments</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs066.html#exercise-2-making-your-own-data-and-exploring-scikit-learn" style="font-size: 80%;"><b>Exercise 2: making your own data and exploring scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._week34-bs066.html#exercise-3-normalizing-our-data" style="font-size: 80%;"><b>Exercise 3: Normalizing our data</b></a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0035"></a>
<!-- !split -->

<h2 id="matrices-in-python" class="anchor">Matrices in Python </h2>

<p>
Having defined vectors, we are now ready to try out matrices. We can
define a \( 3 \times 3  \) real matrix \( \boldsymbol{A} \) as (recall that we user
lowercase letters for vectors and uppercase letters for matrices)

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
A <span style="color: #666666">=</span> np<span style="color: #666666">.</span>log(np<span style="color: #666666">.</span>array([ [<span style="color: #666666">4.0</span>, <span style="color: #666666">7.0</span>, <span style="color: #666666">8.0</span>], [<span style="color: #666666">3.0</span>, <span style="color: #666666">10.0</span>, <span style="color: #666666">11.0</span>], [<span style="color: #666666">4.0</span>, <span style="color: #666666">5.0</span>, <span style="color: #666666">7.0</span>] ]))
<span style="color: #008000">print</span>(A)
</pre></div>
<p>
If we use the <b>shape</b> function we would get \( (3, 3) \) as output, that is verifying that our matrix is a \( 3\times 3 \) matrix. We can slice the matrix and print for example the first column (Python organized matrix elements in a row-major order, see below) as
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
A <span style="color: #666666">=</span> np<span style="color: #666666">.</span>log(np<span style="color: #666666">.</span>array([ [<span style="color: #666666">4.0</span>, <span style="color: #666666">7.0</span>, <span style="color: #666666">8.0</span>], [<span style="color: #666666">3.0</span>, <span style="color: #666666">10.0</span>, <span style="color: #666666">11.0</span>], [<span style="color: #666666">4.0</span>, <span style="color: #666666">5.0</span>, <span style="color: #666666">7.0</span>] ]))
<span style="color: #408080; font-style: italic"># print the first column, row-major order and elements start with 0</span>
<span style="color: #008000">print</span>(A[:,<span style="color: #666666">0</span>]) 
</pre></div>
<p>
We can continue this was by printing out other columns or rows. The example here prints out the second column
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
A <span style="color: #666666">=</span> np<span style="color: #666666">.</span>log(np<span style="color: #666666">.</span>array([ [<span style="color: #666666">4.0</span>, <span style="color: #666666">7.0</span>, <span style="color: #666666">8.0</span>], [<span style="color: #666666">3.0</span>, <span style="color: #666666">10.0</span>, <span style="color: #666666">11.0</span>], [<span style="color: #666666">4.0</span>, <span style="color: #666666">5.0</span>, <span style="color: #666666">7.0</span>] ]))
<span style="color: #408080; font-style: italic"># print the first column, row-major order and elements start with 0</span>
<span style="color: #008000">print</span>(A[<span style="color: #666666">1</span>,:]) 
</pre></div>
<p>
Numpy contains many other functionalities that allow us to slice, subdivide etc etc arrays. We strongly recommend that you look up the <a href="http://www.numpy.org/" target="_self">Numpy website for more details</a>. Useful functions when defining a matrix are the <b>np.zeros</b> function which declares a matrix of a given dimension and sets all elements to zero
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
n <span style="color: #666666">=</span> <span style="color: #666666">10</span>
<span style="color: #408080; font-style: italic"># define a matrix of dimension 10 x 10 and set all elements to zero</span>
A <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros( (n, n) )
<span style="color: #008000">print</span>(A) 
</pre></div>
<p>
or initializing all elements to 
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
n <span style="color: #666666">=</span> <span style="color: #666666">10</span>
<span style="color: #408080; font-style: italic"># define a matrix of dimension 10 x 10 and set all elements to one</span>
A <span style="color: #666666">=</span> np<span style="color: #666666">.</span>ones( (n, n) )
<span style="color: #008000">print</span>(A) 
</pre></div>
<p>
or as unitarily distributed random numbers (see the material on random number generators in the statistics part)
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
n <span style="color: #666666">=</span> <span style="color: #666666">10</span>
<span style="color: #408080; font-style: italic"># define a matrix of dimension 10 x 10 and set all elements to random numbers with x \in [0, 1]</span>
A <span style="color: #666666">=</span> np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>rand(n, n)
<span style="color: #008000">print</span>(A) 
</pre></div>
<p>
As we will see throughout these lectures, there are several extremely useful functionalities in Numpy.
As an example, consider the discussion of the covariance matrix. Suppose we have defined three vectors
\( \boldsymbol{x}, \boldsymbol{y}, \boldsymbol{z} \) with \( n \) elements each. The covariance matrix is defined as 
$$
\boldsymbol{\Sigma} = \begin{bmatrix} \sigma_{xx} & \sigma_{xy} & \sigma_{xz} \\
                              \sigma_{yx} & \sigma_{yy} & \sigma_{yz} \\
                              \sigma_{zx} & \sigma_{zy} & \sigma_{zz} 
             \end{bmatrix},
$$

where for example
$$
\sigma_{xy} =\frac{1}{n} \sum_{i=0}^{n-1}(x_i- \overline{x})(y_i- \overline{y}).
$$

The Numpy function <b>np.cov</b> calculates the covariance elements using the factor \( 1/(n-1) \) instead of \( 1/n \) since it assumes we do not have the exact mean values. 
The following simple function uses the <b>np.vstack</b> function which takes each vector of dimension \( 1\times n \) and produces a \( 3\times n \) matrix \( \boldsymbol{W} \)
$$
\boldsymbol{W} = \begin{bmatrix} x_0 & x_1 & x_2 & \dots & x_{n-2} & x_{n-1} \\
                         y_0 & y_1 & y_2 & \dots & y_{n-2} & y_{n-1} \\
			 z_0 & z_1 & z_2 & \dots & z_{n-2} & z_{n-1} \\
             \end{bmatrix},
$$

<p>
which in turn is converted into into the \( 3\times 3 \) covariance matrix
\( \boldsymbol{\Sigma} \) via the Numpy function <b>np.cov()</b>. We note that we can also calculate
the mean value of each set of samples \( \boldsymbol{x} \) etc using the Numpy
function <b>np.mean(x)</b>. We can also extract the eigenvalues of the
covariance matrix through the <b>np.linalg.eig()</b> function.

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><span style="color: #408080; font-style: italic"># Importing various packages</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>

n <span style="color: #666666">=</span> <span style="color: #666666">100</span>
x <span style="color: #666666">=</span> np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>normal(size<span style="color: #666666">=</span>n)
<span style="color: #008000">print</span>(np<span style="color: #666666">.</span>mean(x))
y <span style="color: #666666">=</span> <span style="color: #666666">4+3*</span>x<span style="color: #666666">+</span>np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>normal(size<span style="color: #666666">=</span>n)
<span style="color: #008000">print</span>(np<span style="color: #666666">.</span>mean(y))
z <span style="color: #666666">=</span> x<span style="color: #666666">**3+</span>np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>normal(size<span style="color: #666666">=</span>n)
<span style="color: #008000">print</span>(np<span style="color: #666666">.</span>mean(z))
W <span style="color: #666666">=</span> np<span style="color: #666666">.</span>vstack((x, y, z))
Sigma <span style="color: #666666">=</span> np<span style="color: #666666">.</span>cov(W)
<span style="color: #008000">print</span>(Sigma)
Eigvals, Eigvecs <span style="color: #666666">=</span> np<span style="color: #666666">.</span>linalg<span style="color: #666666">.</span>eig(Sigma)
<span style="color: #008000">print</span>(Eigvals)
</pre></div>
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">scipy</span> <span style="color: #008000; font-weight: bold">import</span> sparse
eye <span style="color: #666666">=</span> np<span style="color: #666666">.</span>eye(<span style="color: #666666">4</span>)
<span style="color: #008000">print</span>(eye)
sparse_mtx <span style="color: #666666">=</span> sparse<span style="color: #666666">.</span>csr_matrix(eye)
<span style="color: #008000">print</span>(sparse_mtx)
x <span style="color: #666666">=</span> np<span style="color: #666666">.</span>linspace(<span style="color: #666666">-10</span>,<span style="color: #666666">10</span>,<span style="color: #666666">100</span>)
y <span style="color: #666666">=</span> np<span style="color: #666666">.</span>sin(x)
plt<span style="color: #666666">.</span>plot(x,y,marker<span style="color: #666666">=</span><span style="color: #BA2121">&#39;x&#39;</span>)
plt<span style="color: #666666">.</span>show()
</pre></div>
<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week34-bs034.html">&laquo;</a></li>
  <li><a href="._week34-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week34-bs027.html">28</a></li>
  <li><a href="._week34-bs028.html">29</a></li>
  <li><a href="._week34-bs029.html">30</a></li>
  <li><a href="._week34-bs030.html">31</a></li>
  <li><a href="._week34-bs031.html">32</a></li>
  <li><a href="._week34-bs032.html">33</a></li>
  <li><a href="._week34-bs033.html">34</a></li>
  <li><a href="._week34-bs034.html">35</a></li>
  <li class="active"><a href="._week34-bs035.html">36</a></li>
  <li><a href="._week34-bs036.html">37</a></li>
  <li><a href="._week34-bs037.html">38</a></li>
  <li><a href="._week34-bs038.html">39</a></li>
  <li><a href="._week34-bs039.html">40</a></li>
  <li><a href="._week34-bs040.html">41</a></li>
  <li><a href="._week34-bs041.html">42</a></li>
  <li><a href="._week34-bs042.html">43</a></li>
  <li><a href="._week34-bs043.html">44</a></li>
  <li><a href="._week34-bs044.html">45</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week34-bs066.html">67</a></li>
  <li><a href="._week34-bs036.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    

