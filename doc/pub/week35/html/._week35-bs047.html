<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week35.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week35-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 35: From Ordinary Linear Regression to Ridge and Lasso Regression">
<title>Week 35: From Ordinary Linear Regression to Ridge and Lasso Regression</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week35.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week35-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plans for week 35', 2, None, 'plans-for-week-35'),
              ('Reading recommendations:', 3, None, 'reading-recommendations'),
              ('Why Linear Regression (aka Ordinary Least Squares and family), '
               'repeat from last week',
               2,
               None,
               'why-linear-regression-aka-ordinary-least-squares-and-family-repeat-from-last-week'),
              ('Regression analysis, overarching aims',
               2,
               None,
               'regression-analysis-overarching-aims'),
              ('Regression analysis, overarching aims II',
               2,
               None,
               'regression-analysis-overarching-aims-ii'),
              ('Examples', 2, None, 'examples'),
              ('General linear models', 2, None, 'general-linear-models'),
              ('Rewriting the fitting procedure as a linear algebra problem',
               2,
               None,
               'rewriting-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Rewriting the fitting procedure as a linear algebra problem, '
               'more details',
               2,
               None,
               'rewriting-the-fitting-procedure-as-a-linear-algebra-problem-more-details'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               'generalizing-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               'generalizing-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Optimizing our parameters',
               2,
               None,
               'optimizing-our-parameters'),
              ('Examples relevant for the exercises',
               2,
               None,
               'examples-relevant-for-the-exercises'),
              ('Optimizing our parameters, more details',
               2,
               None,
               'optimizing-our-parameters-more-details'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Some useful matrix and vector expressions',
               2,
               None,
               'some-useful-matrix-and-vector-expressions'),
              ('The Jacobian', 2, None, 'the-jacobian'),
              ('Derivatives, example 1', 2, None, 'derivatives-example-1'),
              ('Meet the Hessian Matrix', 2, None, 'meet-the-hessian-matrix'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Own code for Ordinary Least Squares',
               2,
               None,
               'own-code-for-ordinary-least-squares'),
              ('Adding error analysis and training set up',
               2,
               None,
               'adding-error-analysis-and-training-set-up'),
              ('Splitting our Data in Training and Test data',
               2,
               None,
               'splitting-our-data-in-training-and-test-data'),
              ('Examples', 2, None, 'examples'),
              ('Making your own test-train splitting',
               2,
               None,
               'making-your-own-test-train-splitting'),
              ('The Boston housing data example',
               2,
               None,
               'the-boston-housing-data-example'),
              ('Housing data, the code', 2, None, 'housing-data-the-code'),
              ('Reducing the number of degrees of freedom, overarching view',
               2,
               None,
               'reducing-the-number-of-degrees-of-freedom-overarching-view'),
              ('Preprocessing our data', 2, None, 'preprocessing-our-data'),
              ('Functionality in Scikit-Learn',
               2,
               None,
               'functionality-in-scikit-learn'),
              ('More preprocessing', 2, None, 'more-preprocessing'),
              ('Frequently used scaling functions',
               2,
               None,
               'frequently-used-scaling-functions'),
              ('Example of own Standard scaling',
               2,
               None,
               'example-of-own-standard-scaling'),
              ('Min-Max Scaling', 2, None, 'min-max-scaling'),
              ('Testing the Means Squared Error as function of Complexity',
               2,
               None,
               'testing-the-means-squared-error-as-function-of-complexity'),
              ('More preprocessing examples, Franke function and regression',
               2,
               None,
               'more-preprocessing-examples-franke-function-and-regression'),
              ('Material for lecture Thursday, August 31',
               2,
               None,
               'material-for-lecture-thursday-august-31'),
              ('Mathematical Interpretation of Ordinary Least Squares',
               2,
               None,
               'mathematical-interpretation-of-ordinary-least-squares'),
              ('Residual Error', 2, None, 'residual-error'),
              ('Simple case', 2, None, 'simple-case'),
              ('The singular value decomposition',
               2,
               None,
               'the-singular-value-decomposition'),
              ('Linear Regression Problems',
               2,
               None,
               'linear-regression-problems'),
              ('Fixing the singularity', 2, None, 'fixing-the-singularity'),
              ('Basic math of the SVD', 2, None, 'basic-math-of-the-svd'),
              ('The SVD, a Fantastic Algorithm',
               2,
               None,
               'the-svd-a-fantastic-algorithm'),
              ('Economy-size SVD', 2, None, 'economy-size-svd'),
              ('Codes for the SVD', 2, None, 'codes-for-the-svd'),
              ('Note about SVD Calculations',
               2,
               None,
               'note-about-svd-calculations'),
              ('Mathematics of the SVD and implications',
               2,
               None,
               'mathematics-of-the-svd-and-implications'),
              ('Example Matrix', 2, None, 'example-matrix'),
              ('Setting up the Matrix to be inverted',
               2,
               None,
               'setting-up-the-matrix-to-be-inverted'),
              ('Further properties (important for our analyses later)',
               2,
               None,
               'further-properties-important-for-our-analyses-later'),
              ('Meet the Covariance Matrix',
               2,
               None,
               'meet-the-covariance-matrix'),
              ('Introducing the Covariance and Correlation functions',
               2,
               None,
               'introducing-the-covariance-and-correlation-functions'),
              ('Covariance and Correlation Matrix',
               2,
               None,
               'covariance-and-correlation-matrix'),
              ('Correlation Function and Design/Feature Matrix',
               2,
               None,
               'correlation-function-and-design-feature-matrix'),
              ('Covariance Matrix Examples',
               2,
               None,
               'covariance-matrix-examples'),
              ('Correlation Matrix', 2, None, 'correlation-matrix'),
              ('Correlation Matrix with Pandas',
               2,
               None,
               'correlation-matrix-with-pandas'),
              ('Correlation Matrix with Pandas and the Franke function',
               2,
               None,
               'correlation-matrix-with-pandas-and-the-franke-function'),
              ('Rewriting the Covariance and/or Correlation Matrix',
               2,
               None,
               'rewriting-the-covariance-and-or-correlation-matrix'),
              ('Linking with the SVD', 2, None, 'linking-with-the-svd'),
              ('What does it mean?', 2, None, 'what-does-it-mean'),
              ('And finally  $\\boldsymbol{X}\\boldsymbol{X}^T$',
               2,
               None,
               'and-finally-boldsymbol-x-boldsymbol-x-t'),
              ('Ridge and LASSO Regression',
               2,
               None,
               'ridge-and-lasso-regression'),
              ('Deriving the  Ridge Regression Equations',
               2,
               None,
               'deriving-the-ridge-regression-equations'),
              ('Interpreting the Ridge results',
               2,
               None,
               'interpreting-the-ridge-results'),
              ('More interpretations', 2, None, 'more-interpretations'),
              ('Deriving the  Lasso Regression Equations',
               2,
               None,
               'deriving-the-lasso-regression-equations'),
              ('Exercises for week 35', 2, None, 'exercises-for-week-35'),
              ('Exercise 1: Setting up various Python environments',
               2,
               None,
               'exercise-1-setting-up-various-python-environments'),
              ('Exercise 2: making your own data and exploring scikit-learn',
               2,
               None,
               'exercise-2-making-your-own-data-and-exploring-scikit-learn'),
              ('Exercise 3: Normalizing our data',
               2,
               None,
               'exercise-3-normalizing-our-data'),
              ('Exercise 4: Adding Ridge Regression',
               2,
               None,
               'exercise-4-adding-ridge-regression'),
              ('Exercise 5: Analytical exercises',
               2,
               None,
               'exercise-5-analytical-exercises')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week35-bs.html">Week 35: From Ordinary Linear Regression to Ridge and Lasso Regression</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week35-bs001.html#plans-for-week-35" style="font-size: 80%;"><b>Plans for week 35</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs001.html#reading-recommendations" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Reading recommendations:</a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs002.html#why-linear-regression-aka-ordinary-least-squares-and-family-repeat-from-last-week" style="font-size: 80%;"><b>Why Linear Regression (aka Ordinary Least Squares and family), repeat from last week</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs003.html#regression-analysis-overarching-aims" style="font-size: 80%;"><b>Regression analysis, overarching aims</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs004.html#regression-analysis-overarching-aims-ii" style="font-size: 80%;"><b>Regression analysis, overarching aims II</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs024.html#examples" style="font-size: 80%;"><b>Examples</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs006.html#general-linear-models" style="font-size: 80%;"><b>General linear models</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs007.html#rewriting-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;"><b>Rewriting the fitting procedure as a linear algebra problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs008.html#rewriting-the-fitting-procedure-as-a-linear-algebra-problem-more-details" style="font-size: 80%;"><b>Rewriting the fitting procedure as a linear algebra problem, more details</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs010.html#generalizing-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;"><b>Generalizing the fitting procedure as a linear algebra problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs010.html#generalizing-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;"><b>Generalizing the fitting procedure as a linear algebra problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs011.html#optimizing-our-parameters" style="font-size: 80%;"><b>Optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs012.html#examples-relevant-for-the-exercises" style="font-size: 80%;"><b>Examples relevant for the exercises</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs013.html#optimizing-our-parameters-more-details" style="font-size: 80%;"><b>Optimizing our parameters, more details</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs020.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;"><b>Interpretations and optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs020.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;"><b>Interpretations and optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs016.html#some-useful-matrix-and-vector-expressions" style="font-size: 80%;"><b>Some useful matrix and vector expressions</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs017.html#the-jacobian" style="font-size: 80%;"><b>The Jacobian</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs018.html#derivatives-example-1" style="font-size: 80%;"><b>Derivatives, example 1</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs019.html#meet-the-hessian-matrix" style="font-size: 80%;"><b>Meet the Hessian Matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs020.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;"><b>Interpretations and optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs021.html#own-code-for-ordinary-least-squares" style="font-size: 80%;"><b>Own code for Ordinary Least Squares</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs022.html#adding-error-analysis-and-training-set-up" style="font-size: 80%;"><b>Adding error analysis and training set up</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs023.html#splitting-our-data-in-training-and-test-data" style="font-size: 80%;"><b>Splitting our Data in Training and Test data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs024.html#examples" style="font-size: 80%;"><b>Examples</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs025.html#making-your-own-test-train-splitting" style="font-size: 80%;"><b>Making your own test-train splitting</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs026.html#the-boston-housing-data-example" style="font-size: 80%;"><b>The Boston housing data example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs027.html#housing-data-the-code" style="font-size: 80%;"><b>Housing data, the code</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs028.html#reducing-the-number-of-degrees-of-freedom-overarching-view" style="font-size: 80%;"><b>Reducing the number of degrees of freedom, overarching view</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs029.html#preprocessing-our-data" style="font-size: 80%;"><b>Preprocessing our data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs030.html#functionality-in-scikit-learn" style="font-size: 80%;"><b>Functionality in Scikit-Learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs031.html#more-preprocessing" style="font-size: 80%;"><b>More preprocessing</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs032.html#frequently-used-scaling-functions" style="font-size: 80%;"><b>Frequently used scaling functions</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs033.html#example-of-own-standard-scaling" style="font-size: 80%;"><b>Example of own Standard scaling</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs034.html#min-max-scaling" style="font-size: 80%;"><b>Min-Max Scaling</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs035.html#testing-the-means-squared-error-as-function-of-complexity" style="font-size: 80%;"><b>Testing the Means Squared Error as function of Complexity</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs036.html#more-preprocessing-examples-franke-function-and-regression" style="font-size: 80%;"><b>More preprocessing examples, Franke function and regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs037.html#material-for-lecture-thursday-august-31" style="font-size: 80%;"><b>Material for lecture Thursday, August 31</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs038.html#mathematical-interpretation-of-ordinary-least-squares" style="font-size: 80%;"><b>Mathematical Interpretation of Ordinary Least Squares</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs039.html#residual-error" style="font-size: 80%;"><b>Residual Error</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs040.html#simple-case" style="font-size: 80%;"><b>Simple case</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs041.html#the-singular-value-decomposition" style="font-size: 80%;"><b>The singular value decomposition</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs042.html#linear-regression-problems" style="font-size: 80%;"><b>Linear Regression Problems</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs043.html#fixing-the-singularity" style="font-size: 80%;"><b>Fixing the singularity</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs044.html#basic-math-of-the-svd" style="font-size: 80%;"><b>Basic math of the SVD</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs045.html#the-svd-a-fantastic-algorithm" style="font-size: 80%;"><b>The SVD, a Fantastic Algorithm</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs046.html#economy-size-svd" style="font-size: 80%;"><b>Economy-size SVD</b></a></li>
     <!-- navigation toc: --> <li><a href="#codes-for-the-svd" style="font-size: 80%;"><b>Codes for the SVD</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs048.html#note-about-svd-calculations" style="font-size: 80%;"><b>Note about SVD Calculations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs049.html#mathematics-of-the-svd-and-implications" style="font-size: 80%;"><b>Mathematics of the SVD and implications</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs050.html#example-matrix" style="font-size: 80%;"><b>Example Matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs051.html#setting-up-the-matrix-to-be-inverted" style="font-size: 80%;"><b>Setting up the Matrix to be inverted</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs052.html#further-properties-important-for-our-analyses-later" style="font-size: 80%;"><b>Further properties (important for our analyses later)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs053.html#meet-the-covariance-matrix" style="font-size: 80%;"><b>Meet the Covariance Matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs054.html#introducing-the-covariance-and-correlation-functions" style="font-size: 80%;"><b>Introducing the Covariance and Correlation functions</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs055.html#covariance-and-correlation-matrix" style="font-size: 80%;"><b>Covariance and Correlation Matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs056.html#correlation-function-and-design-feature-matrix" style="font-size: 80%;"><b>Correlation Function and Design/Feature Matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs057.html#covariance-matrix-examples" style="font-size: 80%;"><b>Covariance Matrix Examples</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs058.html#correlation-matrix" style="font-size: 80%;"><b>Correlation Matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs059.html#correlation-matrix-with-pandas" style="font-size: 80%;"><b>Correlation Matrix with Pandas</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs060.html#correlation-matrix-with-pandas-and-the-franke-function" style="font-size: 80%;"><b>Correlation Matrix with Pandas and the Franke function</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs061.html#rewriting-the-covariance-and-or-correlation-matrix" style="font-size: 80%;"><b>Rewriting the Covariance and/or Correlation Matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs062.html#linking-with-the-svd" style="font-size: 80%;"><b>Linking with the SVD</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs063.html#what-does-it-mean" style="font-size: 80%;"><b>What does it mean?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs064.html#and-finally-boldsymbol-x-boldsymbol-x-t" style="font-size: 80%;"><b>And finally  \( \boldsymbol{X}\boldsymbol{X}^T \)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs065.html#ridge-and-lasso-regression" style="font-size: 80%;"><b>Ridge and LASSO Regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs066.html#deriving-the-ridge-regression-equations" style="font-size: 80%;"><b>Deriving the  Ridge Regression Equations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs067.html#interpreting-the-ridge-results" style="font-size: 80%;"><b>Interpreting the Ridge results</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs068.html#more-interpretations" style="font-size: 80%;"><b>More interpretations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs069.html#deriving-the-lasso-regression-equations" style="font-size: 80%;"><b>Deriving the  Lasso Regression Equations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs070.html#exercises-for-week-35" style="font-size: 80%;"><b>Exercises for week 35</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs070.html#exercise-1-setting-up-various-python-environments" style="font-size: 80%;"><b>Exercise 1: Setting up various Python environments</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs070.html#exercise-2-making-your-own-data-and-exploring-scikit-learn" style="font-size: 80%;"><b>Exercise 2: making your own data and exploring scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs070.html#exercise-3-normalizing-our-data" style="font-size: 80%;"><b>Exercise 3: Normalizing our data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs070.html#exercise-4-adding-ridge-regression" style="font-size: 80%;"><b>Exercise 4: Adding Ridge Regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._week35-bs070.html#exercise-5-analytical-exercises" style="font-size: 80%;"><b>Exercise 5: Analytical exercises</b></a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0047"></a>
<!-- !split -->
<h2 id="codes-for-the-svd" class="anchor">Codes for the SVD </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #408080; font-style: italic"># SVD inversion</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">SVD</span>(A):
    <span style="color: #BA2121; font-style: italic">&#39;&#39;&#39; Takes as input a numpy matrix A and returns inv(A) based on singular value decomposition (SVD).</span>
<span style="color: #BA2121; font-style: italic">    SVD is numerically more stable than the inversion algorithms provided by</span>
<span style="color: #BA2121; font-style: italic">    numpy and scipy.linalg at the cost of being slower.</span>
<span style="color: #BA2121; font-style: italic">    &#39;&#39;&#39;</span>
    U, S, VT <span style="color: #666666">=</span> np<span style="color: #666666">.</span>linalg<span style="color: #666666">.</span>svd(A,full_matrices<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>)
    <span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;test U&#39;</span>)
    <span style="color: #008000">print</span>( (np<span style="color: #666666">.</span>transpose(U) <span style="color: #666666">@</span> U <span style="color: #666666">-</span> U <span style="color: #AA22FF">@np</span><span style="color: #666666">.</span>transpose(U)))
    <span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;test VT&#39;</span>)
    <span style="color: #008000">print</span>( (np<span style="color: #666666">.</span>transpose(VT) <span style="color: #666666">@</span> VT <span style="color: #666666">-</span> VT <span style="color: #AA22FF">@np</span><span style="color: #666666">.</span>transpose(VT)))
    <span style="color: #008000">print</span>(U)
    <span style="color: #008000">print</span>(S)
    <span style="color: #008000">print</span>(VT)

    D <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #008000">len</span>(U),<span style="color: #008000">len</span>(VT)))
    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #666666">0</span>,<span style="color: #008000">len</span>(VT)):
        D[i,i]<span style="color: #666666">=</span>S[i]
    <span style="color: #008000; font-weight: bold">return</span> U <span style="color: #666666">@</span> D <span style="color: #666666">@</span> VT


X <span style="color: #666666">=</span> np<span style="color: #666666">.</span>array([ [<span style="color: #666666">1.0</span>,<span style="color: #666666">-1.0</span>], [<span style="color: #666666">1.0</span>,<span style="color: #666666">-1.0</span>]])
<span style="color: #408080; font-style: italic">#X = np.array([[1, 2], [3, 4], [5, 6]])</span>

<span style="color: #008000">print</span>(X)
C <span style="color: #666666">=</span> SVD(X)
<span style="color: #408080; font-style: italic"># Print the difference between the original matrix and the SVD one</span>
<span style="color: #008000">print</span>(C<span style="color: #666666">-</span>X)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>The matrix \( \boldsymbol{X} \) has columns that are linearly dependent. The first
column is the row-wise sum of the other two columns. The rank of a
matrix (the column rank) is the dimension of space spanned by the
column vectors. The rank of the matrix is the number of linearly
independent columns, in this case just \( 2 \). We see this from the
singular values when running the above code. Running the standard
inversion algorithm for matrix inversion with \( \boldsymbol{X}^T\boldsymbol{X} \) results
in the program terminating due to a singular matrix.
</p>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week35-bs046.html">&laquo;</a></li>
  <li><a href="._week35-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week35-bs039.html">40</a></li>
  <li><a href="._week35-bs040.html">41</a></li>
  <li><a href="._week35-bs041.html">42</a></li>
  <li><a href="._week35-bs042.html">43</a></li>
  <li><a href="._week35-bs043.html">44</a></li>
  <li><a href="._week35-bs044.html">45</a></li>
  <li><a href="._week35-bs045.html">46</a></li>
  <li><a href="._week35-bs046.html">47</a></li>
  <li class="active"><a href="._week35-bs047.html">48</a></li>
  <li><a href="._week35-bs048.html">49</a></li>
  <li><a href="._week35-bs049.html">50</a></li>
  <li><a href="._week35-bs050.html">51</a></li>
  <li><a href="._week35-bs051.html">52</a></li>
  <li><a href="._week35-bs052.html">53</a></li>
  <li><a href="._week35-bs053.html">54</a></li>
  <li><a href="._week35-bs054.html">55</a></li>
  <li><a href="._week35-bs055.html">56</a></li>
  <li><a href="._week35-bs056.html">57</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week35-bs070.html">71</a></li>
  <li><a href="._week35-bs048.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

