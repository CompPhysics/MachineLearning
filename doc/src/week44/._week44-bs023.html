<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week44.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week44-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 44,  Convolutional Neural Networks (CNN)">
<title>Week 44,  Convolutional Neural Networks (CNN)</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week44.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week44-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 44', 2, None, 'plan-for-week-44'),
              ('Lab  sessions on Tuesday and Wednesday',
               2,
               None,
               'lab-sessions-on-tuesday-and-wednesday'),
              ('Material for Lecture Monday October 28',
               2,
               None,
               'material-for-lecture-monday-october-28'),
              ('Convolutional Neural Networks (recognizing images)',
               2,
               None,
               'convolutional-neural-networks-recognizing-images'),
              ('What is the Difference', 2, None, 'what-is-the-difference'),
              ('Neural Networks vs CNNs', 2, None, 'neural-networks-vs-cnns'),
              ('Why CNNS for images, sound files, medical images from CT scans '
               'etc?',
               2,
               None,
               'why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc'),
              ('Regular NNs don’t scale well to full images',
               2,
               None,
               'regular-nns-don-t-scale-well-to-full-images'),
              ('3D volumes of neurons', 2, None, '3d-volumes-of-neurons'),
              ('More on Dimensionalities', 2, None, 'more-on-dimensionalities'),
              ('Further remarks', 2, None, 'further-remarks'),
              ('Layers used to build CNNs',
               2,
               None,
               'layers-used-to-build-cnns'),
              ('Transforming images', 2, None, 'transforming-images'),
              ('CNNs in brief', 2, None, 'cnns-in-brief'),
              ('A deep CNN model ("From Raschka et '
               'al":"https://github.com/rasbt/machine-learning-book")',
               2,
               None,
               'a-deep-cnn-model-from-raschka-et-al-https-github-com-rasbt-machine-learning-book'),
              ('Key Idea', 2, None, 'key-idea'),
              ('Mathematics of CNNs', 2, None, 'mathematics-of-cnns'),
              ('Convolution Examples: Polynomial multiplication',
               2,
               None,
               'convolution-examples-polynomial-multiplication'),
              ('Efficient Polynomial Multiplication',
               2,
               None,
               'efficient-polynomial-multiplication'),
              ('Further simplification', 2, None, 'further-simplification'),
              ('A more efficient way of coding the above Convolution',
               2,
               None,
               'a-more-efficient-way-of-coding-the-above-convolution'),
              ('Fourier series and Toeplitz matrices',
               2,
               None,
               'fourier-series-and-toeplitz-matrices'),
              ('Generalizing the above one-dimensional case',
               2,
               None,
               'generalizing-the-above-one-dimensional-case'),
              ('Two-dimensional Objects', 2, None, 'two-dimensional-objects'),
              ('CNNs in more detail', 2, None, 'cnns-in-more-detail'),
              ('Performing a discrete convolution with padding ("From Raschka '
               'et al":"https://github.com/rasbt/machine-learning-book")',
               2,
               None,
               'performing-a-discrete-convolution-with-padding-from-raschka-et-al-https-github-com-rasbt-machine-learning-book'),
              ('Performing a general discrete convolution ("From Raschka et '
               'al":"https://github.com/rasbt/machine-learning-book")',
               2,
               None,
               'performing-a-general-discrete-convolution-from-raschka-et-al-https-github-com-rasbt-machine-learning-book'),
              ('Set of filters', 2, None, 'set-of-filters'),
              ('Pooling', 2, None, 'pooling'),
              ('No zero padding, unit strides',
               2,
               None,
               'no-zero-padding-unit-strides'),
              ('Zero padding, unit strides',
               2,
               None,
               'zero-padding-unit-strides'),
              ('Half (same) padding', 2, None, 'half-same-padding'),
              ('Full padding', 2, None, 'full-padding'),
              ('Pooling arithmetic', 2, None, 'pooling-arithmetic'),
              ('Pooling types ("From Raschka et '
               'al":"https://github.com/rasbt/machine-learning-book")',
               2,
               None,
               'pooling-types-from-raschka-et-al-https-github-com-rasbt-machine-learning-book'),
              ('Building our own CNN code',
               2,
               None,
               'building-our-own-cnn-code'),
              ('List of contents:', 3, None, 'list-of-contents'),
              ('Schedulers', 3, None, 'schedulers'),
              ('Usage of schedulers', 3, None, 'usage-of-schedulers'),
              ('Cost functions', 3, None, 'cost-functions'),
              ('Usage of cost functions', 3, None, 'usage-of-cost-functions'),
              ('Activation functions', 3, None, 'activation-functions'),
              ('Usage of activation functions',
               3,
               None,
               'usage-of-activation-functions'),
              ('Convolution', 3, None, 'convolution'),
              ('Layers', 3, None, 'layers'),
              ('Convolution2DLayer: convolution in a hidden layer',
               3,
               None,
               'convolution2dlayer-convolution-in-a-hidden-layer'),
              ('Backpropagation in the convolutional layer',
               3,
               None,
               'backpropagation-in-the-convolutional-layer'),
              ('Demonstration', 3, None, 'demonstration'),
              ('Pooling Layer', 3, None, 'pooling-layer'),
              ('Flattening Layer', 3, None, 'flattening-layer'),
              ('Fully Connected Layers', 3, None, 'fully-connected-layers'),
              ('Optimized Convolution2DLayer',
               3,
               None,
               'optimized-convolution2dlayer'),
              ('The Convolutional Neural Network (CNN)',
               3,
               None,
               'the-convolutional-neural-network-cnn'),
              ('Usage of CNN code', 3, None, 'usage-of-cnn-code'),
              ('Additional Remarks', 3, None, 'additional-remarks'),
              ('Remarks on the speed', 3, None, 'remarks-on-the-speed'),
              ('Convolution using separable kernels',
               3,
               None,
               'convolution-using-separable-kernels'),
              ('Convolution in the Fourier domain',
               3,
               None,
               'convolution-in-the-fourier-domain'),
              ('Building convolutional neural networks in Tensorflow and Keras',
               2,
               None,
               'building-convolutional-neural-networks-in-tensorflow-and-keras'),
              ('Setting it up', 2, None, 'setting-it-up'),
              ('The MNIST dataset again', 2, None, 'the-mnist-dataset-again'),
              ('Strong correlations', 2, None, 'strong-correlations'),
              ('Layers of a CNN', 2, None, 'layers-of-a-cnn'),
              ('Systematic reduction', 2, None, 'systematic-reduction'),
              ('Prerequisites: Collect and pre-process data',
               2,
               None,
               'prerequisites-collect-and-pre-process-data'),
              ('Importing Keras and Tensorflow',
               2,
               None,
               'importing-keras-and-tensorflow'),
              ('Running with Keras', 2, None, 'running-with-keras'),
              ('Final part', 2, None, 'final-part'),
              ('Final visualization', 2, None, 'final-visualization')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week44-bs.html">Week 44,  Convolutional Neural Networks (CNN)</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week44-bs001.html#plan-for-week-44" style="font-size: 80%;"><b>Plan for week 44</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs002.html#lab-sessions-on-tuesday-and-wednesday" style="font-size: 80%;"><b>Lab  sessions on Tuesday and Wednesday</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs003.html#material-for-lecture-monday-october-28" style="font-size: 80%;"><b>Material for Lecture Monday October 28</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs004.html#convolutional-neural-networks-recognizing-images" style="font-size: 80%;"><b>Convolutional Neural Networks (recognizing images)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs005.html#what-is-the-difference" style="font-size: 80%;"><b>What is the Difference</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs006.html#neural-networks-vs-cnns" style="font-size: 80%;"><b>Neural Networks vs CNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs007.html#why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc" style="font-size: 80%;"><b>Why CNNS for images, sound files, medical images from CT scans etc?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs008.html#regular-nns-don-t-scale-well-to-full-images" style="font-size: 80%;"><b>Regular NNs don’t scale well to full images</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs009.html#3d-volumes-of-neurons" style="font-size: 80%;"><b>3D volumes of neurons</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs010.html#more-on-dimensionalities" style="font-size: 80%;"><b>More on Dimensionalities</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs011.html#further-remarks" style="font-size: 80%;"><b>Further remarks</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs012.html#layers-used-to-build-cnns" style="font-size: 80%;"><b>Layers used to build CNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs013.html#transforming-images" style="font-size: 80%;"><b>Transforming images</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs014.html#cnns-in-brief" style="font-size: 80%;"><b>CNNs in brief</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs015.html#a-deep-cnn-model-from-raschka-et-al-https-github-com-rasbt-machine-learning-book" style="font-size: 80%;"><b>A deep CNN model ("From Raschka et al":"https://github.com/rasbt/machine-learning-book")</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs016.html#key-idea" style="font-size: 80%;"><b>Key Idea</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs017.html#mathematics-of-cnns" style="font-size: 80%;"><b>Mathematics of CNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs018.html#convolution-examples-polynomial-multiplication" style="font-size: 80%;"><b>Convolution Examples: Polynomial multiplication</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs019.html#efficient-polynomial-multiplication" style="font-size: 80%;"><b>Efficient Polynomial Multiplication</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs020.html#further-simplification" style="font-size: 80%;"><b>Further simplification</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs021.html#a-more-efficient-way-of-coding-the-above-convolution" style="font-size: 80%;"><b>A more efficient way of coding the above Convolution</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs022.html#fourier-series-and-toeplitz-matrices" style="font-size: 80%;"><b>Fourier series and Toeplitz matrices</b></a></li>
     <!-- navigation toc: --> <li><a href="#generalizing-the-above-one-dimensional-case" style="font-size: 80%;"><b>Generalizing the above one-dimensional case</b></a></li>
     <!-- navigation toc: --> <li><a href="#two-dimensional-objects" style="font-size: 80%;"><b>Two-dimensional Objects</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs024.html#cnns-in-more-detail" style="font-size: 80%;"><b>CNNs in more detail</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs025.html#performing-a-discrete-convolution-with-padding-from-raschka-et-al-https-github-com-rasbt-machine-learning-book" style="font-size: 80%;"><b>Performing a discrete convolution with padding ("From Raschka et al":"https://github.com/rasbt/machine-learning-book")</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs026.html#performing-a-general-discrete-convolution-from-raschka-et-al-https-github-com-rasbt-machine-learning-book" style="font-size: 80%;"><b>Performing a general discrete convolution ("From Raschka et al":"https://github.com/rasbt/machine-learning-book")</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs027.html#set-of-filters" style="font-size: 80%;"><b>Set of filters</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs028.html#pooling" style="font-size: 80%;"><b>Pooling</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs029.html#no-zero-padding-unit-strides" style="font-size: 80%;"><b>No zero padding, unit strides</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs030.html#zero-padding-unit-strides" style="font-size: 80%;"><b>Zero padding, unit strides</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs031.html#half-same-padding" style="font-size: 80%;"><b>Half (same) padding</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs032.html#full-padding" style="font-size: 80%;"><b>Full padding</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs033.html#pooling-arithmetic" style="font-size: 80%;"><b>Pooling arithmetic</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs034.html#pooling-types-from-raschka-et-al-https-github-com-rasbt-machine-learning-book" style="font-size: 80%;"><b>Pooling types ("From Raschka et al":"https://github.com/rasbt/machine-learning-book")</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#building-our-own-cnn-code" style="font-size: 80%;"><b>Building our own CNN code</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#list-of-contents" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;List of contents:</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#schedulers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Schedulers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#usage-of-schedulers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of schedulers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#cost-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Cost functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#usage-of-cost-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of cost functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#activation-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Activation functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#usage-of-activation-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of activation functions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#convolution" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#layers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Layers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#convolution2dlayer-convolution-in-a-hidden-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution2DLayer: convolution in a hidden layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#backpropagation-in-the-convolutional-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Backpropagation in the convolutional layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#demonstration" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Demonstration</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#pooling-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Pooling Layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#flattening-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Flattening Layer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#fully-connected-layers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Fully Connected Layers</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#optimized-convolution2dlayer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Optimized Convolution2DLayer</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#the-convolutional-neural-network-cnn" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The Convolutional Neural Network (CNN)</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#usage-of-cnn-code" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of CNN code</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#additional-remarks" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Additional Remarks</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#remarks-on-the-speed" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Remarks on the speed</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#convolution-using-separable-kernels" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution using separable kernels</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#convolution-in-the-fourier-domain" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution in the Fourier domain</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs036.html#building-convolutional-neural-networks-in-tensorflow-and-keras" style="font-size: 80%;"><b>Building convolutional neural networks in Tensorflow and Keras</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs037.html#setting-it-up" style="font-size: 80%;"><b>Setting it up</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs038.html#the-mnist-dataset-again" style="font-size: 80%;"><b>The MNIST dataset again</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs039.html#strong-correlations" style="font-size: 80%;"><b>Strong correlations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs040.html#layers-of-a-cnn" style="font-size: 80%;"><b>Layers of a CNN</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs041.html#systematic-reduction" style="font-size: 80%;"><b>Systematic reduction</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs042.html#prerequisites-collect-and-pre-process-data" style="font-size: 80%;"><b>Prerequisites: Collect and pre-process data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs043.html#importing-keras-and-tensorflow" style="font-size: 80%;"><b>Importing Keras and Tensorflow</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs044.html#running-with-keras" style="font-size: 80%;"><b>Running with Keras</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs045.html#final-part" style="font-size: 80%;"><b>Final part</b></a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs046.html#final-visualization" style="font-size: 80%;"><b>Final visualization</b></a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0023"></a>
<!-- !split -->
<h2 id="generalizing-the-above-one-dimensional-case" class="anchor">Generalizing the above one-dimensional case </h2>

<p>In order to align the above simple case with the more general convolution cases, we rename \( \boldsymbol{\alpha} \), whose length is \( m=3 \), with \( \boldsymbol{w} \).
We will interpret \( \boldsymbol{w} \) as a weight/filter function with which we want to perform the convolution with an input varibale \( \boldsymbol{x} \).
We replace thus \( \boldsymbol{\beta} \) with \( \boldsymbol{x} \) and \( \boldsymbol{\delta} \) with \( \boldsymbol{s} \) and have
</p>
$$
s(i) \left(x*w\right)(i)= \sum_{k=0}^{k=m-1}w(k)x(i-k),
$$

<p>where \( m=3 \) in our case, the maximum length of the vector \( \boldsymbol{w} \).
Here the symbol \( * \) represents the mathematical operation of convolution.
</p>
<h2 id="two-dimensional-objects" class="anchor">Two-dimensional Objects </h2>

<p>We are now ready to start studying the discrete convolutions relevant for convolutional neural networks.
We often use convolutions over more than one dimension at a time. If
we have a two-dimensional image \( X \) as input, we can have a <b>filter</b>
defined by a two-dimensional <b>kernel/weight/filter</b> \( W \). This leads to an output \( Y \)
</p>

$$
Y(i,j)=(X * W)(i,j) = \sum_m\sum_n X(m,n)W(i-m,j-n).
$$

<p>Convolution is a commutative process, which means we can rewrite this equation as</p>
$$
Y(i,j)=(X * W)(i,j) = \sum_m\sum_n X(i-m,j-n)W(m,n).
$$

<p>Normally the latter is more straightforward to implement in  a machine larning library since there is less variation in the range of values of \( m \) and \( n \).</p>

<p>Many deep learning libraries implement cross-correlation instead of convolution (although it is referred to s convolution)</p>
$$
Y(i,j)=(X * W)(i,j) = \sum_m\sum_n X(i+m,j+n)W(m,n).
$$


<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week44-bs022.html">&laquo;</a></li>
  <li><a href="._week44-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week44-bs015.html">16</a></li>
  <li><a href="._week44-bs016.html">17</a></li>
  <li><a href="._week44-bs017.html">18</a></li>
  <li><a href="._week44-bs018.html">19</a></li>
  <li><a href="._week44-bs019.html">20</a></li>
  <li><a href="._week44-bs020.html">21</a></li>
  <li><a href="._week44-bs021.html">22</a></li>
  <li><a href="._week44-bs022.html">23</a></li>
  <li class="active"><a href="._week44-bs023.html">24</a></li>
  <li><a href="._week44-bs024.html">25</a></li>
  <li><a href="._week44-bs025.html">26</a></li>
  <li><a href="._week44-bs026.html">27</a></li>
  <li><a href="._week44-bs027.html">28</a></li>
  <li><a href="._week44-bs028.html">29</a></li>
  <li><a href="._week44-bs029.html">30</a></li>
  <li><a href="._week44-bs030.html">31</a></li>
  <li><a href="._week44-bs031.html">32</a></li>
  <li><a href="._week44-bs032.html">33</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week44-bs046.html">47</a></li>
  <li><a href="._week44-bs024.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

